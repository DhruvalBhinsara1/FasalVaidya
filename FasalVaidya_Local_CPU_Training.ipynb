{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c6bac4",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d36f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Check for GPU (will use if available, but notebook optimized for CPU)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"‚úÖ GPU detected: {gpus[0].name}\")\n",
    "    print(\"   Note: This notebook is optimized for CPU, but will use GPU if available\")\n",
    "    # Enable memory growth to prevent OOM\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"üíª No GPU detected - training on CPU\")\n",
    "    print(\"   Expected time: 8-13 hours total\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Session timing\n",
    "SESSION_START_TIME = datetime.now()\n",
    "print(f\"\\n‚è±Ô∏è Session started: {SESSION_START_TIME.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd36e02",
   "metadata": {},
   "source": [
    "## üîë Configuration - SET YOUR LOCAL PATHS HERE\n",
    "\n",
    "**üëâ EDIT THESE PATHS TO MATCH YOUR LOCAL SYSTEM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27baa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üîß LOCAL CONFIGURATION - EDIT THESE PATHS!\n",
    "# =============================================================\n",
    "\n",
    "# Path to your local \"Leaf Nutrient Data Sets\" folder\n",
    "# Example Windows: r'D:\\Datasets\\Leaf Nutrient Data Sets'\n",
    "# Example Mac/Linux: '/Users/yourname/Datasets/Leaf Nutrient Data Sets'\n",
    "NUTRIENT_DATASETS_ROOT = r'B:\\FasalVaidya\\datasets\\Leaf Nutrient Data Sets'\n",
    "\n",
    "# Path to PlantVillage dataset (optional - only if doing Stage 2)\n",
    "# Example: r'D:\\Datasets\\PlantVillage'\n",
    "PLANTVILLAGE_PATH = r'B:\\FasalVaidya\\datasets\\PlantVillage'\n",
    "\n",
    "# Output directory for models and checkpoints\n",
    "OUTPUT_DIR = r'B:\\FasalVaidya\\models\\local_training'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# üåæ Crop datasets to include (4-crop MVP)\n",
    "CROP_DATASETS = {\n",
    "    'rice': 'Rice Nutrients',\n",
    "    'wheat': 'Wheat Nitrogen',\n",
    "    'tomato': 'Tomato Nutrients',\n",
    "    'maize': 'Maize Nutrients',\n",
    "}\n",
    "\n",
    "# =============================================================\n",
    "# üéØ CPU-OPTIMIZED TRAINING SETTINGS\n",
    "# =============================================================\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8  # Reduced for CPU (GPU uses 32)\n",
    "\n",
    "# Epochs - reduced for faster CPU training\n",
    "# Note: You can increase these if you want better accuracy and have time\n",
    "PLANTVILLAGE_EPOCHS = 5   # Stage 2: Takes ~3-5 hours on CPU\n",
    "UNIFIED_EPOCHS = 10       # Stage 3: Takes ~5-8 hours on CPU\n",
    "\n",
    "# Learning rates\n",
    "LEARNING_RATE_STAGE2 = 1e-3\n",
    "LEARNING_RATE_STAGE3 = 5e-4\n",
    "\n",
    "# Regularization\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "# CPU-specific optimizations\n",
    "NUM_WORKERS = min(os.cpu_count(), 4)  # Limit workers to avoid overhead\n",
    "PREFETCH_BUFFER = 2  # Small prefetch for CPU\n",
    "\n",
    "# Use float32 (no mixed precision on CPU)\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "print(\"‚úÖ Using float32 policy\")\n",
    "\n",
    "# =============================================================\n",
    "# üìä CONFIGURATION SUMMARY\n",
    "# =============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üíª LOCAL CPU TRAINING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üåæ Crops: {len(CROP_DATASETS)} ({', '.join(CROP_DATASETS.keys())})\")\n",
    "print(f\"\\nüìÅ Data Paths:\")\n",
    "print(f\"   Nutrient datasets: {NUTRIENT_DATASETS_ROOT}\")\n",
    "print(f\"   PlantVillage: {PLANTVILLAGE_PATH}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"\\nüéØ Training Settings:\")\n",
    "print(f\"   Image size: {IMG_SIZE}√ó{IMG_SIZE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE} (CPU optimized)\")\n",
    "print(f\"   CPU workers: {NUM_WORKERS}\")\n",
    "print(f\"   Stage 2 epochs: {PLANTVILLAGE_EPOCHS}\")\n",
    "print(f\"   Stage 3 epochs: {UNIFIED_EPOCHS}\")\n",
    "print(f\"\\n‚è±Ô∏è Expected Time:\")\n",
    "print(f\"   Stage 2: ~{PLANTVILLAGE_EPOCHS * 40}-{PLANTVILLAGE_EPOCHS * 60} min\")\n",
    "print(f\"   Stage 3: ~{UNIFIED_EPOCHS * 40}-{UNIFIED_EPOCHS * 60} min\")\n",
    "print(f\"   Total: ~{(PLANTVILLAGE_EPOCHS + UNIFIED_EPOCHS) * 40 // 60}-{(PLANTVILLAGE_EPOCHS + UNIFIED_EPOCHS) * 60 // 60} hours\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"üîç Verifying paths...\")\n",
    "if not os.path.exists(NUTRIENT_DATASETS_ROOT):\n",
    "    print(f\"‚ùå ERROR: Nutrient dataset root not found!\")\n",
    "    print(f\"   Path: {NUTRIENT_DATASETS_ROOT}\")\n",
    "    print(f\"   Please update NUTRIENT_DATASETS_ROOT in the cell above\")\n",
    "else:\n",
    "    print(f\"‚úÖ Nutrient datasets found\")\n",
    "\n",
    "if not os.path.exists(PLANTVILLAGE_PATH):\n",
    "    print(f\"‚ö†Ô∏è PlantVillage not found (OK if skipping Stage 2)\")\n",
    "else:\n",
    "    print(f\"‚úÖ PlantVillage dataset found\")\n",
    "\n",
    "print(f\"‚úÖ Output directory ready: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26caf28",
   "metadata": {},
   "source": [
    "## üöÄ Optimized Data Pipeline for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üì¶ CPU-OPTIMIZED DATA PIPELINE\n",
    "# =============================================================\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def create_dataset(data_dir, img_size, batch_size, validation_split=0.2, subset=None):\n",
    "    \"\"\"Create dataset from directory\"\"\"\n",
    "    print(f\"üì¶ Loading {subset} data from {os.path.basename(data_dir)}...\")\n",
    "    \n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=validation_split,\n",
    "        subset=subset,\n",
    "        seed=42,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "@tf.function\n",
    "def augment_image(image, label):\n",
    "    \"\"\"Light augmentation for CPU training\"\"\"\n",
    "    # Random flip\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    \n",
    "    # Brightness and contrast\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    \n",
    "    # Clip values\n",
    "    image = tf.clip_by_value(image, 0.0, 255.0)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "@tf.function\n",
    "def normalize_for_mobilenet(image, label):\n",
    "    \"\"\"Normalize to MobileNetV2 input range [-1, 1]\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "def build_pipeline(dataset, is_training=True):\n",
    "    \"\"\"Build CPU-optimized pipeline\"\"\"\n",
    "    \n",
    "    # Light augmentation for training\n",
    "    if is_training:\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=NUM_WORKERS)\n",
    "    \n",
    "    # Normalize\n",
    "    dataset = dataset.map(normalize_for_mobilenet, num_parallel_calls=NUM_WORKERS)\n",
    "    \n",
    "    # Small prefetch for CPU\n",
    "    dataset = dataset.prefetch(buffer_size=PREFETCH_BUFFER)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# =============================================================\n",
    "# üìä PROGRESS CALLBACK\n",
    "# =============================================================\n",
    "class CPUProgressCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Progress tracking optimized for CPU training\"\"\"\n",
    "    \n",
    "    def __init__(self, total_epochs, stage_name=\"Training\"):\n",
    "        super().__init__()\n",
    "        self.total_epochs = total_epochs\n",
    "        self.stage_name = stage_name\n",
    "        self.epoch_times = []\n",
    "        self.start_time = None\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "        print(f\"\\nüöÄ {self.stage_name} Started\")\n",
    "        print(f\"   Epochs: {self.total_epochs}\")\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start = time.time()\n",
    "        print(f\"\\nüìà Epoch {epoch+1}/{self.total_epochs}\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        \n",
    "        # Calculate ETA\n",
    "        avg_time = np.mean(self.epoch_times)\n",
    "        remaining = self.total_epochs - (epoch + 1)\n",
    "        eta_seconds = remaining * avg_time\n",
    "        eta = str(timedelta(seconds=int(eta_seconds)))\n",
    "        \n",
    "        # Progress\n",
    "        val_acc = logs.get('val_accuracy', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        train_acc = logs.get('accuracy', 0)\n",
    "        \n",
    "        print(f\"   ‚úÖ Complete: train_acc={train_acc:.4f}, val_acc={val_acc:.4f}, val_loss={val_loss:.4f}\")\n",
    "        print(f\"   ‚è±Ô∏è Time: {epoch_time:.1f}s | Avg: {avg_time:.1f}s | ETA: {eta}\")\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        total_time = time.time() - self.start_time\n",
    "        print(f\"\\n‚úÖ {self.stage_name} Complete!\")\n",
    "        print(f\"   Total time: {str(timedelta(seconds=int(total_time)))}\")\n",
    "        print(f\"   Avg epoch: {np.mean(self.epoch_times):.1f}s\")\n",
    "\n",
    "print(\"‚úÖ Data pipeline functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6b161",
   "metadata": {},
   "source": [
    "## üå± Stage 2: PlantVillage Training (OPTIONAL)\n",
    "\n",
    "**‚ö†Ô∏è This stage takes 3-5 hours on CPU!**\n",
    "\n",
    "You can skip this and go directly to Stage 3 if:\n",
    "- You want faster training\n",
    "- You already have a Stage 2 checkpoint\n",
    "- You're okay with slightly lower accuracy\n",
    "\n",
    "**To skip:** Just run the cell that creates the Stage 2 model without training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b7684",
   "metadata": {},
   "source": [
    "## üì• Download PlantVillage Dataset (Optional)\n",
    "\n",
    "If you don't have PlantVillage dataset locally, you can download it from Kaggle.\n",
    "\n",
    "**Requirements:**\n",
    "1. Kaggle account\n",
    "2. Kaggle API key (`kaggle.json`)\n",
    "\n",
    "**To get kaggle.json:**\n",
    "1. Go to https://www.kaggle.com/settings\n",
    "2. Scroll to \"API\" section\n",
    "3. Click \"Create New Token\"\n",
    "4. Place `kaggle.json` in: `~/.kaggle/` (Linux/Mac) or `C:\\Users\\YourName\\.kaggle\\` (Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üì• DOWNLOAD PLANTVILLAGE DATASET FROM KAGGLE\n",
    "# =============================================================\n",
    "\n",
    "import zipfile\n",
    "import subprocess\n",
    "\n",
    "def download_plantvillage():\n",
    "    \"\"\"Download PlantVillage dataset from Kaggle with progress tracking\"\"\"\n",
    "    \n",
    "    # Check if already exists\n",
    "    if PLANTVILLAGE_PATH.exists():\n",
    "        # Check if it has data\n",
    "        try:\n",
    "            subdirs = [d for d in PLANTVILLAGE_PATH.iterdir() if d.is_dir()]\n",
    "            if len(subdirs) > 10:  # PlantVillage has ~38 classes\n",
    "                print(\"‚úÖ PlantVillage dataset already exists!\")\n",
    "                print(f\"   Location: {PLANTVILLAGE_PATH.relative_to(NOTEBOOK_DIR)}\")\n",
    "                print(f\"   Classes found: {len(subdirs)}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è PlantVillage folder exists but seems incomplete\")\n",
    "                print(\"   Will re-download...\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"üì• Downloading PlantVillage dataset from Kaggle...\")\n",
    "    print(\"   This may take 5-10 minutes (~1-2 GB)\")\n",
    "    \n",
    "    # Check for Kaggle credentials\n",
    "    kaggle_config = Path.home() / '.kaggle' / 'kaggle.json'\n",
    "    if not kaggle_config.exists():\n",
    "        print(\"\\n‚ùå Kaggle credentials not found!\")\n",
    "        print(f\"   Expected: {kaggle_config}\")\n",
    "        print(\"\\nüìù To set up:\")\n",
    "        print(\"   1. Go to https://www.kaggle.com/settings\")\n",
    "        print(\"   2. Scroll to 'API' section\")\n",
    "        print(\"   3. Click 'Create New Token'\")\n",
    "        print(f\"   4. Place kaggle.json in: {kaggle_config.parent}\")\n",
    "        print(\"\\n‚è© Skipping download - you can manually download from:\")\n",
    "        print(\"   https://www.kaggle.com/datasets/arjuntejaswi/plant-village\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Install kaggle package if not available\n",
    "        try:\n",
    "            import kaggle\n",
    "        except ImportError:\n",
    "            print(\"üì¶ Installing kaggle package...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"])\n",
    "            import kaggle\n",
    "        \n",
    "        # Create parent directory\n",
    "        PLANTVILLAGE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Download dataset\n",
    "        print(\"\\n‚¨áÔ∏è Downloading from Kaggle...\")\n",
    "        download_path = PLANTVILLAGE_PATH.parent\n",
    "        \n",
    "        # Download using kaggle API\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        \n",
    "        print(\"   Downloading arjuntejaswi/plant-village...\")\n",
    "        api.dataset_download_files(\n",
    "            'arjuntejaswi/plant-village',\n",
    "            path=str(download_path),\n",
    "            unzip=False\n",
    "        )\n",
    "        \n",
    "        # Find downloaded zip file\n",
    "        zip_file = download_path / 'plant-village.zip'\n",
    "        if not zip_file.exists():\n",
    "            # Try alternative name\n",
    "            zip_files = list(download_path.glob('*.zip'))\n",
    "            if zip_files:\n",
    "                zip_file = zip_files[0]\n",
    "            else:\n",
    "                print(\"‚ùå Downloaded file not found!\")\n",
    "                return False\n",
    "        \n",
    "        print(f\"\\nüì¶ Extracting {zip_file.name}...\")\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            # Extract all files\n",
    "            zip_ref.extractall(download_path)\n",
    "        \n",
    "        # Find extracted folder (might be nested)\n",
    "        possible_dirs = [\n",
    "            download_path / 'PlantVillage',\n",
    "            download_path / 'plant-village',\n",
    "            download_path / 'Plant_Village',\n",
    "        ]\n",
    "        \n",
    "        extracted_dir = None\n",
    "        for d in possible_dirs:\n",
    "            if d.exists():\n",
    "                extracted_dir = d\n",
    "                break\n",
    "        \n",
    "        # If not found, look for any directory with many subdirectories\n",
    "        if not extracted_dir:\n",
    "            for d in download_path.iterdir():\n",
    "                if d.is_dir() and d.name not in ['unified_nutrient_dataset', 'local_training']:\n",
    "                    subdirs = [x for x in d.iterdir() if x.is_dir()]\n",
    "                    if len(subdirs) > 10:\n",
    "                        extracted_dir = d\n",
    "                        break\n",
    "        \n",
    "        if extracted_dir and extracted_dir != PLANTVILLAGE_PATH:\n",
    "            # Rename to expected path\n",
    "            if PLANTVILLAGE_PATH.exists():\n",
    "                shutil.rmtree(PLANTVILLAGE_PATH)\n",
    "            extracted_dir.rename(PLANTVILLAGE_PATH)\n",
    "            print(f\"‚úÖ Renamed to: {PLANTVILLAGE_PATH.relative_to(NOTEBOOK_DIR)}\")\n",
    "        \n",
    "        # Clean up zip file\n",
    "        zip_file.unlink()\n",
    "        print(\"üóëÔ∏è Cleaned up zip file\")\n",
    "        \n",
    "        # Verify extraction\n",
    "        if PLANTVILLAGE_PATH.exists():\n",
    "            num_classes = len([d for d in PLANTVILLAGE_PATH.iterdir() if d.is_dir()])\n",
    "            print(f\"\\n‚úÖ PlantVillage dataset ready!\")\n",
    "            print(f\"   Location: {PLANTVILLAGE_PATH.relative_to(NOTEBOOK_DIR)}\")\n",
    "            print(f\"   Classes: {num_classes}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"\\n‚ùå Extraction failed - path not found\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Download failed: {e}\")\n",
    "        print(\"\\nüí° You can manually download from:\")\n",
    "        print(\"   https://www.kaggle.com/datasets/arjuntejaswi/plant-village\")\n",
    "        print(f\"   Then extract to: {PLANTVILLAGE_PATH.relative_to(NOTEBOOK_DIR)}\")\n",
    "        return False\n",
    "\n",
    "# Run download\n",
    "print(\"=\"*70)\n",
    "print(\"üì• PLANTVILLAGE DATASET CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "download_success = download_plantvillage()\n",
    "\n",
    "if download_success:\n",
    "    print(\"\\n‚úÖ Ready for Stage 2 training!\")\n",
    "else:\n",
    "    print(\"\\n‚è© You can skip Stage 2 or download manually\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad68675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if PlantVillage path exists\n",
    "if not os.path.exists(PLANTVILLAGE_PATH):\n",
    "    print(\"‚ö†Ô∏è PlantVillage dataset not found\")\n",
    "    print(f\"   Path: {PLANTVILLAGE_PATH}\")\n",
    "    print(\"\\nüí° Options:\")\n",
    "    print(\"   1. Skip Stage 2 (go to Stage 3)\")\n",
    "    print(\"   2. Download PlantVillage and update path\")\n",
    "    SKIP_STAGE2 = True\n",
    "else:\n",
    "    print(\"‚úÖ PlantVillage dataset found\")\n",
    "    print(\"\\nü§î Do you want to train Stage 2?\")\n",
    "    print(\"   Set SKIP_STAGE2 = True to skip (faster)\")\n",
    "    print(\"   Set SKIP_STAGE2 = False to train (better accuracy)\")\n",
    "    SKIP_STAGE2 = False  # Change to True to skip\n",
    "\n",
    "if SKIP_STAGE2:\n",
    "    print(\"\\n‚è© Skipping Stage 2 (PlantVillage training)\")\n",
    "    print(\"   Will create model with ImageNet weights only\")\n",
    "else:\n",
    "    print(\"\\n‚è±Ô∏è Stage 2 will take approximately 3-5 hours\")\n",
    "    print(\"   Consider running overnight!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üì¶ CREATE PLANTVILLAGE DATASETS (if not skipping)\n",
    "# =============================================================\n",
    "\n",
    "if not SKIP_STAGE2:\n",
    "    print(\"üì¶ Creating PlantVillage datasets...\")\n",
    "    \n",
    "    train_plantvillage_raw = create_dataset(\n",
    "        PLANTVILLAGE_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "        validation_split=0.2, subset='training'\n",
    "    )\n",
    "    val_plantvillage_raw = create_dataset(\n",
    "        PLANTVILLAGE_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "        validation_split=0.2, subset='validation'\n",
    "    )\n",
    "    \n",
    "    # Build pipelines\n",
    "    train_plantvillage = build_pipeline(train_plantvillage_raw, is_training=True)\n",
    "    val_plantvillage = build_pipeline(val_plantvillage_raw, is_training=False)\n",
    "    \n",
    "    num_plantvillage_classes = len(train_plantvillage_raw.class_names)\n",
    "    train_batches = tf.data.experimental.cardinality(train_plantvillage_raw).numpy()\n",
    "    val_batches = tf.data.experimental.cardinality(val_plantvillage_raw).numpy()\n",
    "    \n",
    "    print(f\"\\n‚úÖ PlantVillage Datasets Ready\")\n",
    "    print(f\"   Classes: {num_plantvillage_classes}\")\n",
    "    print(f\"   Training: {train_batches} batches √ó {BATCH_SIZE}\")\n",
    "    print(f\"   Validation: {val_batches} batches √ó {BATCH_SIZE}\")\n",
    "else:\n",
    "    print(\"‚è© Skipped PlantVillage dataset creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c112e2",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Build Stage 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a634fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üèóÔ∏è CREATE MODEL ARCHITECTURE\n",
    "# =============================================================\n",
    "\n",
    "def create_model(num_classes, input_shape=(224, 224, 3), freeze_base=True):\n",
    "    \"\"\"Create MobileNetV2-based model\"\"\"\n",
    "    \n",
    "    # Load MobileNetV2 with ImageNet weights\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = not freeze_base\n",
    "    \n",
    "    # Build classification head\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "        tf.keras.layers.Dense(\n",
    "            256,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE * 0.8),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "if not SKIP_STAGE2:\n",
    "    # Check for existing checkpoint\n",
    "    stage2_checkpoint = os.path.join(OUTPUT_DIR, 'stage2_plantvillage_best.keras')\n",
    "    \n",
    "    if os.path.exists(stage2_checkpoint):\n",
    "        print(\"üîÑ Found existing Stage 2 checkpoint\")\n",
    "        try:\n",
    "            model_stage2 = tf.keras.models.load_model(stage2_checkpoint)\n",
    "            print(\"‚úÖ Loaded checkpoint\")\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Could not load checkpoint, creating new model\")\n",
    "            model_stage2, base_stage2 = create_model(num_plantvillage_classes)\n",
    "    else:\n",
    "        print(\"üèóÔ∏è Creating new Stage 2 model...\")\n",
    "        model_stage2, base_stage2 = create_model(num_plantvillage_classes)\n",
    "    \n",
    "    # Compile\n",
    "    model_stage2.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_STAGE2),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Stage 2 Model Ready\")\n",
    "    print(f\"   Classes: {num_plantvillage_classes}\")\n",
    "    print(f\"   Trainable params: {sum([tf.keras.backend.count_params(w) for w in model_stage2.trainable_weights]):,}\")\n",
    "else:\n",
    "    print(\"‚è© Skipped Stage 2 model creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da550156",
   "metadata": {},
   "source": [
    "## üéØ Train Stage 2 (PlantVillage)\n",
    "\n",
    "**‚ö†Ô∏è This will take 3-5 hours!** Consider running overnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3adc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_STAGE2:\n",
    "    print(\"üöÄ Starting Stage 2 Training\")\n",
    "    print(f\"‚è±Ô∏è Expected time: ~{PLANTVILLAGE_EPOCHS * 40} - {PLANTVILLAGE_EPOCHS * 60} minutes\")\n",
    "    print(\"\\nüí° You can stop anytime (Ctrl+C) - checkpoint will be saved!\\n\")\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks_stage2 = [\n",
    "        CPUProgressCallback(PLANTVILLAGE_EPOCHS, stage_name=\"Stage 2: PlantVillage\"),\n",
    "        \n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(OUTPUT_DIR, 'stage2_plantvillage_best.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    history_stage2 = model_stage2.fit(\n",
    "        train_plantvillage,\n",
    "        validation_data=val_plantvillage,\n",
    "        epochs=PLANTVILLAGE_EPOCHS,\n",
    "        callbacks=callbacks_stage2,\n",
    "        verbose=2  # Progress per epoch\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Stage 2 Training Complete!\")\n",
    "    print(f\"   Best val accuracy: {max(history_stage2.history['val_accuracy']):.4f}\")\n",
    "else:\n",
    "    print(\"‚è© Skipped Stage 2 training\")\n",
    "    print(\"   Will use ImageNet weights for Stage 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81751b7",
   "metadata": {},
   "source": [
    "## üîÑ Stage 3: Build Unified Nutrient Dataset\n",
    "\n",
    "This combines all crop datasets into one unified structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ed2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üèóÔ∏è BUILD UNIFIED DATASET\n",
    "# =============================================================\n",
    "\n",
    "print(\"üèóÔ∏è Building unified nutrient dataset...\")\n",
    "\n",
    "UNIFIED_DATASET_PATH = os.path.join(OUTPUT_DIR, 'unified_nutrient_dataset')\n",
    "\n",
    "def detect_nutrient_classes(crop_path):\n",
    "    \"\"\"Detect nutrient classes from folder structure\"\"\"\n",
    "    nutrient_classes = {}\n",
    "    \n",
    "    if not os.path.exists(crop_path):\n",
    "        return nutrient_classes\n",
    "    \n",
    "    subfolders = [d for d in os.listdir(crop_path) \n",
    "                  if os.path.isdir(os.path.join(crop_path, d))]\n",
    "    \n",
    "    # Check for train/test/val splits\n",
    "    split_keywords = {'train', 'test', 'val', 'validation'}\n",
    "    has_splits = any(f.lower() in split_keywords for f in subfolders)\n",
    "    \n",
    "    if has_splits:\n",
    "        # Has train/test/val structure\n",
    "        for split in subfolders:\n",
    "            if split.lower() in split_keywords:\n",
    "                split_path = os.path.join(crop_path, split)\n",
    "                for cls in os.listdir(split_path):\n",
    "                    cls_path = os.path.join(split_path, cls)\n",
    "                    if os.path.isdir(cls_path):\n",
    "                        files = os.listdir(cls_path)[:10]\n",
    "                        has_images = any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in files)\n",
    "                        if has_images:\n",
    "                            if cls not in nutrient_classes:\n",
    "                                nutrient_classes[cls] = []\n",
    "                            nutrient_classes[cls].append(cls_path)\n",
    "    else:\n",
    "        # Flat structure\n",
    "        for cls in subfolders:\n",
    "            cls_path = os.path.join(crop_path, cls)\n",
    "            files = os.listdir(cls_path)[:10]\n",
    "            has_images = any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in files)\n",
    "            if has_images:\n",
    "                nutrient_classes[cls] = [cls_path]\n",
    "    \n",
    "    return nutrient_classes\n",
    "\n",
    "# Build unified dataset\n",
    "if os.path.exists(UNIFIED_DATASET_PATH):\n",
    "    existing = [d for d in os.listdir(UNIFIED_DATASET_PATH) \n",
    "                if os.path.isdir(os.path.join(UNIFIED_DATASET_PATH, d))]\n",
    "    if len(existing) > 5:\n",
    "        print(f\"‚úÖ Unified dataset exists with {len(existing)} classes\")\n",
    "        unified_classes = existing\n",
    "        needs_rebuild = False\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Incomplete dataset, rebuilding...\")\n",
    "        shutil.rmtree(UNIFIED_DATASET_PATH)\n",
    "        needs_rebuild = True\n",
    "else:\n",
    "    needs_rebuild = True\n",
    "\n",
    "if needs_rebuild:\n",
    "    os.makedirs(UNIFIED_DATASET_PATH, exist_ok=True)\n",
    "    unified_classes = []\n",
    "    \n",
    "    print(\"üìÇ Combining crop datasets...\\n\")\n",
    "    \n",
    "    for crop, folder_name in CROP_DATASETS.items():\n",
    "        crop_path = os.path.join(NUTRIENT_DATASETS_ROOT, folder_name)\n",
    "        \n",
    "        if not os.path.exists(crop_path):\n",
    "            print(f\"   ‚ö†Ô∏è {crop.upper()}: Not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   üåæ {crop.upper()}: Processing...\")\n",
    "        \n",
    "        nutrient_classes = detect_nutrient_classes(crop_path)\n",
    "        \n",
    "        for cls_name, src_paths in nutrient_classes.items():\n",
    "            clean_name = cls_name.replace(f\"{crop}_\", \"\").replace(f\"{crop}__\", \"\")\n",
    "            unified_class = f\"{crop}_{clean_name}\"\n",
    "            \n",
    "            dst_dir = os.path.join(UNIFIED_DATASET_PATH, unified_class)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            \n",
    "            # Copy images\n",
    "            total = 0\n",
    "            for src_dir in src_paths:\n",
    "                src_name = os.path.basename(os.path.dirname(src_dir))\n",
    "                for img_file in os.listdir(src_dir):\n",
    "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        src_file = os.path.join(src_dir, img_file)\n",
    "                        dst_file = os.path.join(dst_dir, f\"{src_name}_{img_file}\")\n",
    "                        if not os.path.exists(dst_file):\n",
    "                            shutil.copy2(src_file, dst_file)\n",
    "                            total += 1\n",
    "            \n",
    "            if total > 0 and unified_class not in unified_classes:\n",
    "                unified_classes.append(unified_class)\n",
    "        \n",
    "        crop_classes = [c for c in unified_classes if c.startswith(f\"{crop}_\")]\n",
    "        print(f\"      ‚úÖ {len(crop_classes)} classes\")\n",
    "\n",
    "class_names = sorted(unified_classes)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\n‚úÖ Unified Dataset Ready\")\n",
    "print(f\"   Total classes: {num_classes}\")\n",
    "print(f\"   Classes: {', '.join(class_names[:6])}...\")\n",
    "print(f\"   Location: {UNIFIED_DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68789a96",
   "metadata": {},
   "source": [
    "## üì¶ Create Unified Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Creating unified nutrient datasets...\")\n",
    "\n",
    "train_nutrient_raw = create_dataset(\n",
    "    UNIFIED_DATASET_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "    validation_split=0.2, subset='training'\n",
    ")\n",
    "val_nutrient_raw = create_dataset(\n",
    "    UNIFIED_DATASET_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "    validation_split=0.2, subset='validation'\n",
    ")\n",
    "\n",
    "# Build pipelines\n",
    "train_nutrient = build_pipeline(train_nutrient_raw, is_training=True)\n",
    "val_nutrient = build_pipeline(val_nutrient_raw, is_training=False)\n",
    "\n",
    "train_batches = tf.data.experimental.cardinality(train_nutrient_raw).numpy()\n",
    "val_batches = tf.data.experimental.cardinality(val_nutrient_raw).numpy()\n",
    "\n",
    "print(f\"\\n‚úÖ Unified Datasets Ready\")\n",
    "print(f\"   Classes: {num_classes}\")\n",
    "print(f\"   Training: {train_batches} batches √ó {BATCH_SIZE}\")\n",
    "print(f\"   Validation: {val_batches} batches √ó {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fe9cfb",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Build Stage 3 Model (Unified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50625223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üîß CREATE STAGE 3 MODEL\n",
    "# =============================================================\n",
    "\n",
    "print(\"üèóÔ∏è Creating Stage 3 unified model...\")\n",
    "\n",
    "# Check for checkpoint\n",
    "stage3_checkpoint = os.path.join(OUTPUT_DIR, 'unified_nutrient_best.keras')\n",
    "\n",
    "if os.path.exists(stage3_checkpoint):\n",
    "    print(\"üîÑ Found existing Stage 3 checkpoint\")\n",
    "    try:\n",
    "        model_stage3 = tf.keras.models.load_model(stage3_checkpoint)\n",
    "        print(\"‚úÖ Loaded checkpoint\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Could not load, creating new model\")\n",
    "        model_stage3 = None\n",
    "else:\n",
    "    model_stage3 = None\n",
    "\n",
    "if model_stage3 is None:\n",
    "    if not SKIP_STAGE2 and 'model_stage2' in locals():\n",
    "        # Use Stage 2 base\n",
    "        print(\"   Using Stage 2 trained base\")\n",
    "        base_model = model_stage2.layers[0]\n",
    "        base_model.trainable = False\n",
    "    else:\n",
    "        # Use ImageNet weights\n",
    "        print(\"   Using ImageNet pretrained base\")\n",
    "        base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    model_stage3 = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "        tf.keras.layers.Dense(\n",
    "            384,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE * 0.8),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')\n",
    "    ], name='unified_nutrient_model')\n",
    "\n",
    "# Compile\n",
    "model_stage3.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_STAGE3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Stage 3 Model Ready\")\n",
    "print(f\"   Classes: {num_classes}\")\n",
    "print(f\"   Trainable params: {sum([tf.keras.backend.count_params(w) for w in model_stage3.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93717e6",
   "metadata": {},
   "source": [
    "## üéØ Train Stage 3 (Unified Nutrient Detection)\n",
    "\n",
    "**‚ö†Ô∏è This will take 5-8 hours on CPU!** Recommended to run overnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting Stage 3 Training (UNIFIED)\")\n",
    "print(f\"‚è±Ô∏è Expected time: ~{UNIFIED_EPOCHS * 40} - {UNIFIED_EPOCHS * 60} minutes\")\n",
    "print(f\"   That's approximately {(UNIFIED_EPOCHS * 40) // 60} - {(UNIFIED_EPOCHS * 60) // 60} hours\")\n",
    "print(\"\\nüí° This is the main training - be patient!\")\n",
    "print(\"   You can stop anytime - checkpoint will be saved!\\n\")\n",
    "\n",
    "# Callbacks\n",
    "callbacks_stage3 = [\n",
    "    CPUProgressCallback(UNIFIED_EPOCHS, stage_name=\"Stage 3: Unified Nutrients\"),\n",
    "    \n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, 'unified_nutrient_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "history_stage3 = model_stage3.fit(\n",
    "    train_nutrient,\n",
    "    validation_data=val_nutrient,\n",
    "    epochs=UNIFIED_EPOCHS,\n",
    "    callbacks=callbacks_stage3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ STAGE 3 TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Best val accuracy: {max(history_stage3.history['val_accuracy']):.4f}\")\n",
    "print(f\"‚úÖ Best top-3 accuracy: {max(history_stage3.history['top3_acc']):.4f}\")\n",
    "print(f\"üíæ Model saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2788f02e",
   "metadata": {},
   "source": [
    "## üìä Training Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc218d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_stage3.history['accuracy'], 'b-', label='Train', linewidth=2)\n",
    "axes[0].plot(history_stage3.history['val_accuracy'], 'r-', label='Validation', linewidth=2)\n",
    "axes[0].set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_stage3.history['loss'], 'b-', label='Train', linewidth=2)\n",
    "axes[1].plot(history_stage3.history['val_loss'], 'r-', label='Validation', linewidth=2)\n",
    "axes[1].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Training curves saved to: {os.path.join(OUTPUT_DIR, 'training_history.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1656bd",
   "metadata": {},
   "source": [
    "## üì¶ Export Model (SavedModel Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ce66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üíæ EXPORT SAVEDMODEL FOR BACKEND\n",
    "# =============================================================\n",
    "\n",
    "print(\"üì¶ Exporting model to SavedModel format...\")\n",
    "\n",
    "savedmodel_path = os.path.join(OUTPUT_DIR, 'unified_savedmodel')\n",
    "\n",
    "# Remove old if exists\n",
    "if os.path.exists(savedmodel_path):\n",
    "    shutil.rmtree(savedmodel_path)\n",
    "\n",
    "# Export\n",
    "model_stage3.save(savedmodel_path, save_format='tf')\n",
    "\n",
    "print(f\"‚úÖ SavedModel exported to: {savedmodel_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_name': 'FasalVaidya Unified Nutrient Model',\n",
    "    'version': '1.0.0-local',\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'num_classes': num_classes,\n",
    "    'class_names': class_names,\n",
    "    'crops': list(CROP_DATASETS.keys()),\n",
    "    'img_size': IMG_SIZE,\n",
    "    'trained_on': 'Local CPU',\n",
    "    'epochs': UNIFIED_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'best_val_accuracy': float(max(history_stage3.history['val_accuracy'])),\n",
    "    'best_top3_accuracy': float(max(history_stage3.history['top3_acc']))\n",
    "}\n",
    "\n",
    "with open(os.path.join(savedmodel_path, 'metadata.json'), 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# Save class labels\n",
    "with open(os.path.join(savedmodel_path, 'labels.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(class_names))\n",
    "\n",
    "print(f\"\\nüìÑ Files created:\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ saved_model.pb\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ variables/\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ metadata.json\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ labels.txt\")\n",
    "\n",
    "# Calculate size\n",
    "total_size = sum(f.stat().st_size for f in Path(savedmodel_path).rglob('*') if f.is_file()) / (1024 * 1024)\n",
    "print(f\"\\nüìä Total size: {total_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a551c",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "### üì¶ Next Steps\n",
    "\n",
    "1. **Copy the SavedModel to your backend:**\n",
    "   ```bash\n",
    "   # Copy the entire folder\n",
    "   cp -r \"{OUTPUT_DIR}/unified_savedmodel\" \"backend/ml/models/\"\n",
    "   ```\n",
    "\n",
    "2. **Test the model:**\n",
    "   ```bash\n",
    "   cd backend\n",
    "   python test_unified.py\n",
    "   ```\n",
    "\n",
    "3. **Expected output:**\n",
    "   ```\n",
    "   N score: 75.3% (moderate deficiency)\n",
    "   P score: 18.2% (healthy)\n",
    "   K score: 6.5% (healthy)\n",
    "   Detected: rice_Nitrogen(N)\n",
    "   Confidence: 75.3%\n",
    "   ```\n",
    "\n",
    "### üìä Model Info\n",
    "\n",
    "Your model is now ready for deployment! It supports:\n",
    "- üåæ **4 crops:** Rice, Wheat, Tomato, Maize\n",
    "- üî¨ **Multiple deficiencies:** N, P, K, and healthy classes\n",
    "- üì± **Real-time inference** on mobile and backend\n",
    "- üéØ **Expected accuracy:** 70-95% on deficient leaves\n",
    "\n",
    "### üöÄ Performance Notes\n",
    "\n",
    "This model was trained on CPU, which is slower but produces the same quality as GPU training. The final model will work just as well in production!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
