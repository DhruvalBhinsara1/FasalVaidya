{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69c6bac4",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Setup & Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17d36f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "NumPy version: 2.2.6\n",
      "ðŸ’» No GPU detected - training on CPU\n",
      "   Expected time: 8-13 hours total\n",
      "\n",
      "â±ï¸ Session started: 14:53:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow>=2.15.0 kaggle opendatasets scikit-learn matplotlib seaborn tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Check for GPU (will use if available, but notebook optimized for CPU)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"âœ… GPU detected: {gpus[0].name}\")\n",
    "    print(\"   Note: This notebook is optimized for CPU, but will use GPU if available\")\n",
    "    # Enable memory growth to prevent OOM\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"ðŸ’» No GPU detected - training on CPU\")\n",
    "    print(\"   Expected time: 8-13 hours total\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Session timing\n",
    "SESSION_START_TIME = datetime.now()\n",
    "print(f\"\\nâ±ï¸ Session started: {SESSION_START_TIME.strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd36e02",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Configuration - SET YOUR LOCAL PATHS HERE\n",
    "\n",
    "**ðŸ‘‰ EDIT THESE PATHS TO MATCH YOUR LOCAL SYSTEM:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e27baa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using float32 policy\n",
      "\n",
      "======================================================================\n",
      "ðŸ’» LOCAL CPU TRAINING CONFIGURATION\n",
      "======================================================================\n",
      "ðŸŒ¾ Crops: 4 (rice, wheat, tomato, maize)\n",
      "\n",
      "ðŸ“ Data Paths:\n",
      "   Nutrient datasets: E:\\FasalVaidya\\datasets\\Leaf Nutrient Data Sets\n",
      "   PlantVillage: E:\\FasalVaidya\\datasets\\PlantVillage\n",
      "   Output: E:\\FasalVaidya\\unified_savedmodel_output\n",
      "   Kaggle JSON: E:\\FasalVaidya\\datasets\\kaggle.json\n",
      "\n",
      "ðŸŽ¯ Training Settings:\n",
      "   Image size: 224Ã—224\n",
      "   Batch size: 8 (CPU optimized)\n",
      "   CPU workers: 4\n",
      "   Stage 2 epochs: 5\n",
      "   Stage 3 epochs: 10\n",
      "\n",
      "â±ï¸ Expected Time:\n",
      "   Stage 2: ~200-300 min\n",
      "   Stage 3: ~400-600 min\n",
      "   Total: ~10-15 hours\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ”§ LOCAL CONFIGURATION - DATASET FOLDERS\n",
    "# =============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Base datasets folder\n",
    "DATASETS_ROOT = Path(\"datasets\").resolve()\n",
    "\n",
    "# Path to leaf nutrient datasets\n",
    "NUTRIENT_DATASETS_ROOT = DATASETS_ROOT / \"Leaf Nutrient Data Sets\"\n",
    "\n",
    "# Path to PlantVillage dataset\n",
    "PLANTVILLAGE_PATH = DATASETS_ROOT / \"PlantVillage\"\n",
    "\n",
    "# Path to kaggle.json (for Kaggle API)\n",
    "KAGGLE_JSON_PATH = DATASETS_ROOT / \"kaggle.json\"\n",
    "\n",
    "# Output directory for models and checkpoints\n",
    "OUTPUT_DIR = Path(\"unified_savedmodel_output\").resolve()\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ðŸŒ¾ Crop datasets to include (4-crop MVP)\n",
    "CROP_DATASETS = {\n",
    "    'rice': 'Rice Nutrients',\n",
    "    'wheat': 'Wheat Nitrogen',\n",
    "    'tomato': 'Tomato Nutrients',\n",
    "    'maize': 'Maize Nutrients',\n",
    "}\n",
    "\n",
    "# Ensure all required folders exist\n",
    "DATASETS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "NUTRIENT_DATASETS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "PLANTVILLAGE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =============================================================\n",
    "# ðŸŽ¯ CPU-OPTIMIZED TRAINING SETTINGS\n",
    "# =============================================================\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8  # Reduced for CPU (GPU uses 32)\n",
    "\n",
    "# Epochs - reduced for faster CPU training\n",
    "# Note: You can increase these if you want better accuracy and have time\n",
    "PLANTVILLAGE_EPOCHS = 5   # Stage 2: Takes ~3-5 hours on CPU\n",
    "UNIFIED_EPOCHS = 10       # Stage 3: Takes ~5-8 hours on CPU\n",
    "\n",
    "# Learning rates\n",
    "LEARNING_RATE_STAGE2 = 1e-3\n",
    "LEARNING_RATE_STAGE3 = 5e-4\n",
    "\n",
    "# Regularization\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "# CPU-specific optimizations\n",
    "NUM_WORKERS = min(os.cpu_count(), 4)  # Limit workers to avoid overhead\n",
    "PREFETCH_BUFFER = 2  # Small prefetch for CPU\n",
    "\n",
    "# Use float32 (no mixed precision on CPU)\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "print(\"âœ… Using float32 policy\")\n",
    "\n",
    "# =============================================================\n",
    "# ðŸ“Š CONFIGURATION SUMMARY\n",
    "# =============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ’» LOCAL CPU TRAINING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ðŸŒ¾ Crops: {len(CROP_DATASETS)} ({', '.join(CROP_DATASETS.keys())})\")\n",
    "print(f\"\\nðŸ“ Data Paths:\")\n",
    "print(f\"   Nutrient datasets: {NUTRIENT_DATASETS_ROOT}\")\n",
    "print(f\"   PlantVillage: {PLANTVILLAGE_PATH}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Kaggle JSON: {KAGGLE_JSON_PATH}\")\n",
    "print(f\"\\nðŸŽ¯ Training Settings:\")\n",
    "print(f\"   Image size: {IMG_SIZE}Ã—{IMG_SIZE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE} (CPU optimized)\")\n",
    "print(f\"   CPU workers: {NUM_WORKERS}\")\n",
    "print(f\"   Stage 2 epochs: {PLANTVILLAGE_EPOCHS}\")\n",
    "print(f\"   Stage 3 epochs: {UNIFIED_EPOCHS}\")\n",
    "print(f\"\\nâ±ï¸ Expected Time:\")\n",
    "print(f\"   Stage 2: ~{PLANTVILLAGE_EPOCHS * 40}-{PLANTVILLAGE_EPOCHS * 60} min\")\n",
    "print(f\"   Stage 3: ~{UNIFIED_EPOCHS * 40}-{UNIFIED_EPOCHS * 60} min\")\n",
    "print(f\"   Total: ~{(PLANTVILLAGE_EPOCHS + UNIFIED_EPOCHS) * 40 // 60}-{(PLANTVILLAGE_EPOCHS + UNIFIED_EPOCHS) * 60 // 60} hours\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26caf28",
   "metadata": {},
   "source": [
    "## ðŸš€ Optimized Data Pipeline for CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9540ceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data pipeline functions ready\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ“¦ CPU-OPTIMIZED DATA PIPELINE\n",
    "# =============================================================\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def create_dataset(data_dir, img_size, batch_size, validation_split=0.2, subset=None):\n",
    "    \"\"\"Create dataset from directory\"\"\"\n",
    "    print(f\"ðŸ“¦ Loading {subset} data from {os.path.basename(data_dir)}...\")\n",
    "    \n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=validation_split,\n",
    "        subset=subset,\n",
    "        seed=42,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "@tf.function\n",
    "def augment_image(image, label):\n",
    "    \"\"\"Light augmentation for CPU training\"\"\"\n",
    "    # Random flip\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    \n",
    "    # Brightness and contrast\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    \n",
    "    # Clip values\n",
    "    image = tf.clip_by_value(image, 0.0, 255.0)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "@tf.function\n",
    "def normalize_for_mobilenet(image, label):\n",
    "    \"\"\"Normalize to MobileNetV2 input range [-1, 1]\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "def build_pipeline(dataset, is_training=True):\n",
    "    \"\"\"Build CPU-optimized pipeline\"\"\"\n",
    "    \n",
    "    # Light augmentation for training\n",
    "    if is_training:\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=NUM_WORKERS)\n",
    "    \n",
    "    # Normalize\n",
    "    dataset = dataset.map(normalize_for_mobilenet, num_parallel_calls=NUM_WORKERS)\n",
    "    \n",
    "    # Small prefetch for CPU\n",
    "    dataset = dataset.prefetch(buffer_size=PREFETCH_BUFFER)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# =============================================================\n",
    "# ðŸ“Š PROGRESS CALLBACK\n",
    "# =============================================================\n",
    "class CPUProgressCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Progress tracking optimized for CPU training\"\"\"\n",
    "    \n",
    "    def __init__(self, total_epochs, stage_name=\"Training\"):\n",
    "        super().__init__()\n",
    "        self.total_epochs = total_epochs\n",
    "        self.stage_name = stage_name\n",
    "        self.epoch_times = []\n",
    "        self.start_time = None\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time.time()\n",
    "        print(f\"\\nðŸš€ {self.stage_name} Started\")\n",
    "        print(f\"   Epochs: {self.total_epochs}\")\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start = time.time()\n",
    "        print(f\"\\nðŸ“ˆ Epoch {epoch+1}/{self.total_epochs}\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        \n",
    "        # Calculate ETA\n",
    "        avg_time = np.mean(self.epoch_times)\n",
    "        remaining = self.total_epochs - (epoch + 1)\n",
    "        eta_seconds = remaining * avg_time\n",
    "        eta = str(timedelta(seconds=int(eta_seconds)))\n",
    "        \n",
    "        # Progress\n",
    "        val_acc = logs.get('val_accuracy', 0)\n",
    "        val_loss = logs.get('val_loss', 0)\n",
    "        train_acc = logs.get('accuracy', 0)\n",
    "        \n",
    "        print(f\"   âœ… Complete: train_acc={train_acc:.4f}, val_acc={val_acc:.4f}, val_loss={val_loss:.4f}\")\n",
    "        print(f\"   â±ï¸ Time: {epoch_time:.1f}s | Avg: {avg_time:.1f}s | ETA: {eta}\")\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        total_time = time.time() - self.start_time\n",
    "        print(f\"\\nâœ… {self.stage_name} Complete!\")\n",
    "        print(f\"   Total time: {str(timedelta(seconds=int(total_time)))}\")\n",
    "        print(f\"   Avg epoch: {np.mean(self.epoch_times):.1f}s\")\n",
    "\n",
    "print(\"âœ… Data pipeline functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6b161",
   "metadata": {},
   "source": [
    "## ðŸŒ± Stage 2: PlantVillage Training (OPTIONAL)\n",
    "\n",
    "**âš ï¸ This stage takes 3-5 hours on CPU!**\n",
    "\n",
    "You can skip this and go directly to Stage 3 if:\n",
    "\n",
    "- You want faster training\n",
    "- You already have a Stage 2 checkpoint\n",
    "- You're okay with slightly lower accuracy\n",
    "\n",
    "**To skip:** Just run the cell that creates the Stage 2 model without training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b7684",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Download PlantVillage Dataset (Optional)\n",
    "\n",
    "If you don't have PlantVillage dataset locally, you can download it from Kaggle.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. Kaggle account\n",
    "2. Kaggle API key (`kaggle.json`)\n",
    "\n",
    "**To get kaggle.json:**\n",
    "\n",
    "1. Go to https://www.kaggle.com/settings\n",
    "2. Scroll to \"API\" section\n",
    "3. Click \"Create New Token\"\n",
    "4. Place `kaggle.json` in: `~/.kaggle/` (Linux/Mac) or `C:\\Users\\YourName\\.kaggle\\` (Windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36dc4a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ðŸ“¥ PLANTVILLAGE DATASET CHECK\n",
      "======================================================================\n",
      "âœ… PlantVillage dataset already exists!\n",
      "ðŸ“¥ Downloading PlantVillage dataset from Kaggle...\n",
      "   This may take 5-10 minutes (~1-2 GB)\n",
      "\n",
      "âŒ Kaggle credentials not found!\n",
      "   Expected: C:\\Users\\asus\\.kaggle\\kaggle.json\n",
      "\n",
      "ðŸ“ To set up:\n",
      "   1. Go to https://www.kaggle.com/settings\n",
      "   2. Scroll to 'API' section\n",
      "   3. Click 'Create New Token'\n",
      "   4. Place kaggle.json in: C:\\Users\\asus\\.kaggle\n",
      "\n",
      "â© Skipping download - you can manually download from:\n",
      "   https://www.kaggle.com/datasets/arjuntejaswi/plant-village\n",
      "\n",
      "â© You can skip Stage 2 or download manually\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ“¥ DOWNLOAD PLANTVILLAGE DATASET FROM KAGGLE\n",
    "# =============================================================\n",
    "\n",
    "import zipfile\n",
    "import subprocess\n",
    "\n",
    "def download_plantvillage():\n",
    "    \"\"\"Download PlantVillage dataset from Kaggle with progress tracking\"\"\"\n",
    "    \n",
    "    # Check if already exists\n",
    "    if PLANTVILLAGE_PATH.exists():\n",
    "        # Check if it has data\n",
    "        try:\n",
    "            subdirs = [d for d in PLANTVILLAGE_PATH.iterdir() if d.is_dir()]\n",
    "            if len(subdirs) > 10:  # PlantVillage has ~38 classes\n",
    "                print(\"âœ… PlantVillage dataset already exists!\")\n",
    "                print(f\"   Location: {PLANTVILLAGE_PATH.relative_to(NOTEBOOK_DIR)}\")\n",
    "                print(f\"   Classes found: {len(subdirs)}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"âš ï¸ PlantVillage folder exists but seems incomplete\")\n",
    "                print(\"   Will re-download...\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"ðŸ“¥ Downloading PlantVillage dataset from Kaggle...\")\n",
    "    print(\"   This may take 5-10 minutes (~1-2 GB)\")\n",
    "    \n",
    "    # Check for Kaggle credentials\n",
    "    kaggle_config = Path.home() / '.kaggle' / 'kaggle.json'\n",
    "    if not kaggle_config.exists():\n",
    "        print(\"\\nâŒ Kaggle credentials not found!\")\n",
    "        print(f\"   Expected: {kaggle_config}\")\n",
    "        print(\"\\nðŸ“ To set up:\")\n",
    "        print(\"   1. Go to https://www.kaggle.com/settings\")\n",
    "        print(\"   2. Scroll to 'API' section\")\n",
    "        print(\"   3. Click 'Create New Token'\")\n",
    "        print(f\"   4. Place kaggle.json in: {kaggle_config.parent}\")\n",
    "        print(\"\\nâ© Skipping download - you can manually download from:\")\n",
    "        print(\"   https://www.kaggle.com/datasets/arjuntejaswi/plant-village\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Install kaggle package if not available\n",
    "        try:\n",
    "            import kaggle\n",
    "        except ImportError:\n",
    "            print(\"ðŸ“¦ Installing kaggle package...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"kaggle\"])\n",
    "            import kaggle\n",
    "        \n",
    "        # Create parent directory\n",
    "        PLANTVILLAGE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Download dataset\n",
    "        print(\"\\nâ¬‡ï¸ Downloading from Kaggle...\")\n",
    "        download_path = PLANTVILLAGE_PATH.parent\n",
    "        \n",
    "        # Download using kaggle API\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        \n",
    "        print(\"   Downloading arjuntejaswi/plant-village...\")\n",
    "        api.dataset_download_files(\n",
    "            'arjuntejaswi/plant-village',\n",
    "            path=str(download_path),\n",
    "            unzip=False\n",
    "        )\n",
    "        \n",
    "        # Find downloaded zip file\n",
    "        zip_file = download_path / 'plant-village.zip'\n",
    "        if not zip_file.exists():\n",
    "            # Try alternative name\n",
    "            zip_files = list(download_path.glob('*.zip'))\n",
    "            if zip_files:\n",
    "                zip_file = zip_files[0]\n",
    "            else:\n",
    "                print(\"âŒ Downloaded file not found!\")\n",
    "                return False\n",
    "        \n",
    "        print(f\"\\nðŸ“¦ Extracting {zip_file.name}...\")\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            # Extract all files\n",
    "            zip_ref.extractall(download_path)\n",
    "        \n",
    "        # Find extracted folder (might be nested)\n",
    "        possible_dirs = [\n",
    "            download_path / 'PlantVillage',\n",
    "            download_path / 'plant-village',\n",
    "            download_path / 'Plant_Village',\n",
    "        ]\n",
    "        \n",
    "        extracted_dir = None\n",
    "        for d in possible_dirs:\n",
    "            if d.exists():\n",
    "                extracted_dir = d\n",
    "                break\n",
    "        \n",
    "        # If not found, look for any directory with many subdirectories\n",
    "        if not extracted_dir:\n",
    "            for d in download_path.iterdir():\n",
    "                if d.is_dir() and d.name not in ['unified_nutrient_dataset', 'local_training']:\n",
    "                    subdirs = [x for x in d.iterdir() if x.is_dir()]\n",
    "                    if len(subdirs) > 10:\n",
    "                        extracted_dir = d\n",
    "                        break\n",
    "        \n",
    "        if extracted_dir and extracted_dir != PLANTVILLAGE_PATH:\n",
    "            # Rename to expected path\n",
    "            if PLANTVILLAGE_PATH.exists():\n",
    "                shutil.rmtree(PLANTVILLAGE_PATH)\n",
    "            extracted_dir.rename(PLANTVILLAGE_PATH)\n",
    "            print(f\"âœ… Renamed to: {PLANTVILLAGE_PATH.relative_to(NOTEBOOK_DIR)}\")\n",
    "        \n",
    "        # Clean up zip file\n",
    "        zip_file.unlink()\n",
    "        print(\"ðŸ—‘ï¸ Cleaned up zip file\")\n",
    "        \n",
    "        # Verify extraction\n",
    "        if PLANTVILLAGE_PATH.exists():\n",
    "            num_classes = len([d for d in PLANTVILLAGE_PATH.iterdir() if d.is_dir()])\n",
    "            print(f\"\\nâœ… PlantVillage dataset ready!\")\n",
    "            print(f\"   Location: {PLANTVILLAGE_PATH.relative_to(NOTEBOOK_DIR)}\")\n",
    "            print(f\"   Classes: {num_classes}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"\\nâŒ Extraction failed - path not found\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Download failed: {e}\")\n",
    "        print(\"\\nðŸ’¡ You can manually download from:\")\n",
    "        print(\"   https://www.kaggle.com/datasets/arjuntejaswi/plant-village\")\n",
    "        print(f\"   Then extract to: {PLANTVILLAGE_PATH.relative_to(NOTEBOOK_DIR)}\")\n",
    "        return False\n",
    "\n",
    "# Run download\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“¥ PLANTVILLAGE DATASET CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "download_success = download_plantvillage()\n",
    "\n",
    "if download_success:\n",
    "    print(\"\\nâœ… Ready for Stage 2 training!\")\n",
    "else:\n",
    "    print(\"\\nâ© You can skip Stage 2 or download manually\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ad68675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PlantVillage dataset found\n",
      "\n",
      "ðŸ¤” Do you want to train Stage 2?\n",
      "   Set SKIP_STAGE2 = True to skip (faster)\n",
      "   Set SKIP_STAGE2 = False to train (better accuracy)\n",
      "\n",
      "â±ï¸ Stage 2 will take approximately 3-5 hours\n",
      "   Consider running overnight!\n"
     ]
    }
   ],
   "source": [
    "# Check if PlantVillage path exists\n",
    "if not os.path.exists(PLANTVILLAGE_PATH):\n",
    "    print(\"âš ï¸ PlantVillage dataset not found\")\n",
    "    print(f\"   Path: {PLANTVILLAGE_PATH}\")\n",
    "    print(\"\\nðŸ’¡ Options:\")\n",
    "    print(\"   1. Skip Stage 2 (go to Stage 3)\")\n",
    "    print(\"   2. Download PlantVillage and update path\")\n",
    "    SKIP_STAGE2 = True\n",
    "else:\n",
    "    print(\"âœ… PlantVillage dataset found\")\n",
    "    print(\"\\nðŸ¤” Do you want to train Stage 2?\")\n",
    "    print(\"   Set SKIP_STAGE2 = True to skip (faster)\")\n",
    "    print(\"   Set SKIP_STAGE2 = False to train (better accuracy)\")\n",
    "    SKIP_STAGE2 = False  # Change to True to skip\n",
    "\n",
    "if SKIP_STAGE2:\n",
    "    print(\"\\nâ© Skipping Stage 2 (PlantVillage training)\")\n",
    "    print(\"   Will create model with ImageNet weights only\")\n",
    "else:\n",
    "    print(\"\\nâ±ï¸ Stage 2 will take approximately 3-5 hours\")\n",
    "    print(\"   Consider running overnight!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82aa852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Creating PlantVillage datasets...\n",
      "ðŸ“¦ Loading training data from PlantVillage...\n",
      "Found 41276 files belonging to 16 classes.\n",
      "Using 33021 files for training.\n",
      "ðŸ“¦ Loading validation data from PlantVillage...\n",
      "Found 41276 files belonging to 16 classes.\n",
      "Using 8255 files for validation.\n",
      "\n",
      "âœ… PlantVillage Datasets Ready\n",
      "   Classes: 16\n",
      "   Training: 4128 batches Ã— 8\n",
      "   Validation: 1032 batches Ã— 8\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ“¦ CREATE PLANTVILLAGE DATASETS (if not skipping)\n",
    "# =============================================================\n",
    "\n",
    "if not SKIP_STAGE2:\n",
    "    print(\"ðŸ“¦ Creating PlantVillage datasets...\")\n",
    "    \n",
    "    train_plantvillage_raw = create_dataset(\n",
    "        PLANTVILLAGE_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "        validation_split=0.2, subset='training'\n",
    "    )\n",
    "    val_plantvillage_raw = create_dataset(\n",
    "        PLANTVILLAGE_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "        validation_split=0.2, subset='validation'\n",
    "    )\n",
    "    \n",
    "    # Build pipelines\n",
    "    train_plantvillage = build_pipeline(train_plantvillage_raw, is_training=True)\n",
    "    val_plantvillage = build_pipeline(val_plantvillage_raw, is_training=False)\n",
    "    \n",
    "    num_plantvillage_classes = len(train_plantvillage_raw.class_names)\n",
    "    train_batches = tf.data.experimental.cardinality(train_plantvillage_raw).numpy()\n",
    "    val_batches = tf.data.experimental.cardinality(val_plantvillage_raw).numpy()\n",
    "    \n",
    "    print(f\"\\nâœ… PlantVillage Datasets Ready\")\n",
    "    print(f\"   Classes: {num_plantvillage_classes}\")\n",
    "    print(f\"   Training: {train_batches} batches Ã— {BATCH_SIZE}\")\n",
    "    print(f\"   Validation: {val_batches} batches Ã— {BATCH_SIZE}\")\n",
    "else:\n",
    "    print(\"â© Skipped PlantVillage dataset creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c112e2",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Build Stage 2 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a634fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—ï¸ Creating new Stage 2 model...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "\n",
      "ðŸ“Š Stage 2 Model Ready\n",
      "   Classes: 16\n",
      "   Trainable params: 332,560\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ—ï¸ CREATE MODEL ARCHITECTURE\n",
    "# =============================================================\n",
    "\n",
    "def create_model(num_classes, input_shape=(224, 224, 3), freeze_base=True):\n",
    "    \"\"\"Create MobileNetV2-based model\"\"\"\n",
    "    \n",
    "    # Load MobileNetV2 with ImageNet weights\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = not freeze_base\n",
    "    \n",
    "    # Build classification head\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "        tf.keras.layers.Dense(\n",
    "            256,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE * 0.8),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "if not SKIP_STAGE2:\n",
    "    # Check for existing checkpoint\n",
    "    stage2_checkpoint = os.path.join(OUTPUT_DIR, 'stage2_plantvillage_best.keras')\n",
    "    \n",
    "    if os.path.exists(stage2_checkpoint):\n",
    "        print(\"ðŸ”„ Found existing Stage 2 checkpoint\")\n",
    "        try:\n",
    "            model_stage2 = tf.keras.models.load_model(stage2_checkpoint)\n",
    "            print(\"âœ… Loaded checkpoint\")\n",
    "        except:\n",
    "            print(\"âš ï¸ Could not load checkpoint, creating new model\")\n",
    "            model_stage2, base_stage2 = create_model(num_plantvillage_classes)\n",
    "    else:\n",
    "        print(\"ðŸ—ï¸ Creating new Stage 2 model...\")\n",
    "        model_stage2, base_stage2 = create_model(num_plantvillage_classes)\n",
    "    \n",
    "    # Compile\n",
    "    model_stage2.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_STAGE2),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Stage 2 Model Ready\")\n",
    "    print(f\"   Classes: {num_plantvillage_classes}\")\n",
    "    print(f\"   Trainable params: {sum([tf.keras.backend.count_params(w) for w in model_stage2.trainable_weights]):,}\")\n",
    "else:\n",
    "    print(\"â© Skipped Stage 2 model creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da550156",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Train Stage 2 (PlantVillage)\n",
    "\n",
    "**âš ï¸ This will take 3-5 hours!** Consider running overnight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3adc445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Stage 2 Training\n",
      "â±ï¸ Expected time: ~200 - 300 minutes\n",
      "\n",
      "ðŸ’¡ You can stop anytime (Ctrl+C) - checkpoint will be saved!\n",
      "\n",
      "\n",
      "ðŸš€ Stage 2: PlantVillage Started\n",
      "   Epochs: 5\n",
      "\n",
      "ðŸ“ˆ Epoch 1/5\n",
      "Epoch 1/5\n",
      "   âœ… Complete: train_acc=0.4683, val_acc=0.4778, val_loss=1.1670\n",
      "   â±ï¸ Time: 732.3s | Avg: 732.3s | ETA: 0:48:49\n",
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.47777, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\stage2_plantvillage_best.keras\n",
      "\n",
      "Epoch 1: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\stage2_plantvillage_best.keras\n",
      "4128/4128 - 733s - 178ms/step - accuracy: 0.4683 - loss: 1.3725 - val_accuracy: 0.4778 - val_loss: 1.1670 - learning_rate: 0.0010\n",
      "\n",
      "ðŸ“ˆ Epoch 2/5\n",
      "Epoch 2/5\n",
      "   âœ… Complete: train_acc=0.4845, val_acc=0.4787, val_loss=1.1309\n",
      "   â±ï¸ Time: 662.2s | Avg: 697.3s | ETA: 0:34:51\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.47777 to 0.47874, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\stage2_plantvillage_best.keras\n",
      "\n",
      "Epoch 2: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\stage2_plantvillage_best.keras\n",
      "4128/4128 - 663s - 161ms/step - accuracy: 0.4845 - loss: 1.2335 - val_accuracy: 0.4787 - val_loss: 1.1309 - learning_rate: 0.0010\n",
      "\n",
      "ðŸ“ˆ Epoch 3/5\n",
      "Epoch 3/5\n",
      "   âœ… Complete: train_acc=0.4903, val_acc=0.4690, val_loss=1.1355\n",
      "   â±ï¸ Time: 660.3s | Avg: 685.0s | ETA: 0:22:49\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.47874\n",
      "4128/4128 - 660s - 160ms/step - accuracy: 0.4903 - loss: 1.2220 - val_accuracy: 0.4690 - val_loss: 1.1355 - learning_rate: 0.0010\n",
      "\n",
      "ðŸ“ˆ Epoch 4/5\n",
      "Epoch 4/5\n",
      "   âœ… Complete: train_acc=0.4842, val_acc=0.4724, val_loss=1.0957\n",
      "   â±ï¸ Time: 664.9s | Avg: 679.9s | ETA: 0:11:19\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.47874\n",
      "4128/4128 - 665s - 161ms/step - accuracy: 0.4842 - loss: 1.2138 - val_accuracy: 0.4724 - val_loss: 1.0957 - learning_rate: 0.0010\n",
      "\n",
      "ðŸ“ˆ Epoch 5/5\n",
      "Epoch 5/5\n",
      "   âœ… Complete: train_acc=0.4858, val_acc=0.4714, val_loss=1.1169\n",
      "   â±ï¸ Time: 653.4s | Avg: 674.6s | ETA: 0:00:00\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.47874\n",
      "4128/4128 - 653s - 158ms/step - accuracy: 0.4858 - loss: 1.2018 - val_accuracy: 0.4714 - val_loss: 1.1169 - learning_rate: 0.0010\n",
      "\n",
      "âœ… Stage 2: PlantVillage Complete!\n",
      "   Total time: 0:56:14\n",
      "   Avg epoch: 674.6s\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "âœ… Stage 2 Training Complete!\n",
      "   Best val accuracy: 0.4787\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_STAGE2:\n",
    "    print(\"ðŸš€ Starting Stage 2 Training\")\n",
    "    print(f\"â±ï¸ Expected time: ~{PLANTVILLAGE_EPOCHS * 40} - {PLANTVILLAGE_EPOCHS * 60} minutes\")\n",
    "    print(\"\\nðŸ’¡ You can stop anytime (Ctrl+C) - checkpoint will be saved!\\n\")\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks_stage2 = [\n",
    "        CPUProgressCallback(PLANTVILLAGE_EPOCHS, stage_name=\"Stage 2: PlantVillage\"),\n",
    "        \n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            os.path.join(OUTPUT_DIR, 'stage2_plantvillage_best.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    history_stage2 = model_stage2.fit(\n",
    "        train_plantvillage,\n",
    "        validation_data=val_plantvillage,\n",
    "        epochs=PLANTVILLAGE_EPOCHS,\n",
    "        callbacks=callbacks_stage2,\n",
    "        verbose=2  # Progress per epoch\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Stage 2 Training Complete!\")\n",
    "    print(f\"   Best val accuracy: {max(history_stage2.history['val_accuracy']):.4f}\")\n",
    "else:\n",
    "    print(\"â© Skipped Stage 2 training\")\n",
    "    print(\"   Will use ImageNet weights for Stage 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81751b7",
   "metadata": {},
   "source": [
    "## ðŸ”„ Stage 3: Build Unified Nutrient Dataset\n",
    "\n",
    "This combines all crop datasets into one unified structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c5ed2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—ï¸ Building unified nutrient dataset...\n",
      "ðŸ“‚ Combining crop datasets...\n",
      "\n",
      "   ðŸŒ¾ RICE: Processing...\n",
      "      âœ… 3 classes\n",
      "   ðŸŒ¾ WHEAT: Processing...\n",
      "      âœ… 2 classes\n",
      "   ðŸŒ¾ TOMATO: Processing...\n",
      "      âœ… 7 classes\n",
      "   ðŸŒ¾ MAIZE: Processing...\n",
      "      âœ… 6 classes\n",
      "\n",
      "âœ… Unified Dataset Ready\n",
      "   Total classes: 18\n",
      "   Classes: maize_ALL Present, maize_ALLAB, maize_KAB, maize_NAB, maize_PAB, maize_ZNAB...\n",
      "   Location: E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_dataset\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ—ï¸ BUILD UNIFIED DATASET\n",
    "# =============================================================\n",
    "\n",
    "print(\"ðŸ—ï¸ Building unified nutrient dataset...\")\n",
    "\n",
    "UNIFIED_DATASET_PATH = OUTPUT_DIR / 'unified_nutrient_dataset'\n",
    "\n",
    "def detect_nutrient_classes(crop_path):\n",
    "    \"\"\"Detect nutrient classes from folder structure\"\"\"\n",
    "    nutrient_classes = {}\n",
    "    \n",
    "    if not crop_path.exists():\n",
    "        return nutrient_classes\n",
    "    \n",
    "    subfolders = [d for d in crop_path.iterdir() if d.is_dir()]\n",
    "    \n",
    "    # Check for train/test/val splits\n",
    "    split_keywords = {'train', 'test', 'val', 'validation'}\n",
    "    has_splits = any(f.name.lower() in split_keywords for f in subfolders)\n",
    "    \n",
    "    if has_splits:\n",
    "        # Has train/test/val structure\n",
    "        for split in subfolders:\n",
    "            if split.name.lower() in split_keywords:\n",
    "                split_path = split\n",
    "                for cls in split_path.iterdir():\n",
    "                    if cls.is_dir():\n",
    "                        files = list(cls.iterdir())[:10]\n",
    "                        has_images = any(f.suffix.lower() in ['.jpg', '.jpeg', '.png'] for f in files)\n",
    "                        if has_images:\n",
    "                            if cls.name not in nutrient_classes:\n",
    "                                nutrient_classes[cls.name] = []\n",
    "                            nutrient_classes[cls.name].append(cls)\n",
    "    else:\n",
    "        # Flat structure\n",
    "        for cls in subfolders:\n",
    "            files = list(cls.iterdir())[:10]\n",
    "            has_images = any(f.suffix.lower() in ['.jpg', '.jpeg', '.png'] for f in files)\n",
    "            if has_images:\n",
    "                nutrient_classes[cls.name] = [cls]\n",
    "    \n",
    "    return nutrient_classes\n",
    "\n",
    "# Build unified dataset\n",
    "if UNIFIED_DATASET_PATH.exists():\n",
    "    existing = [d for d in UNIFIED_DATASET_PATH.iterdir() if d.is_dir()]\n",
    "    if len(existing) > 5:\n",
    "        print(f\"âœ… Unified dataset exists with {len(existing)} classes\")\n",
    "        unified_classes = [d.name for d in existing]\n",
    "        needs_rebuild = False\n",
    "    else:\n",
    "        print(\"âš ï¸ Incomplete dataset, rebuilding...\")\n",
    "        shutil.rmtree(UNIFIED_DATASET_PATH)\n",
    "        needs_rebuild = True\n",
    "else:\n",
    "    needs_rebuild = True\n",
    "\n",
    "if needs_rebuild:\n",
    "    UNIFIED_DATASET_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    unified_classes = []\n",
    "    \n",
    "    print(\"ðŸ“‚ Combining crop datasets...\\n\")\n",
    "    \n",
    "    for crop, folder_name in CROP_DATASETS.items():\n",
    "        crop_path = NUTRIENT_DATASETS_ROOT / folder_name\n",
    "        \n",
    "        if not crop_path.exists():\n",
    "            print(f\"   âš ï¸ {crop.upper()}: Not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   ðŸŒ¾ {crop.upper()}: Processing...\")\n",
    "        \n",
    "        nutrient_classes = detect_nutrient_classes(crop_path)\n",
    "        \n",
    "        for cls_name, src_paths in nutrient_classes.items():\n",
    "            clean_name = cls_name.replace(f\"{crop}_\", \"\").replace(f\"{crop}__\", \"\")\n",
    "            unified_class = f\"{crop}_{clean_name}\"\n",
    "            \n",
    "            dst_dir = UNIFIED_DATASET_PATH / unified_class\n",
    "            dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Copy images\n",
    "            total = 0\n",
    "            for src_dir in src_paths:\n",
    "                src_name = src_dir.parent.name\n",
    "                for img_file in src_dir.iterdir():\n",
    "                    if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                        dst_file = dst_dir / f\"{src_name}_{img_file.name}\"\n",
    "                        if not dst_file.exists():\n",
    "                            shutil.copy2(img_file, dst_file)\n",
    "                            total += 1\n",
    "            \n",
    "            if total > 0 and unified_class not in unified_classes:\n",
    "                unified_classes.append(unified_class)\n",
    "        \n",
    "        crop_classes = [c for c in unified_classes if c.startswith(f\"{crop}_\")]\n",
    "        print(f\"      âœ… {len(crop_classes)} classes\")\n",
    "\n",
    "class_names = sorted(unified_classes)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\nâœ… Unified Dataset Ready\")\n",
    "print(f\"   Total classes: {num_classes}\")\n",
    "print(f\"   Classes: {', '.join(class_names[:6])}...\")\n",
    "print(f\"   Location: {UNIFIED_DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# âš–ï¸ BALANCE DATASET - FIX MODEL BIAS\n",
    "# =============================================================\n",
    "# Ensures equal representation of all classes to prevent bias\n",
    "\n",
    "import random\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from collections import Counter\n",
    "\n",
    "def augment_image_pil(img_path, save_path, augmentation_idx):\n",
    "    \"\"\"\n",
    "    Create augmented version of image using PIL\n",
    "    Lighter augmentation than training pipeline (preserves image identity)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        # Different augmentation based on index\n",
    "        if augmentation_idx % 5 == 0:\n",
    "            # Horizontal flip\n",
    "            img = ImageOps.mirror(img)\n",
    "        elif augmentation_idx % 5 == 1:\n",
    "            # Brightness adjustment\n",
    "            enhancer = ImageEnhance.Brightness(img)\n",
    "            img = enhancer.enhance(random.uniform(0.85, 1.15))\n",
    "        elif augmentation_idx % 5 == 2:\n",
    "            # Contrast adjustment\n",
    "            enhancer = ImageEnhance.Contrast(img)\n",
    "            img = enhancer.enhance(random.uniform(0.85, 1.15))\n",
    "        elif augmentation_idx % 5 == 3:\n",
    "            # Color adjustment\n",
    "            enhancer = ImageEnhance.Color(img)\n",
    "            img = enhancer.enhance(random.uniform(0.9, 1.1))\n",
    "        else:\n",
    "            # Sharpness adjustment\n",
    "            enhancer = ImageEnhance.Sharpness(img)\n",
    "            img = enhancer.enhance(random.uniform(0.9, 1.1))\n",
    "        \n",
    "        img.save(save_path, quality=95)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"      âš ï¸ Augmentation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def balance_dataset(dataset_path, target_images_per_class=None, strategy='hybrid'):\n",
    "    \"\"\"\n",
    "    Balance dataset to prevent model bias\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to unified dataset\n",
    "        target_images_per_class: Target number of images per class (None = use median)\n",
    "        strategy: 'undersample', 'oversample', or 'hybrid'\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with balancing statistics\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âš–ï¸ BALANCING DATASET TO PREVENT BIAS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Count images per class\n",
    "    class_counts = {}\n",
    "    for class_name in dataset_path.iterdir():\n",
    "        if not class_name.is_dir():\n",
    "            continue\n",
    "        \n",
    "        images = [f for f in class_name.iterdir() \n",
    "                  if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "        class_counts[class_name.name] = len(images)\n",
    "    \n",
    "    if not class_counts:\n",
    "        print(\"âŒ No classes found!\")\n",
    "        return {}\n",
    "    \n",
    "    # Calculate statistics\n",
    "    min_count = min(class_counts.values())\n",
    "    max_count = max(class_counts.values())\n",
    "    median_count = sorted(class_counts.values())[len(class_counts) // 2]\n",
    "    mean_count = sum(class_counts.values()) // len(class_counts)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Current Distribution:\")\n",
    "    print(f\"   Min: {min_count} images\")\n",
    "    print(f\"   Max: {max_count} images\")\n",
    "    print(f\"   Median: {median_count} images\")\n",
    "    print(f\"   Mean: {mean_count} images\")\n",
    "    print(f\"   Imbalance ratio: {min_count/max_count:.2f}\")\n",
    "    \n",
    "    # Determine target\n",
    "    if target_images_per_class is None:\n",
    "        if strategy == 'undersample':\n",
    "            target = min_count\n",
    "        elif strategy == 'oversample':\n",
    "            target = max_count\n",
    "        else:  # hybrid\n",
    "            # Use median or mean, whichever is more balanced\n",
    "            target = median_count if median_count > mean_count * 0.8 else mean_count\n",
    "    else:\n",
    "        target = target_images_per_class\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Target: {target} images per class\")\n",
    "    print(f\"   Strategy: {strategy}\")\n",
    "    \n",
    "    # Balance each class\n",
    "    stats = {\n",
    "        'original': {},\n",
    "        'final': {},\n",
    "        'undersampled': [],\n",
    "        'oversampled': [],\n",
    "        'augmented_images': 0\n",
    "    }\n",
    "    \n",
    "    for class_name, current_count in class_counts.items():\n",
    "        class_path = dataset_path / class_name\n",
    "        images = [f for f in class_path.iterdir() \n",
    "                  if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "        \n",
    "        stats['original'][class_name] = current_count\n",
    "        \n",
    "        if current_count > target:\n",
    "            # Undersample: randomly remove excess images\n",
    "            excess = current_count - target\n",
    "            images_to_remove = random.sample(images, excess)\n",
    "            \n",
    "            for img_file in images_to_remove:\n",
    "                img_file.unlink()\n",
    "            \n",
    "            stats['final'][class_name] = target\n",
    "            stats['undersampled'].append(class_name)\n",
    "            \n",
    "        elif current_count < target:\n",
    "            # Oversample: augment existing images\n",
    "            deficit = target - current_count\n",
    "            \n",
    "            # Calculate how many augmentations per image\n",
    "            augmentations_needed = deficit\n",
    "            augmentation_idx = 0\n",
    "            \n",
    "            while augmentations_needed > 0:\n",
    "                # Pick a random source image\n",
    "                source_img = random.choice(images)\n",
    "                \n",
    "                # Create augmented filename\n",
    "                base_name = source_img.stem\n",
    "                ext = source_img.suffix\n",
    "                aug_name = f\"{base_name}_aug{augmentation_idx}{ext}\"\n",
    "                aug_path = class_path / aug_name\n",
    "                \n",
    "                # Skip if already exists\n",
    "                if aug_path.exists():\n",
    "                    augmentation_idx += 1\n",
    "                    continue\n",
    "                \n",
    "                # Augment and save\n",
    "                if augment_image_pil(source_img, aug_path, augmentation_idx):\n",
    "                    augmentations_needed -= 1\n",
    "                    stats['augmented_images'] += 1\n",
    "                \n",
    "                augmentation_idx += 1\n",
    "            \n",
    "            stats['final'][class_name] = target\n",
    "            stats['oversampled'].append(class_name)\n",
    "        else:\n",
    "            # Already balanced\n",
    "            stats['final'][class_name] = current_count\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nâœ… Balancing Complete!\")\n",
    "    print(f\"   Undersampled: {len(stats['undersampled'])} classes\")\n",
    "    print(f\"   Oversampled: {len(stats['oversampled'])} classes\")\n",
    "    print(f\"   Augmented images created: {stats['augmented_images']}\")\n",
    "    \n",
    "    # Verify balance\n",
    "    final_counts = stats['final'].values()\n",
    "    if len(set(final_counts)) == 1:\n",
    "        print(f\"\\nâœ… Perfect balance achieved!\")\n",
    "        print(f\"   All classes now have {target} images\")\n",
    "    else:\n",
    "        print(f\"\\nðŸ“Š Final distribution:\")\n",
    "        print(f\"   Min: {min(final_counts)} images\")\n",
    "        print(f\"   Max: {max(final_counts)} images\")\n",
    "        print(f\"   Balance ratio: {min(final_counts)/max(final_counts):.2f}\")\n",
    "    \n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run balancing\n",
    "print(\"ðŸ” Checking if dataset needs balancing...\")\n",
    "\n",
    "# Count current distribution\n",
    "current_counts = {}\n",
    "for class_dir in sorted(UNIFIED_DATASET_PATH.iterdir()):\n",
    "    if class_dir.is_dir():\n",
    "        num_images = len([f for f in class_dir.iterdir() \n",
    "                          if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])\n",
    "        current_counts[class_dir.name] = num_images\n",
    "\n",
    "if current_counts:\n",
    "    min_imgs = min(current_counts.values())\n",
    "    max_imgs = max(current_counts.values())\n",
    "    imbalance_ratio = min_imgs / max_imgs\n",
    "    \n",
    "    if imbalance_ratio < 0.7:  # More than 30% imbalance\n",
    "        print(f\"âš ï¸ Imbalance detected! Ratio: {imbalance_ratio:.2f}\")\n",
    "        print(f\"   This can cause bias (e.g., towards maize)\")\n",
    "        print(f\"\\nðŸ”§ Applying automatic balancing...\\n\")\n",
    "        \n",
    "        # Use hybrid strategy: balance to median\n",
    "        balance_stats = balance_dataset(\n",
    "            UNIFIED_DATASET_PATH,\n",
    "            target_images_per_class=None,  # Auto-determine from median\n",
    "            strategy='hybrid'\n",
    "        )\n",
    "        \n",
    "        print(\"ðŸ”„ Refreshing class information...\")\n",
    "        \n",
    "        # Update class_names and num_classes\n",
    "        unified_classes = sorted([d.name for d in UNIFIED_DATASET_PATH.iterdir() if d.is_dir()])\n",
    "        class_names = unified_classes\n",
    "        num_classes = len(class_names)\n",
    "        \n",
    "        print(f\"âœ… Updated: {num_classes} balanced classes\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âœ… Dataset is already balanced (ratio: {imbalance_ratio:.2f})\")\n",
    "        print(f\"   No balancing needed!\\n\")\n",
    "else:\n",
    "    print(\"âš ï¸ No classes found in unified dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd344f65",
   "metadata": {},
   "source": [
    "## âš–ï¸ Balance Dataset (Fix Model Bias)\n",
    "\n",
    "**Why Balance?**\n",
    "- Imbalanced datasets cause model bias (e.g., predicting maize for everything)\n",
    "- Equal representation ensures fair predictions across all crops\n",
    "\n",
    "**Strategies:**\n",
    "- **Undersample:** Remove excess images from majority classes (faster, data loss)\n",
    "- **Oversample:** Augment minority classes (more data, longer training)\n",
    "- **Hybrid:** Balance to median count (recommended)\n",
    "\n",
    "This will automatically detect imbalance and fix it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68789a96",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Create Unified Training Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce15b050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Creating unified nutrient datasets...\n",
      "ðŸ“¦ Loading training data from unified_nutrient_dataset...\n",
      "Found 19952 files belonging to 18 classes.\n",
      "Using 15962 files for training.\n",
      "ðŸ“¦ Loading validation data from unified_nutrient_dataset...\n",
      "Found 19952 files belonging to 18 classes.\n",
      "Using 3990 files for validation.\n",
      "\n",
      "âœ… Unified Datasets Ready\n",
      "   Classes: 18\n",
      "   Training: 1996 batches Ã— 8\n",
      "   Validation: 499 batches Ã— 8\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“¦ Creating unified nutrient datasets...\")\n",
    "\n",
    "train_nutrient_raw = create_dataset(\n",
    "    str(UNIFIED_DATASET_PATH), IMG_SIZE, BATCH_SIZE,\n",
    "    validation_split=0.2, subset='training'\n",
    " )\n",
    "val_nutrient_raw = create_dataset(\n",
    "    str(UNIFIED_DATASET_PATH), IMG_SIZE, BATCH_SIZE,\n",
    "    validation_split=0.2, subset='validation'\n",
    " )\n",
    "\n",
    "# Build pipelines\n",
    "train_nutrient = build_pipeline(train_nutrient_raw, is_training=True)\n",
    "val_nutrient = build_pipeline(val_nutrient_raw, is_training=False)\n",
    "\n",
    "train_batches = tf.data.experimental.cardinality(train_nutrient_raw).numpy()\n",
    "val_batches = tf.data.experimental.cardinality(val_nutrient_raw).numpy()\n",
    "\n",
    "print(f\"\\nâœ… Unified Datasets Ready\")\n",
    "print(f\"   Classes: {num_classes}\")\n",
    "print(f\"   Training: {train_batches} batches Ã— {BATCH_SIZE}\")\n",
    "print(f\"   Validation: {val_batches} batches Ã— {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fe9cfb",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Build Stage 3 Model (Unified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50625223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—ï¸ Creating Stage 3 unified model...\n",
      "   Using Stage 2 trained base\n",
      "\n",
      "ðŸ“Š Stage 3 Model Ready\n",
      "   Classes: 18\n",
      "   Trainable params: 499,602\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ”§ CREATE STAGE 3 MODEL\n",
    "# =============================================================\n",
    "\n",
    "print(\"ðŸ—ï¸ Creating Stage 3 unified model...\")\n",
    "\n",
    "# Check for checkpoint\n",
    "stage3_checkpoint = os.path.join(OUTPUT_DIR, 'unified_nutrient_best.keras')\n",
    "\n",
    "if os.path.exists(stage3_checkpoint):\n",
    "    print(\"ðŸ”„ Found existing Stage 3 checkpoint\")\n",
    "    try:\n",
    "        model_stage3 = tf.keras.models.load_model(stage3_checkpoint)\n",
    "        print(\"âœ… Loaded checkpoint\")\n",
    "    except:\n",
    "        print(\"âš ï¸ Could not load, creating new model\")\n",
    "        model_stage3 = None\n",
    "else:\n",
    "    model_stage3 = None\n",
    "\n",
    "if model_stage3 is None:\n",
    "    if not SKIP_STAGE2 and 'model_stage2' in locals():\n",
    "        # Use Stage 2 base\n",
    "        print(\"   Using Stage 2 trained base\")\n",
    "        base_model = model_stage2.layers[0]\n",
    "        base_model.trainable = False\n",
    "    else:\n",
    "        # Use ImageNet weights\n",
    "        print(\"   Using ImageNet pretrained base\")\n",
    "        base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet'\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    model_stage3 = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "        tf.keras.layers.Dense(\n",
    "            384,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-4)\n",
    "        ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE * 0.8),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')\n",
    "    ], name='unified_nutrient_model')\n",
    "\n",
    "# Compile\n",
    "model_stage3.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_STAGE3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š Stage 3 Model Ready\")\n",
    "print(f\"   Classes: {num_classes}\")\n",
    "print(f\"   Trainable params: {sum([tf.keras.backend.count_params(w) for w in model_stage3.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93717e6",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Train Stage 3 (Unified Nutrient Detection)\n",
    "\n",
    "**âš ï¸ This will take 5-8 hours on CPU!** Recommended to run overnight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "433d00c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Stage 3 Training (UNIFIED)\n",
      "â±ï¸ Expected time: ~400 - 600 minutes\n",
      "   That's approximately 6 - 10 hours\n",
      "\n",
      "ðŸ’¡ This is the main training - be patient!\n",
      "   You can stop anytime - checkpoint will be saved!\n",
      "\n",
      "\n",
      "ðŸš€ Stage 3: Unified Nutrients Started\n",
      "   Epochs: 10\n",
      "\n",
      "ðŸ“ˆ Epoch 1/10\n",
      "Epoch 1/10\n",
      "   âœ… Complete: train_acc=0.7783, val_acc=0.9008, val_loss=0.3663\n",
      "   â±ï¸ Time: 340.8s | Avg: 340.8s | ETA: 0:51:06\n",
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.90075, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "\n",
      "Epoch 1: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "1996/1996 - 341s - 171ms/step - accuracy: 0.7783 - loss: 0.8043 - top3_acc: 0.9350 - val_accuracy: 0.9008 - val_loss: 0.3663 - val_top3_acc: 0.9910 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 2/10\n",
      "Epoch 2/10\n",
      "   âœ… Complete: train_acc=0.8458, val_acc=0.9283, val_loss=0.2948\n",
      "   â±ï¸ Time: 331.7s | Avg: 336.2s | ETA: 0:44:49\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.90075 to 0.92832, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "\n",
      "Epoch 2: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "1996/1996 - 332s - 166ms/step - accuracy: 0.8458 - loss: 0.5173 - top3_acc: 0.9809 - val_accuracy: 0.9283 - val_loss: 0.2948 - val_top3_acc: 0.9947 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 3/10\n",
      "Epoch 3/10\n",
      "   âœ… Complete: train_acc=0.8586, val_acc=0.9278, val_loss=0.3009\n",
      "   â±ï¸ Time: 328.4s | Avg: 333.6s | ETA: 0:38:55\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.92832\n",
      "1996/1996 - 328s - 165ms/step - accuracy: 0.8586 - loss: 0.4918 - top3_acc: 0.9835 - val_accuracy: 0.9278 - val_loss: 0.3009 - val_top3_acc: 0.9935 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 4/10\n",
      "Epoch 4/10\n",
      "   âœ… Complete: train_acc=0.8724, val_acc=0.9311, val_loss=0.2872\n",
      "   â±ï¸ Time: 327.3s | Avg: 332.0s | ETA: 0:33:12\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.92832 to 0.93108, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "\n",
      "Epoch 4: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "1996/1996 - 328s - 164ms/step - accuracy: 0.8724 - loss: 0.4591 - top3_acc: 0.9848 - val_accuracy: 0.9311 - val_loss: 0.2872 - val_top3_acc: 0.9960 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 5/10\n",
      "Epoch 5/10\n",
      "   âœ… Complete: train_acc=0.8742, val_acc=0.9328, val_loss=0.2873\n",
      "   â±ï¸ Time: 329.7s | Avg: 331.6s | ETA: 0:27:37\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.93108 to 0.93283, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "\n",
      "Epoch 5: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "1996/1996 - 330s - 165ms/step - accuracy: 0.8742 - loss: 0.4416 - top3_acc: 0.9880 - val_accuracy: 0.9328 - val_loss: 0.2873 - val_top3_acc: 0.9952 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 6/10\n",
      "Epoch 6/10\n",
      "   âœ… Complete: train_acc=0.8859, val_acc=0.9461, val_loss=0.2512\n",
      "   â±ï¸ Time: 321.0s | Avg: 329.8s | ETA: 0:21:59\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.93283 to 0.94612, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "\n",
      "Epoch 6: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "1996/1996 - 321s - 161ms/step - accuracy: 0.8859 - loss: 0.4166 - top3_acc: 0.9888 - val_accuracy: 0.9461 - val_loss: 0.2512 - val_top3_acc: 0.9955 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 7/10\n",
      "Epoch 7/10\n",
      "   âœ… Complete: train_acc=0.8850, val_acc=0.9499, val_loss=0.2492\n",
      "   â±ï¸ Time: 298.9s | Avg: 325.4s | ETA: 0:16:16\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.94612 to 0.94987, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "\n",
      "Epoch 7: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "1996/1996 - 299s - 150ms/step - accuracy: 0.8850 - loss: 0.4181 - top3_acc: 0.9899 - val_accuracy: 0.9499 - val_loss: 0.2492 - val_top3_acc: 0.9947 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 8/10\n",
      "Epoch 8/10\n",
      "   âœ… Complete: train_acc=0.8896, val_acc=0.9491, val_loss=0.2454\n",
      "   â±ï¸ Time: 270.6s | Avg: 318.5s | ETA: 0:10:37\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.94987\n",
      "1996/1996 - 271s - 136ms/step - accuracy: 0.8896 - loss: 0.4045 - top3_acc: 0.9901 - val_accuracy: 0.9491 - val_loss: 0.2454 - val_top3_acc: 0.9960 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 9/10\n",
      "Epoch 9/10\n",
      "   âœ… Complete: train_acc=0.8909, val_acc=0.9569, val_loss=0.2340\n",
      "   â±ï¸ Time: 268.8s | Avg: 313.0s | ETA: 0:05:13\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.94987 to 0.95689, saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "\n",
      "Epoch 9: finished saving model to E:\\FasalVaidya\\unified_savedmodel_output\\unified_nutrient_best.keras\n",
      "1996/1996 - 269s - 135ms/step - accuracy: 0.8909 - loss: 0.4040 - top3_acc: 0.9904 - val_accuracy: 0.9569 - val_loss: 0.2340 - val_top3_acc: 0.9970 - learning_rate: 5.0000e-04\n",
      "\n",
      "ðŸ“ˆ Epoch 10/10\n",
      "Epoch 10/10\n",
      "   âœ… Complete: train_acc=0.8956, val_acc=0.9514, val_loss=0.2511\n",
      "   â±ï¸ Time: 265.3s | Avg: 308.2s | ETA: 0:00:00\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.95689\n",
      "1996/1996 - 265s - 133ms/step - accuracy: 0.8956 - loss: 0.3984 - top3_acc: 0.9904 - val_accuracy: 0.9514 - val_loss: 0.2511 - val_top3_acc: 0.9950 - learning_rate: 5.0000e-04\n",
      "\n",
      "âœ… Stage 3: Unified Nutrients Complete!\n",
      "   Total time: 0:51:24\n",
      "   Avg epoch: 308.2s\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ STAGE 3 TRAINING COMPLETE!\n",
      "======================================================================\n",
      "âœ… Best val accuracy: 0.9569\n",
      "âœ… Best top-3 accuracy: 0.9904\n",
      "ðŸ’¾ Model saved to: E:\\FasalVaidya\\unified_savedmodel_output\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Starting Stage 3 Training (UNIFIED)\")\n",
    "print(f\"â±ï¸ Expected time: ~{UNIFIED_EPOCHS * 40} - {UNIFIED_EPOCHS * 60} minutes\")\n",
    "print(f\"   That's approximately {(UNIFIED_EPOCHS * 40) // 60} - {(UNIFIED_EPOCHS * 60) // 60} hours\")\n",
    "print(\"\\nðŸ’¡ This is the main training - be patient!\")\n",
    "print(\"   You can stop anytime - checkpoint will be saved!\\n\")\n",
    "\n",
    "# Callbacks\n",
    "callbacks_stage3 = [\n",
    "    CPUProgressCallback(UNIFIED_EPOCHS, stage_name=\"Stage 3: Unified Nutrients\"),\n",
    "    \n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, 'unified_nutrient_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "history_stage3 = model_stage3.fit(\n",
    "    train_nutrient,\n",
    "    validation_data=val_nutrient,\n",
    "    epochs=UNIFIED_EPOCHS,\n",
    "    callbacks=callbacks_stage3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ STAGE 3 TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"âœ… Best val accuracy: {max(history_stage3.history['val_accuracy']):.4f}\")\n",
    "print(f\"âœ… Best top-3 accuracy: {max(history_stage3.history['top3_acc']):.4f}\")\n",
    "print(f\"ðŸ’¾ Model saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2788f02e",
   "metadata": {},
   "source": [
    "## ðŸ“Š Training Results Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efc218d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Training curves saved to: E:\\FasalVaidya\\unified_savedmodel_output\\training_history.png\n"
     ]
    }
   ],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_stage3.history['accuracy'], 'b-', label='Train', linewidth=2)\n",
    "axes[0].plot(history_stage3.history['val_accuracy'], 'r-', label='Validation', linewidth=2)\n",
    "axes[0].set_title('Training Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_stage3.history['loss'], 'b-', label='Train', linewidth=2)\n",
    "axes[1].plot(history_stage3.history['val_loss'], 'r-', label='Validation', linewidth=2)\n",
    "axes[1].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"ðŸ“Š Training curves saved to: {os.path.join(OUTPUT_DIR, 'training_history.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1656bd",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Export Model (SavedModel Format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "021ce66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Exporting model to SavedModel format...\n",
      "INFO:tensorflow:Assets written to: E:\\FasalVaidya\\unified_savedmodel_output\\unified_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\FasalVaidya\\unified_savedmodel_output\\unified_savedmodel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'E:\\FasalVaidya\\unified_savedmodel_output\\unified_savedmodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_162')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 18), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1524780244752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780243600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768602064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768601296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768595152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768595920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779833232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779830928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768600528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768594000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779839184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779834192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780637968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779830352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779837840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780639504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780632400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780642576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780631824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780633744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780633360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780641424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780640080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780632208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780640656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769771728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768793104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768786000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769783056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769781712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768797328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768795984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768785232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768787536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768798864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768800208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768794640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768788496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768784464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768795408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768793488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777384656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777373904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768795600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768799440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777379280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777369872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777381968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777385040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777381008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777374096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777381584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772809296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777375248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777380432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772807184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772808528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772806608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772798736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772813904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772811216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772799696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772802000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772807568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772802576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772810256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777509968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777505552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772813520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772811408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777507472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777516304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777509392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777505360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777516112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777510544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777184592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777175376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777173456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777186704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777178832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777184400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777181136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777182096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777188048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524745128464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777181328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772671312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524765456720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524777176912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772682256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772672848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772677648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772671888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772680336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772671504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772682640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772682448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772683600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772668048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772670928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772681872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780282128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772675920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772669392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780278864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780277712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780272336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780280400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780283088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768521488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768516304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768507280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768509008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768510352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768509200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768507088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768515920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768513232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768514960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768512272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768517456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768521296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768511888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768520336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768507664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780575120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780577040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768513616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780568976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780568400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780576272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780572432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780567248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780574736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780571856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780568592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780572240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780578384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780579920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768451536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768448848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768454800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768450960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768454416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768450000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768446352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768456336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768448656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768454032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768453456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768440976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780405520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768449232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768452688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780400912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780408976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780406288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780404752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780402448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780411088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780401680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780403408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780410320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780405712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780413584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780408208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780411664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780409168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780415696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780405904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768481232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768478928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768488720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768484304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768481616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768475472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768482384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768487376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768480080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524768484688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780449040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780444240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780440400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780442704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780442128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780434256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780448848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780436944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780434640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780438672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780445968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780704080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780441552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780448656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780703312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780709648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780706960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780706576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780703120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780702928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780703504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780700816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780711184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780704656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780706768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780707152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780701200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780701968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780711760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780701776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772614416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772603088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780708688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780701584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772617296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772611728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772603664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772614032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772609424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772605584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772617488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772615760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772614992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772612688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524772605776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769896784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769887760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769891408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769884496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769893136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769891216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769884304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769890448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769896208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769888912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769897744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769889296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769895440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769892560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769893904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780381008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780375248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524769883152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780378512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780374288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780368528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780373904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780370064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780369104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780372560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780376016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779799696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780371024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524780372752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779804112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779794704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779803728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779799504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524779802192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524786193296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524765455760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524765455568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524765456336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524765456144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524765457680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524765457104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1524765454992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "âœ… SavedModel exported to: E:\\FasalVaidya\\unified_savedmodel_output\\unified_savedmodel\n",
      "\n",
      "ðŸ“„ Files created:\n",
      "   â”œâ”€â”€ saved_model.pb\n",
      "   â”œâ”€â”€ variables/\n",
      "   â”œâ”€â”€ metadata.json\n",
      "   â””â”€â”€ labels.txt\n",
      "\n",
      "ðŸ“Š Total size: 22.8 MB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ’¾ EXPORT SAVEDMODEL FOR BACKEND\n",
    "# =============================================================\n",
    "\n",
    "print(\"ðŸ“¦ Exporting model to SavedModel format...\")\n",
    "\n",
    "savedmodel_path = OUTPUT_DIR / 'unified_savedmodel'\n",
    "\n",
    "# Remove old if exists\n",
    "if savedmodel_path.exists():\n",
    "    shutil.rmtree(savedmodel_path)\n",
    "\n",
    "# Export (Keras 3.x: use export() for SavedModel format)\n",
    "model_stage3.export(str(savedmodel_path))\n",
    "\n",
    "print(f\"âœ… SavedModel exported to: {savedmodel_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'model_name': 'FasalVaidya Unified Nutrient Model',\n",
    "    'version': '1.0.0-local',\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'num_classes': num_classes,\n",
    "    'class_names': class_names,\n",
    "    'crops': list(CROP_DATASETS.keys()),\n",
    "    'img_size': IMG_SIZE,\n",
    "    'trained_on': 'Local CPU',\n",
    "    'epochs': UNIFIED_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'best_val_accuracy': float(max(history_stage3.history['val_accuracy'])),\n",
    "    'best_top3_accuracy': float(max(history_stage3.history['top3_acc']))\n",
    "}\n",
    "\n",
    "with open(savedmodel_path / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "# Save class labels\n",
    "with open(savedmodel_path / 'labels.txt', 'w') as f:\n",
    "    f.write('\\n'.join(class_names))\n",
    "\n",
    "print(f\"\\nðŸ“„ Files created:\")\n",
    "print(f\"   â”œâ”€â”€ saved_model.pb\")\n",
    "print(f\"   â”œâ”€â”€ variables/\")\n",
    "print(f\"   â”œâ”€â”€ metadata.json\")\n",
    "print(f\"   â””â”€â”€ labels.txt\")\n",
    "\n",
    "# Calculate size\n",
    "total_size = sum(f.stat().st_size for f in savedmodel_path.rglob('*') if f.is_file()) / (1024 * 1024)\n",
    "print(f\"\\nðŸ“Š Total size: {total_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9cc8b333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output key: output_0\n",
      "Output shape: (8, 18)\n",
      "Sample output (first 3):\n",
      "[[1.29649256e-04 1.79378465e-02 1.49130425e-03 1.71315522e-04\n",
      "  9.69740927e-01 1.01742465e-02 1.55364796e-05 9.54057396e-05\n",
      "  5.03001793e-05 1.22727024e-05 1.28262946e-05 1.43606394e-06\n",
      "  3.12202392e-05 1.23309865e-05 1.85213539e-05 2.48700326e-06\n",
      "  2.30392961e-05 7.92945939e-05]\n",
      " [1.54816207e-05 9.98965979e-01 7.48446701e-06 7.40163500e-07\n",
      "  2.65506213e-04 7.37699273e-04 1.73631832e-07 8.82045583e-08\n",
      "  1.36681109e-07 1.10846145e-06 8.54278639e-08 6.60089938e-08\n",
      "  3.26175638e-07 4.32778933e-07 2.77202588e-07 1.14668225e-07\n",
      "  3.42393378e-06 9.62239255e-07]\n",
      " [7.26935547e-03 2.02925344e-06 9.87369716e-01 1.23597295e-06\n",
      "  5.58807340e-04 4.78734681e-03 1.42801559e-06 4.21444604e-08\n",
      "  1.52260654e-07 8.12735038e-07 8.29929775e-07 2.11230031e-06\n",
      "  1.06956782e-06 5.01006241e-07 9.56721237e-07 3.15459829e-07\n",
      "  1.44893852e-06 1.96648421e-06]]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# ðŸ§ª TEST EXPORTED MODEL OUTPUT (DETAILED)\n",
    "# =============================================================\n",
    "import numpy as np\n",
    "\n",
    "# Use TFSMLayer for inference from SavedModel (already loaded as inference_layer)\n",
    "try:\n",
    "    sample_batch = next(iter(val_nutrient))\n",
    "    images, labels = sample_batch\n",
    "    preds = inference_layer(images)\n",
    "    if isinstance(preds, dict):\n",
    "        # Try to extract the first tensor output from the dict\n",
    "        first_key = list(preds.keys())[0]\n",
    "        output = preds[first_key]\n",
    "        print(f\"Output key: {first_key}\")\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        print(f\"Sample output (first 3):\\n{output[:3]}\")\n",
    "    else:\n",
    "        print(f\"Output shape: {preds.shape}\")\n",
    "        print(f\"Sample output (first 3):\\n{preds[:3]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not run sample prediction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a551c",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Training Complete!\n",
    "\n",
    "### ðŸ“¦ Next Steps\n",
    "\n",
    "1. **Copy the SavedModel to your backend:**\n",
    "\n",
    "   ```bash\n",
    "   # Copy the entire folder\n",
    "   cp -r \"{OUTPUT_DIR}/unified_savedmodel\" \"backend/ml/models/\"\n",
    "   ```\n",
    "\n",
    "2. **Test the model:**\n",
    "\n",
    "   ```bash\n",
    "   cd backend\n",
    "   python test_unified.py\n",
    "   ```\n",
    "\n",
    "3. **Expected output:**\n",
    "   ```\n",
    "   N score: 75.3% (moderate deficiency)\n",
    "   P score: 18.2% (healthy)\n",
    "   K score: 6.5% (healthy)\n",
    "   Detected: rice_Nitrogen(N)\n",
    "   Confidence: 75.3%\n",
    "   ```\n",
    "\n",
    "### ðŸ“Š Model Info\n",
    "\n",
    "Your model is now ready for deployment! It supports:\n",
    "\n",
    "- ðŸŒ¾ **4 crops:** Rice, Wheat, Tomato, Maize\n",
    "- ðŸ”¬ **Multiple deficiencies:** N, P, K, and healthy classes\n",
    "- ðŸ“± **Real-time inference** on mobile and backend\n",
    "- ðŸŽ¯ **Expected accuracy:** 70-95% on deficient leaves\n",
    "\n",
    "### ðŸš€ Performance Notes\n",
    "\n",
    "This model was trained on CPU, which is slower but produces the same quality as GPU training. The final model will work just as well in production!\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FasalVaidya (.venv311)",
   "language": "python",
   "name": "fasalvaidya-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
