{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üì¶ **Step 1: Setup & GPU Check** { display-mode: \"form\" }\n",
    "#@markdown Run this cell first to check GPU and install dependencies\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "import zipfile\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Check GPU\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU devices: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"‚úÖ GPU enabled: {gpus[0].name}\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU found! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "print(f\"CPU cores: {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üì§ **Step 2: Upload Dataset** { display-mode: \"form\" }\n",
    "#@markdown Upload a ZIP file containing your dataset folders\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "# Setup directories\n",
    "BASE_DIR = Path(\"/content/ml_models\")\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOCAL_CACHE = BASE_DIR / \"combined_balanced_dataset\"\n",
    "OUTPUT_DIR = BASE_DIR\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üì§ UPLOAD YOUR DATASET ZIP FILE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\")\n",
    "print(\"Your ZIP should contain folders like:\")\n",
    "print(\"  üìÇ Bigger CoLeaf DATASET/CoLeaf DATASET/\")\n",
    "print(\"  üìÇ Propossed_Data/\")\n",
    "print(\"  üìÇ Nitrogen deficiency/\")\n",
    "print(\"  üìÇ ThorCam_semiFiltered/\")\n",
    "print(\"  üìÇ POTASSIUM DEFICIENCY/\")\n",
    "print(\"\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract uploaded ZIP\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"\\nüì¶ Extracting {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall(str(BASE_DIR))\n",
    "    os.remove(filename)\n",
    "    print(f\"‚úÖ Extracted to {BASE_DIR}\")\n",
    "\n",
    "# Show contents\n",
    "print(\"\\nüîç Extracted contents:\")\n",
    "for item in sorted(BASE_DIR.iterdir()):\n",
    "    if item.is_dir():\n",
    "        count = sum(1 for _ in item.rglob(\"*\") if _.is_file())\n",
    "        print(f\"   üìÇ {item.name}/  ({count} files)\")\n",
    "    else:\n",
    "        print(f\"   üìÑ {item.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ‚öôÔ∏è **Step 3: Configuration** { display-mode: \"form\" }\n",
    "#@markdown Configure training parameters\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Dataset paths\n",
    "DATA_SOURCES = [\n",
    "    BASE_DIR / \"Bigger CoLeaf DATASET\" / \"CoLeaf DATASET\",\n",
    "    BASE_DIR / \"Propossed_Data\" / \"Contrast_Stretching\",\n",
    "    BASE_DIR / \"Propossed_Data\" / \"Histogram_Equalization\",\n",
    "    BASE_DIR / \"Propossed_Data\" / \"Log_Transformation\",\n",
    "    BASE_DIR / \"Nitrogen deficiency\",\n",
    "    BASE_DIR / \"ThorCam_semiFiltered\",\n",
    "    BASE_DIR / \"POTASSIUM DEFICIENCY\",\n",
    "]\n",
    "\n",
    "# Class mapping\n",
    "CLASS_MAPPING = {\n",
    "    \"healthy\": \"healthy\", \"control\": \"healthy\", \"-C\": \"healthy\",\n",
    "    \"nitrogen-N\": \"nitrogen-N\", \"deficiency\": \"nitrogen-N\", \"N\": \"nitrogen-N\",\n",
    "    \"phosphorus-P\": \"phosphorus-P\", \"-P\": \"phosphorus-P\", \"-P50\": \"phosphorus-P\", \"P\": \"phosphorus-P\",\n",
    "    \"potasium-K\": \"potasium-K\", \"K\": \"potasium-K\",\n",
    "    \"boron-B\": \"boron-B\", \"calcium-Ca\": \"calcium-Ca\", \"iron-Fe\": \"iron-Fe\",\n",
    "    \"magnesium-Mg\": \"magnesium-Mg\", \"manganese-Mn\": \"manganese-Mn\",\n",
    "}\n",
    "\n",
    "TARGET_CLASSES = [\"healthy\", \"nitrogen-N\", \"phosphorus-P\", \"potasium-K\"]\n",
    "EXTRA_CLASSES = [\"boron-B\", \"calcium-Ca\", \"iron-Fe\", \"magnesium-Mg\", \"manganese-Mn\"]\n",
    "ALL_CLASSES = TARGET_CLASSES + EXTRA_CLASSES\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32  # Larger for GPU\n",
    "EPOCHS_PHASE1 = 30\n",
    "EPOCHS_PHASE2 = 25\n",
    "EPOCHS_PHASE3 = 20\n",
    "VALIDATION_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.10\n",
    "INITIAL_LR = 1e-3\n",
    "FINE_TUNE_LR = 1e-4\n",
    "LABEL_SMOOTHING = 0.1\n",
    "DROPOUT_RATE = 0.4\n",
    "EARLY_STOPPING_PATIENCE = 8\n",
    "TARGET_SAMPLES_PER_CLASS = 500\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Classes: {len(ALL_CLASSES)}\")\n",
    "print(f\"   Total epochs: {EPOCHS_PHASE1 + EPOCHS_PHASE2 + EPOCHS_PHASE3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98acc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üìÇ **Step 4: Combine & Balance Datasets** { display-mode: \"form\" }\n",
    "#@markdown Scan, combine, and balance all datasets\n",
    "\n",
    "def copy_file(args):\n",
    "    src, dest = args\n",
    "    try:\n",
    "        if not dest.exists():\n",
    "            shutil.copy2(src, dest)\n",
    "            return 1\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def collect_all_images():\n",
    "    print(\"üìÅ Scanning all datasets...\")\n",
    "    class_images = {cls: [] for cls in ALL_CLASSES}\n",
    "    \n",
    "    for dataset_path in DATA_SOURCES:\n",
    "        if not dataset_path.exists():\n",
    "            print(f\"   ‚ö†Ô∏è Not found: {dataset_path.name}\")\n",
    "            continue\n",
    "        \n",
    "        dataset_name = dataset_path.name\n",
    "        print(f\"   üìÇ Scanning {dataset_name}...\")\n",
    "        \n",
    "        if \"Nitrogen\" in dataset_name or \"nitrogen\" in dataset_name:\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                split_dir = dataset_path / split\n",
    "                if split_dir.exists():\n",
    "                    for class_dir in split_dir.iterdir():\n",
    "                        if class_dir.is_dir():\n",
    "                            std_class = CLASS_MAPPING.get(class_dir.name)\n",
    "                            if std_class and std_class in class_images:\n",
    "                                for img in class_dir.glob(\"*\"):\n",
    "                                    if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
    "                                        class_images[std_class].append(img)\n",
    "        elif \"ThorCam\" in dataset_name:\n",
    "            for class_dir in dataset_path.iterdir():\n",
    "                if class_dir.is_dir():\n",
    "                    std_class = CLASS_MAPPING.get(class_dir.name)\n",
    "                    if std_class and std_class in class_images:\n",
    "                        for img in class_dir.glob(\"*\"):\n",
    "                            if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".tif\"]:\n",
    "                                class_images[std_class].append(img)\n",
    "        elif \"POTASSIUM\" in dataset_name.upper():\n",
    "            for img in dataset_path.glob(\"*\"):\n",
    "                if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
    "                    class_images[\"potasium-K\"].append(img)\n",
    "        else:\n",
    "            for class_dir in dataset_path.iterdir():\n",
    "                if class_dir.is_dir():\n",
    "                    std_class = CLASS_MAPPING.get(class_dir.name, class_dir.name)\n",
    "                    if std_class and std_class in class_images:\n",
    "                        for img in class_dir.glob(\"*\"):\n",
    "                            if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
    "                                class_images[std_class].append(img)\n",
    "    return class_images\n",
    "\n",
    "def balance_classes(class_images):\n",
    "    print(f\"\\n‚öñÔ∏è Balancing classes (target: {TARGET_SAMPLES_PER_CLASS})...\")\n",
    "    balanced = {cls: list(imgs) for cls, imgs in class_images.items()}\n",
    "    \n",
    "    for cls in ALL_CLASSES:\n",
    "        current = len(balanced[cls])\n",
    "        if current == 0:\n",
    "            print(f\"   ‚ö†Ô∏è {cls}: No samples!\")\n",
    "            continue\n",
    "        if current < TARGET_SAMPLES_PER_CLASS:\n",
    "            needed = TARGET_SAMPLES_PER_CLASS - current\n",
    "            balanced[cls].extend(random.choices(balanced[cls], k=needed))\n",
    "            print(f\"   üìà {cls}: {current} ‚Üí {len(balanced[cls])}\")\n",
    "        elif current > TARGET_SAMPLES_PER_CLASS * 2:\n",
    "            balanced[cls] = random.sample(balanced[cls], TARGET_SAMPLES_PER_CLASS)\n",
    "            print(f\"   üìâ {cls}: {current} ‚Üí {len(balanced[cls])}\")\n",
    "        else:\n",
    "            print(f\"   ‚úì {cls}: {current}\")\n",
    "    return balanced\n",
    "\n",
    "# Run\n",
    "if LOCAL_CACHE.exists():\n",
    "    shutil.rmtree(LOCAL_CACHE)\n",
    "\n",
    "class_images = collect_all_images()\n",
    "\n",
    "print(\"\\nüìä Raw dataset statistics:\")\n",
    "total = sum(len(imgs) for imgs in class_images.values())\n",
    "for cls in ALL_CLASSES:\n",
    "    print(f\"   {cls:15s}: {len(class_images[cls]):5d}\")\n",
    "print(f\"   {'TOTAL':15s}: {total:5d}\")\n",
    "\n",
    "balanced_images = balance_classes(class_images)\n",
    "\n",
    "for cls in ALL_CLASSES:\n",
    "    (LOCAL_CACHE / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "copy_tasks = []\n",
    "for cls in ALL_CLASSES:\n",
    "    for i, src_path in enumerate(balanced_images[cls]):\n",
    "        suffix = src_path.suffix.lower()\n",
    "        if suffix not in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            suffix = \".jpg\"\n",
    "        dst_path = LOCAL_CACHE / cls / f\"{cls}_{i:05d}{suffix}\"\n",
    "        copy_tasks.append((src_path, dst_path))\n",
    "\n",
    "print(f\"\\nüìÅ Copying {len(copy_tasks)} files...\")\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    results = list(tqdm(executor.map(copy_file, copy_tasks), total=len(copy_tasks), desc=\"Copying\"))\n",
    "print(f\"‚úÖ Done! {sum(results)} files copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeab242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üîÄ **Step 5: Create Train/Val/Test Splits** { display-mode: \"form\" }\n",
    "\n",
    "print(\"üîÄ Creating train/val/test splits...\")\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(ALL_CLASSES)}\n",
    "\n",
    "for cls in ALL_CLASSES:\n",
    "    cls_dir = LOCAL_CACHE / cls\n",
    "    if not cls_dir.exists():\n",
    "        continue\n",
    "    for img_file in cls_dir.glob(\"*\"):\n",
    "        if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "            all_images.append(str(img_file))\n",
    "            all_labels.append(class_to_idx[cls])\n",
    "\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "train_val_imgs, test_imgs, train_val_labels, test_labels = train_test_split(\n",
    "    all_images, all_labels, test_size=TEST_SPLIT, stratify=all_labels, random_state=42\n",
    ")\n",
    "\n",
    "val_ratio = VALIDATION_SPLIT / (1 - TEST_SPLIT)\n",
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(\n",
    "    train_val_imgs, train_val_labels, test_size=val_ratio, stratify=train_val_labels, random_state=42\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(ALL_CLASSES)\n",
    "print(f\"   ‚úÖ Train: {len(train_imgs)} images\")\n",
    "print(f\"   ‚úÖ Val:   {len(val_imgs)} images\")\n",
    "print(f\"   ‚úÖ Test:  {len(test_imgs)} images\")\n",
    "print(f\"\\nüìö Classes ({NUM_CLASSES}): {ALL_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ecfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ‚ö° **Step 6: Create Data Pipeline** { display-mode: \"form\" }\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def augment(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
    "    image = tf.image.rot90(image, k)\n",
    "    return image\n",
    "\n",
    "def parse_image(file_path, label, training=True):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    if training:\n",
    "        image = augment(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(images, labels, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(images))\n",
    "    ds = ds.map(lambda x, y: parse_image(x, y, training), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.cache()\n",
    "    return ds\n",
    "\n",
    "print(\"‚ö° Creating data pipelines...\")\n",
    "train_ds = create_dataset(train_imgs, train_labels, training=True)\n",
    "val_ds = create_dataset(val_imgs, val_labels, training=False)\n",
    "test_ds = create_dataset(test_imgs, test_labels, training=False)\n",
    "\n",
    "print(f\"   ‚úÖ Train batches: {len(train_imgs) // BATCH_SIZE}\")\n",
    "print(f\"   ‚úÖ Val batches:   {len(val_imgs) // BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3882cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üèóÔ∏è **Step 7: Build Model** { display-mode: \"form\" }\n",
    "\n",
    "print(\"üèóÔ∏è Building EfficientNetV2-S model...\")\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetV2S(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling=None\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(DROPOUT_RATE)(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(DROPOUT_RATE)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = tf.keras.layers.Dropout(DROPOUT_RATE / 2)(x)\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "print(f\"   ‚úÖ Total params: {model.count_params():,}\")\n",
    "print(f\"   ‚úÖ Trainable: {sum(tf.keras.backend.count_params(w) for w in model.trainable_weights):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605005d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ‚öñÔ∏è **Step 8: Class Weights & Callbacks** { display-mode: \"form\" }\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"‚öñÔ∏è Class weights:\")\n",
    "for cls_name, weight in zip(ALL_CLASSES, class_weights):\n",
    "    print(f\"   {cls_name:15s}: {weight:.3f}\")\n",
    "\n",
    "# Callbacks\n",
    "CHECKPOINT_DIR = OUTPUT_DIR / \"checkpoints\"\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class TqdmCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs, phase_name=\"Training\"):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.phase_name = phase_name\n",
    "        self.epoch_bar = None\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_bar = tqdm(total=self.epochs, desc=f\"üöÄ {self.phase_name}\", unit=\"epoch\")\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch_bar.set_postfix({'acc': f\"{logs.get('accuracy', 0):.2%}\", 'val_acc': f\"{logs.get('val_accuracy', 0):.2%}\"})\n",
    "        self.epoch_bar.update(1)\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.epoch_bar.close()\n",
    "\n",
    "callbacks_base = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(str(CHECKPOINT_DIR / \"best_model.keras\"), monitor='val_accuracy', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "print(\"\\nüéØ Callbacks configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79bea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üöÄ **Step 9: Phase 1 - Train Head** { display-mode: \"form\" }\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ PHASE 1: Training Classification Head (Backbone Frozen)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LR),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING),\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_accuracy')]\n",
    ")\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE1,\n",
    "    callbacks=callbacks_base + [TqdmCallback(EPOCHS_PHASE1, \"Phase 1: Head\")],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Phase 1 Complete! Best val_accuracy: {max(history_phase1.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13acaa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üî• **Step 10: Phase 2 - Unfreeze Top 30%** { display-mode: \"form\" }\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üî• PHASE 2: Training Top 30% of Backbone\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "base_model.trainable = True\n",
    "num_layers = len(base_model.layers)\n",
    "freeze_until = int(num_layers * 0.7)\n",
    "\n",
    "for layer in base_model.layers[:freeze_until]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"   üìä Total layers: {num_layers}\")\n",
    "print(f\"   üîí Frozen: {freeze_until}\")\n",
    "print(f\"   üî• Trainable: {num_layers - freeze_until}\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING),\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_accuracy')]\n",
    ")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE2,\n",
    "    callbacks=callbacks_base + [TqdmCallback(EPOCHS_PHASE2, \"Phase 2: Top 30%\")],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Phase 2 Complete! Best val_accuracy: {max(history_phase2.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525127cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üéì **Step 11: Phase 3 - Full Fine-tuning** { display-mode: \"form\" }\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üéì PHASE 3: Full Fine-tuning (All Layers Trainable)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "print(f\"   üî• All {len(base_model.layers)} layers now trainable\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR / 5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING),\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_accuracy')]\n",
    ")\n",
    "\n",
    "history_phase3 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE3,\n",
    "    callbacks=callbacks_base + [TqdmCallback(EPOCHS_PHASE3, \"Phase 3: Full\")],\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Phase 3 Complete! Best val_accuracy: {max(history_phase3.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa562f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üìä **Step 12: Training Visualization** { display-mode: \"form\" }\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "colors = ['#2ecc71', '#3498db', '#9b59b6']\n",
    "histories = [history_phase1, history_phase2, history_phase3]\n",
    "names = ['Phase 1', 'Phase 2', 'Phase 3']\n",
    "\n",
    "epoch_offset = 0\n",
    "for hist, name, color in zip(histories, names, colors):\n",
    "    epochs = range(epoch_offset, epoch_offset + len(hist.history['loss']))\n",
    "    axes[0].plot(epochs, hist.history['loss'], color=color, linestyle='-', label=f'{name} Train')\n",
    "    axes[0].plot(epochs, hist.history['val_loss'], color=color, linestyle='--', label=f'{name} Val')\n",
    "    axes[1].plot(epochs, hist.history['accuracy'], color=color, linestyle='-', label=f'{name} Train')\n",
    "    axes[1].plot(epochs, hist.history['val_accuracy'], color=color, linestyle='--', label=f'{name} Val')\n",
    "    axes[2].plot(epochs, hist.history['top3_accuracy'], color=color, linestyle='-', label=f'{name} Train')\n",
    "    axes[2].plot(epochs, hist.history['val_top3_accuracy'], color=color, linestyle='--', label=f'{name} Val')\n",
    "    epoch_offset += len(hist.history['loss'])\n",
    "\n",
    "axes[0].set_title('Loss'); axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "axes[1].set_title('Accuracy'); axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "axes[2].set_title('Top-3 Accuracy'); axes[2].legend(); axes[2].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUTPUT_DIR / 'training_history.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ebf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üß™ **Step 13: Model Evaluation** { display-mode: \"form\" }\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üß™ FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_loss, test_acc, test_top3 = model.evaluate(test_ds, verbose=1)\n",
    "print(f\"\\nüìä Test Results:\")\n",
    "print(f\"   Loss:          {test_loss:.4f}\")\n",
    "print(f\"   Accuracy:      {test_acc:.2%}\")\n",
    "print(f\"   Top-3 Accuracy: {test_top3:.2%}\")\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for images, labels in tqdm(test_ds, desc=\"üîÆ Predicting\"):\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=ALL_CLASSES, digits=3))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=ALL_CLASSES, yticklabels=ALL_CLASSES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUTPUT_DIR / 'confusion_matrix.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üíæ **Step 14: Save Model** { display-mode: \"form\" }\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üíæ SAVING FINAL MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save model\n",
    "final_model_path = OUTPUT_DIR / \"plantvillage-npk-v3.h5\"\n",
    "model.save(str(final_model_path))\n",
    "print(f\"   ‚úÖ Saved: {final_model_path}\")\n",
    "\n",
    "# Save class names\n",
    "with open(OUTPUT_DIR / \"class_names.txt\", 'w') as f:\n",
    "    for cls in ALL_CLASSES:\n",
    "        f.write(cls + '\\n')\n",
    "print(f\"   ‚úÖ Saved: class_names.txt\")\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    'model': 'EfficientNetV2-S',\n",
    "    'img_size': IMG_SIZE,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'classes': ALL_CLASSES,\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_top3_accuracy': float(test_top3)\n",
    "}\n",
    "with open(OUTPUT_DIR / \"model_config.json\", 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(f\"   ‚úÖ Saved: model_config.json\")\n",
    "\n",
    "print(\"\\nüéâ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üì• **Step 15: Download Model** { display-mode: \"form\" }\n",
    "#@markdown Download the trained model to your computer\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Downloading trained model...\")\n",
    "print(\"   (This will trigger a browser download)\")\n",
    "\n",
    "# Download model\n",
    "files.download(str(OUTPUT_DIR / \"plantvillage-npk-v3.h5\"))\n",
    "files.download(str(OUTPUT_DIR / \"class_names.txt\"))\n",
    "files.download(str(OUTPUT_DIR / \"model_config.json\"))\n",
    "\n",
    "print(\"\\n‚úÖ Files downloaded!\")\n",
    "print(\"\\nüìã Next steps:\")\n",
    "print(\"   1. Copy plantvillage-npk-v3.h5 to backend/ml/models/\")\n",
    "print(\"   2. Update MODEL_PATH in your backend config\")\n",
    "print(\"   3. Restart the backend server\")\n",
    "print(\"   4. Test with the app!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
