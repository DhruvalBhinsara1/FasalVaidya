{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f253f5b",
   "metadata": {},
   "source": [
    "# ğŸŒ± FasalVaidya NPK Deficiency Detection Model Training\n",
    "\n",
    "**Optimized for Google Colab with GPU Acceleration**\n",
    "\n",
    "This notebook trains an EfficientNetV2-S model to detect NPK (Nitrogen, Phosphorus, Potassium) deficiencies in plant leaves.\n",
    "\n",
    "## Features:\n",
    "\n",
    "- âš¡ **GPU Acceleration** - Uses Colab's free GPU (T4/V100)\n",
    "- ğŸ”„ **Parallel Data Loading** - Multi-threaded data pipelines\n",
    "- ğŸ“Š **9-Class Classification** - NPK + healthy + 5 other deficiencies\n",
    "- ğŸ¯ **Transfer Learning** - EfficientNetV2-S pretrained on ImageNet\n",
    "- ğŸ“ˆ **3-Phase Training** - Progressive unfreezing for best accuracy\n",
    "\n",
    "**Runtime â†’ Change runtime type â†’ GPU (T4)** before running!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b0d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "âœ… GPU enabled: /physical_device:GPU:0\n",
      "CPU cores for parallel loading: 2\n",
      "Running on: Google Colab\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Step 1: Setup & GPU Check\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Install and import tqdm for progress bars\n",
    "%pip install -q tqdm\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU devices: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Enable memory growth to prevent OOM\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"âœ… GPU enabled: {gpus[0].name}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU found! Go to Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "# Set optimal thread counts\n",
    "NUM_PARALLEL_CALLS = tf.data.AUTOTUNE\n",
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "print(f\"CPU cores for parallel loading: {NUM_WORKERS}\")\n",
    "\n",
    "# Detect environment (Colab vs Local)\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running on: {'Google Colab' if IS_COLAB else 'Local Machine'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddf9e9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Running on Google Colab\n",
      "   âš ï¸ Google Drive mount failed: mount failed\n",
      "   ğŸ“‚ Using Colab's local storage instead\n",
      "\n",
      "   âš ï¸ IMPORTANT: Local storage is NOT persistent!\n",
      "   ğŸ“¤ Upload your datasets to /content/ml_models/ using the file browser\n",
      "   ğŸ’¾ Download your trained model before session ends!\n",
      "\n",
      "ğŸ“ Base directory: /content/ml_models\n",
      "ğŸ’¾ Cache directory: /content/ml_models/combined_balanced_dataset\n",
      "ğŸ“¦ Output model: /content/ml_models/plantvillage-npk-v3.h5\n",
      "\n",
      "ğŸ” Checking dataset paths:\n",
      "   âš ï¸ NOT FOUND: /content/ml_models/Bigger CoLeaf DATASET/CoLeaf DATASET\n",
      "   âš ï¸ NOT FOUND: /content/ml_models/Propossed_Data/Contrast_Stretching\n",
      "   âš ï¸ NOT FOUND: /content/ml_models/Propossed_Data/Histogram_Equalization\n",
      "   âš ï¸ NOT FOUND: /content/ml_models/Propossed_Data/Log_Transformation\n",
      "   âš ï¸ NOT FOUND: /content/ml_models/Nitrogen deficiency\n",
      "   âš ï¸ NOT FOUND: /content/ml_models/ThorCam_semiFiltered\n",
      "   âš ï¸ NOT FOUND: /content/ml_models/POTASSIUM DEFICIENCY\n",
      "\n",
      "============================================================\n",
      "ğŸ“¤ NO DATASETS FOUND! Upload your data:\n",
      "============================================================\n",
      "   1. Click the folder icon (ğŸ“) in the left sidebar\n",
      "   2. Navigate to: /content/ml_models\n",
      "   3. Upload your dataset folders:\n",
      "      - Bigger CoLeaf DATASET/\n",
      "      - Propossed_Data/\n",
      "      - etc.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ Step 2: Setup Paths (Auto-detect Colab vs Local)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-detect environment and set paths accordingly\n",
    "if IS_COLAB:\n",
    "    print(\"ğŸ“ Running on Google Colab\")\n",
    "    \n",
    "    # Try to mount Google Drive\n",
    "    DRIVE_MOUNTED = False\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=False)\n",
    "        DRIVE_MOUNTED = True\n",
    "        print(\"   âœ… Google Drive mounted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ Google Drive mount failed: {e}\")\n",
    "        print(\"   ğŸ“‚ Using Colab's local storage instead\")\n",
    "    \n",
    "    if DRIVE_MOUNTED:\n",
    "        # Use Google Drive for persistent storage\n",
    "        BASE_DIR = Path(\"/content/drive/MyDrive/FasalVaidya/ml/models\")\n",
    "        # Create directory if it doesn't exist\n",
    "        BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        # Fallback: Use Colab's local storage (faster but not persistent)\n",
    "        BASE_DIR = Path(\"/content/ml_models\")\n",
    "        BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"\\n   âš ï¸ IMPORTANT: Local storage is NOT persistent!\")\n",
    "        print(\"   ğŸ“¤ Upload your datasets to /content/ml_models/ using the file browser\")\n",
    "        print(\"   ğŸ’¾ Download your trained model before session ends!\")\n",
    "else:\n",
    "    # Local Windows paths\n",
    "    BASE_DIR = Path(r\"E:\\FasalVaidya\\backend\\ml\\models\")\n",
    "    print(\"ğŸ“ Running on Local Machine\")\n",
    "\n",
    "# Dataset paths - all your datasets\n",
    "# NOTE: \"Bigger CoLeaf DATASET\" has nested \"CoLeaf DATASET\" folder with actual classes\n",
    "DATA_SOURCES = [\n",
    "    BASE_DIR / \"Bigger CoLeaf DATASET\" / \"CoLeaf DATASET\",  # Main 9-class dataset\n",
    "    BASE_DIR / \"Propossed_Data\" / \"Contrast_Stretching\",\n",
    "    BASE_DIR / \"Propossed_Data\" / \"Histogram_Equalization\",\n",
    "    BASE_DIR / \"Propossed_Data\" / \"Log_Transformation\",\n",
    "    # Additional datasets\n",
    "    BASE_DIR / \"Nitrogen deficiency\",  # Rice nitrogen dataset (train/val/test â†’ control/deficiency)\n",
    "    BASE_DIR / \"ThorCam_semiFiltered\",  # Control (-C) & Phosphorus (-P, -P50)\n",
    "    BASE_DIR / \"POTASSIUM DEFICIENCY\",  # Extra potassium data (flat folder, all K deficiency)\n",
    "]\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = BASE_DIR\n",
    "OUTPUT_MODEL = OUTPUT_DIR / \"plantvillage-npk-v3.h5\"\n",
    "\n",
    "# Local cache for combined dataset\n",
    "LOCAL_CACHE = BASE_DIR / \"combined_balanced_dataset\"\n",
    "LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nğŸ“ Base directory: {BASE_DIR}\")\n",
    "print(f\"ğŸ’¾ Cache directory: {LOCAL_CACHE}\")\n",
    "print(f\"ğŸ“¦ Output model: {OUTPUT_MODEL}\")\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"\\nğŸ” Checking dataset paths:\")\n",
    "found_any = False\n",
    "for src in DATA_SOURCES:\n",
    "    if src.exists():\n",
    "        found_any = True\n",
    "        count = sum(1 for _ in src.rglob(\"*\") if _.is_file() and _.suffix.lower() in ['.jpg', '.jpeg', '.png', '.tif', '.tiff'])\n",
    "        print(f\"   âœ… {src.name}: ~{count} images\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ NOT FOUND: {src}\")\n",
    "\n",
    "if not found_any and IS_COLAB:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“¤ NO DATASETS FOUND! Upload your data:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"   1. Click the folder icon (ğŸ“) in the left sidebar\")\n",
    "    print(f\"   2. Navigate to: {BASE_DIR}\")\n",
    "    print(f\"   3. Upload your dataset folders:\")\n",
    "    print(f\"      - Bigger CoLeaf DATASET/\")\n",
    "    print(f\"      - Propossed_Data/\")\n",
    "    print(f\"      - etc.\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "978edd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Upload your dataset as a ZIP file...\n",
      "   The ZIP should contain folders like: Bigger CoLeaf DATASET/, Propossed_Data/, etc.\n",
      "\n",
      "â³ Waiting for file upload (click 'Choose Files' below)...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ee71fbed-e05f-443a-b2a2-96cea991c772\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-ee71fbed-e05f-443a-b2a2-96cea991c772\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1191125723.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ğŸ“¤ Step 2b: Upload Dataset to Colab\n",
    "# Run this cell DIRECTLY in Colab browser (not via VS Code remote connection)\n",
    "\n",
    "if IS_COLAB:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ğŸ“¤ DATASET UPLOAD OPTIONS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # OPTION 1: Manual Upload via File Browser (RECOMMENDED)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    print(\"\"\"\n",
    "ğŸ”¹ OPTION 1: Manual Upload (Works Always)\n",
    "   1. Click the folder icon (ğŸ“) in the LEFT sidebar of Colab\n",
    "   2. Right-click on the file browser â†’ 'Upload'\n",
    "   3. Upload your ZIP file containing the datasets\n",
    "   4. Then run the extraction code below\n",
    "    \"\"\")\n",
    "    \n",
    "    # Check if any zip files were uploaded manually\n",
    "    import glob \n",
    "    zip_files = glob.glob(\"/content/*.zip\")\n",
    "    if zip_files:\n",
    "        print(f\"   âœ… Found uploaded ZIP files: {zip_files}\")\n",
    "        print(\"   Run the extraction cell below!\")\n",
    "    else:\n",
    "        print(\"   â³ No ZIP files found yet. Upload one first.\")\n",
    "    \n",
    "    print(\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ğŸ”¹ OPTION 2: Download from Google Drive Link\n",
    "   If you have a shareable Google Drive link, uncomment and run:\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \"\"\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# OPTION 2: Download from Google Drive shareable link (UNCOMMENT TO USE)\n",
    "# Replace YOUR_FILE_ID with the actual file ID from your Drive link\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# !pip install -q gdown\n",
    "# !gdown \"YOUR_FILE_ID\" -O /content/dataset.zip\n",
    "# # Example: !gdown \"1ABC123xyz\" -O /content/dataset.zip\n",
    "# # Get FILE_ID from link like: https://drive.google.com/file/d/FILE_ID/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70906e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ Step 2c: Extract uploaded ZIP file\n",
    "# Run this AFTER uploading a ZIP file to /content/\n",
    "\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "zip_files = glob.glob(\"/content/*.zip\")\n",
    "\n",
    "if zip_files:\n",
    "    for zip_path in zip_files:\n",
    "        print(f\"ğŸ“¦ Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(str(BASE_DIR))\n",
    "        print(f\"   âœ… Extracted to {BASE_DIR}\")\n",
    "        \n",
    "        # Optionally remove zip to save space\n",
    "        # os.remove(zip_path)\n",
    "        # print(f\"   ğŸ—‘ï¸ Removed {zip_path}\")\n",
    "    \n",
    "    # Show what was extracted\n",
    "    print(\"\\nğŸ” Extracted contents:\")\n",
    "    for item in sorted(BASE_DIR.iterdir()):\n",
    "        if item.is_dir():\n",
    "            count = sum(1 for _ in item.rglob(\"*\") if _.is_file())\n",
    "            print(f\"   ğŸ“‚ {item.name}/  ({count} files)\")\n",
    "        else:\n",
    "            print(f\"   ğŸ“„ {item.name}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No ZIP files found in /content/\")\n",
    "    print(\"   Upload a ZIP file using the file browser (ğŸ“) first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4134c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Step 3: Configuration & Auto-detect Dataset Paths\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import EfficientNetV2S, EfficientNetB0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Classes - mapping for different folder naming conventions\n",
    "CLASS_MAPPING = {\n",
    "    \"healthy\": \"healthy\", \"control\": \"healthy\", \"-C\": \"healthy\",\n",
    "    \"nitrogen-N\": \"nitrogen-N\", \"deficiency\": \"nitrogen-N\", \"N\": \"nitrogen-N\",\n",
    "    \"phosphorus-P\": \"phosphorus-P\", \"-P\": \"phosphorus-P\", \"-P50\": \"phosphorus-P\", \"P\": \"phosphorus-P\",\n",
    "    \"potasium-K\": \"potasium-K\", \"K\": \"potasium-K\",\n",
    "    \"boron-B\": \"boron-B\", \"calcium-Ca\": \"calcium-Ca\", \"iron-Fe\": \"iron-Fe\",\n",
    "    \"magnesium-Mg\": \"magnesium-Mg\", \"manganese-Mn\": \"manganese-Mn\",\n",
    "}\n",
    "\n",
    "TARGET_CLASSES = [\"healthy\", \"nitrogen-N\", \"phosphorus-P\", \"potasium-K\"]\n",
    "EXTRA_CLASSES = [\"boron-B\", \"calcium-Ca\", \"iron-Fe\", \"magnesium-Mg\", \"manganese-Mn\"]\n",
    "ALL_CLASSES = TARGET_CLASSES + EXTRA_CLASSES\n",
    "\n",
    "# Training hyperparameters - OPTIMIZED FOR LOCAL CPU/GPU\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16  # Smaller for CPU\n",
    "EPOCHS_PHASE1 = 30  # Head training\n",
    "EPOCHS_PHASE2 = 25  # Fine-tuning top 40%\n",
    "EPOCHS_PHASE3 = 20  # Full fine-tuning\n",
    "VALIDATION_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.10\n",
    "\n",
    "# Additional hyperparameters\n",
    "INITIAL_LR = 1e-3\n",
    "FINE_TUNE_LR = 1e-4\n",
    "DEEP_TUNE_LR = 1e-5\n",
    "LABEL_SMOOTHING = 0.1\n",
    "DROPOUT_RATE = 0.4  # Increased for better regularization\n",
    "EARLY_STOPPING_PATIENCE = 8\n",
    "\n",
    "# Class balancing\n",
    "TARGET_SAMPLES_PER_CLASS = 500  # Oversample/undersample to this target\n",
    "\n",
    "# Performance settings\n",
    "PREFETCH_BUFFER = tf.data.AUTOTUNE\n",
    "SHUFFLE_BUFFER = 2000\n",
    "NUM_WORKERS = min(8, os.cpu_count() or 4)\n",
    "\n",
    "print(f\"âœ… Configuration loaded\")\n",
    "print(f\"   Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Classes: {len(ALL_CLASSES)}\")\n",
    "print(f\"   Target samples/class: {TARGET_SAMPLES_PER_CLASS}\")\n",
    "print(f\"   Training phases: {EPOCHS_PHASE1} + {EPOCHS_PHASE2} + {EPOCHS_PHASE3} = {EPOCHS_PHASE1+EPOCHS_PHASE2+EPOCHS_PHASE3} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‚ Step 4: Parallel Dataset Combining (Multi-threaded with tqdm)\n",
    "import shutil\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def copy_file(args):\n",
    "    \"\"\"Thread worker for parallel file copying.\"\"\"\n",
    "    src, dest = args\n",
    "    try:\n",
    "        if not dest.exists():\n",
    "            shutil.copy2(src, dest)\n",
    "            return 1\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "def collect_all_images():\n",
    "    \"\"\"Scan all datasets and collect image paths by class.\"\"\"\n",
    "    print(\"ğŸ“ Scanning all datasets...\")\n",
    "    \n",
    "    class_images = {cls: [] for cls in ALL_CLASSES}\n",
    "    \n",
    "    for dataset_path in DATA_SOURCES:\n",
    "        if not dataset_path.exists():\n",
    "            print(f\"   âš ï¸ Not found: {dataset_path}\")\n",
    "            continue\n",
    "        \n",
    "        dataset_name = dataset_path.name\n",
    "        print(f\"   ğŸ“‚ Scanning {dataset_name}...\")\n",
    "        \n",
    "        # Handle Nitrogen deficiency dataset (special structure: train/val/test â†’ control/deficiency)\n",
    "        if \"Nitrogen\" in dataset_name or \"nitrogen\" in dataset_name:\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                split_dir = dataset_path / split\n",
    "                if split_dir.exists():\n",
    "                    for class_dir in split_dir.iterdir():\n",
    "                        if class_dir.is_dir():\n",
    "                            std_class = CLASS_MAPPING.get(class_dir.name)\n",
    "                            if std_class and std_class in class_images:\n",
    "                                for img in class_dir.glob(\"*\"):\n",
    "                                    if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
    "                                        class_images[std_class].append(img)\n",
    "        \n",
    "        # Handle ThorCam dataset (-C, -P, -P50 folders)\n",
    "        elif \"ThorCam\" in dataset_name:\n",
    "            for class_dir in dataset_path.iterdir():\n",
    "                if class_dir.is_dir():\n",
    "                    std_class = CLASS_MAPPING.get(class_dir.name)\n",
    "                    if std_class and std_class in class_images:\n",
    "                        for img in class_dir.glob(\"*\"):\n",
    "                            if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".tif\"]:\n",
    "                                class_images[std_class].append(img)\n",
    "        \n",
    "        # Handle POTASSIUM DEFICIENCY dataset (flat folder - all images are potassium deficiency)\n",
    "        elif \"POTASSIUM\" in dataset_name.upper():\n",
    "            for img in dataset_path.glob(\"*\"):\n",
    "                if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
    "                    class_images[\"potasium-K\"].append(img)\n",
    "        \n",
    "        # Standard structure: class_name/images\n",
    "        else:\n",
    "            for class_dir in dataset_path.iterdir():\n",
    "                if class_dir.is_dir():\n",
    "                    std_class = CLASS_MAPPING.get(class_dir.name, class_dir.name)\n",
    "                    if std_class and std_class in class_images:\n",
    "                        for img in class_dir.glob(\"*\"):\n",
    "                            if img.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
    "                                class_images[std_class].append(img)\n",
    "    \n",
    "    return class_images\n",
    "\n",
    "def balance_classes(class_images):\n",
    "    \"\"\"Balance classes with oversampling/undersampling.\"\"\"\n",
    "    print(f\"\\nâš–ï¸ Balancing classes (target: {TARGET_SAMPLES_PER_CLASS} per class)...\")\n",
    "    \n",
    "    balanced = {cls: list(imgs) for cls, imgs in class_images.items()}\n",
    "    \n",
    "    for cls in ALL_CLASSES:\n",
    "        current = len(balanced[cls])\n",
    "        if current == 0:\n",
    "            print(f\"   âš ï¸ {cls}: No samples!\")\n",
    "            continue\n",
    "        \n",
    "        if current < TARGET_SAMPLES_PER_CLASS:\n",
    "            # Oversample\n",
    "            needed = TARGET_SAMPLES_PER_CLASS - current\n",
    "            balanced[cls].extend(random.choices(balanced[cls], k=needed))\n",
    "            print(f\"   ğŸ“ˆ {cls}: {current} â†’ {len(balanced[cls])} (+{needed})\")\n",
    "        elif current > TARGET_SAMPLES_PER_CLASS * 2:\n",
    "            # Undersample only if way too many\n",
    "            balanced[cls] = random.sample(balanced[cls], TARGET_SAMPLES_PER_CLASS)\n",
    "            print(f\"   ğŸ“‰ {cls}: {current} â†’ {len(balanced[cls])}\")\n",
    "        else:\n",
    "            print(f\"   âœ“ {cls}: {current}\")\n",
    "    \n",
    "    return balanced\n",
    "\n",
    "def combine_datasets_parallel():\n",
    "    \"\"\"Combine all datasets using parallel threads.\"\"\"\n",
    "    # Remove old cache\n",
    "    if LOCAL_CACHE.exists():\n",
    "        print(\"   Removing old cache...\")\n",
    "        shutil.rmtree(LOCAL_CACHE)\n",
    "    \n",
    "    # Collect all images\n",
    "    class_images = collect_all_images()\n",
    "    \n",
    "    # Print raw stats\n",
    "    print(\"\\nğŸ“Š Raw dataset statistics:\")\n",
    "    total_raw = 0\n",
    "    max_count = max(len(imgs) for imgs in class_images.values()) if class_images else 1\n",
    "    for cls in ALL_CLASSES:\n",
    "        count = len(class_images[cls])\n",
    "        total_raw += count\n",
    "        bar = \"â–ˆ\" * int(30 * count / max_count) if max_count > 0 else \"\"\n",
    "        print(f\"   {cls:15s}: {bar:30s} {count:5d}\")\n",
    "    print(f\"   {'â”€' * 50}\")\n",
    "    print(f\"   {'TOTAL':15s}:                                {total_raw:5d}\")\n",
    "    \n",
    "    # Balance classes\n",
    "    balanced_images = balance_classes(class_images)\n",
    "    \n",
    "    # Create directories\n",
    "    for cls in ALL_CLASSES:\n",
    "        (LOCAL_CACHE / cls).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Prepare copy tasks\n",
    "    copy_tasks = []\n",
    "    for cls in ALL_CLASSES:\n",
    "        for i, src_path in enumerate(balanced_images[cls]):\n",
    "            suffix = src_path.suffix.lower()\n",
    "            if suffix not in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                suffix = \".jpg\"\n",
    "            dst_path = LOCAL_CACHE / cls / f\"{cls}_{i:05d}{suffix}\"\n",
    "            copy_tasks.append((src_path, dst_path))\n",
    "    \n",
    "    # Copy with progress bar\n",
    "    print(f\"\\nğŸ“ Copying {len(copy_tasks)} files with {NUM_WORKERS} threads...\")\n",
    "    copied = 0\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        futures = list(tqdm(\n",
    "            executor.map(copy_file, copy_tasks),\n",
    "            total=len(copy_tasks),\n",
    "            desc=\"   Copying\",\n",
    "            unit=\"file\"\n",
    "        ))\n",
    "        copied = sum(futures)\n",
    "    \n",
    "    print(f\"   âœ… Done! {copied} files copied to {LOCAL_CACHE}\")\n",
    "    return balanced_images\n",
    "\n",
    "# Run the combination\n",
    "balanced_data = combine_datasets_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae29ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”€ Step 5: Create Train/Val/Test Splits\n",
    "def create_splits():\n",
    "    \"\"\"Create stratified train/val/test splits.\"\"\"\n",
    "    print(\"\\nğŸ”€ Creating train/val/test splits...\")\n",
    "    \n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(ALL_CLASSES)}\n",
    "    \n",
    "    for cls in ALL_CLASSES:\n",
    "        cls_dir = LOCAL_CACHE / cls\n",
    "        if not cls_dir.exists():\n",
    "            continue\n",
    "        for img_file in cls_dir.glob(\"*\"):\n",
    "            if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                all_images.append(str(img_file))\n",
    "                all_labels.append(class_to_idx[cls])\n",
    "    \n",
    "    all_images = np.array(all_images)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Stratified splits\n",
    "    train_val_imgs, test_imgs, train_val_labels, test_labels = train_test_split(\n",
    "        all_images, all_labels, test_size=TEST_SPLIT, stratify=all_labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    val_ratio = VALIDATION_SPLIT / (1 - TEST_SPLIT)\n",
    "    train_imgs, val_imgs, train_labels, val_labels = train_test_split(\n",
    "        train_val_imgs, train_val_labels, test_size=val_ratio, stratify=train_val_labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"   âœ… Train: {len(train_imgs):4d} images\")\n",
    "    print(f\"   âœ… Val:   {len(val_imgs):4d} images\")\n",
    "    print(f\"   âœ… Test:  {len(test_imgs):4d} images\")\n",
    "    \n",
    "    return (train_imgs, train_labels), (val_imgs, val_labels), (test_imgs, test_labels)\n",
    "\n",
    "(train_imgs, train_labels), (val_imgs, val_labels), (test_imgs, test_labels) = create_splits()\n",
    "NUM_CLASSES = len(ALL_CLASSES)\n",
    "print(f\"\\nğŸ“š Classes ({NUM_CLASSES}): {ALL_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš¡ Step 6: Optimized tf.data Pipeline (GPU-accelerated)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def augment(image, training=True):\n",
    "    \"\"\"GPU-accelerated augmentation.\"\"\"\n",
    "    if training:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "        image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "        image = tf.image.random_hue(image, max_delta=0.1)\n",
    "        # Random rotation (90Â° increments)\n",
    "        k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
    "        image = tf.image.rot90(image, k)\n",
    "    return image\n",
    "\n",
    "def parse_image(file_path, label, training=True):\n",
    "    \"\"\"Load and preprocess image with parallel threading.\"\"\"\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    if training:\n",
    "        image = augment(image, training=True)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(images, labels, training=True):\n",
    "    \"\"\"Create optimized tf.data.Dataset with parallelization.\"\"\"\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(images), reshuffle_each_iteration=True)\n",
    "    \n",
    "    # Parallel map with NUM_WORKERS threads\n",
    "    ds = ds.map(\n",
    "        lambda x, y: parse_image(x, y, training),\n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "    \n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    \n",
    "    if training:\n",
    "        ds = ds.cache()  # Cache after batching for memory efficiency\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# Create datasets\n",
    "print(\"âš¡ Creating optimized GPU data pipelines...\")\n",
    "train_ds = create_dataset(train_imgs, train_labels, training=True)\n",
    "val_ds = create_dataset(val_imgs, val_labels, training=False)\n",
    "test_ds = create_dataset(test_imgs, test_labels, training=False)\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = len(train_imgs) // BATCH_SIZE\n",
    "validation_steps = len(val_imgs) // BATCH_SIZE\n",
    "\n",
    "print(f\"   âœ… Train batches: {len(train_imgs) // BATCH_SIZE}\")\n",
    "print(f\"   âœ… Val batches:   {len(val_imgs) // BATCH_SIZE}\")\n",
    "print(f\"   âœ… Prefetching:   AUTOTUNE enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ—ï¸ Step 7: Build EfficientNetV2-S Model\n",
    "def build_model():\n",
    "    \"\"\"Build EfficientNetV2-S with custom head for NPK classification.\"\"\"\n",
    "    print(\"\\nğŸ—ï¸ Building EfficientNetV2-S model...\")\n",
    "    \n",
    "    # Base model (pretrained on ImageNet)\n",
    "    base_model = tf.keras.applications.EfficientNetV2S(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling=None\n",
    "    )\n",
    "    \n",
    "    # Initially freeze all layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model with custom head\n",
    "    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(DROPOUT_RATE)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(DROPOUT_RATE)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(DROPOUT_RATE / 2)(x)\n",
    "    outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    print(f\"   âœ… Base model:     EfficientNetV2-S\")\n",
    "    print(f\"   âœ… Total params:   {model.count_params():,}\")\n",
    "    print(f\"   âœ… Trainable:      {sum(tf.keras.backend.count_params(w) for w in model.trainable_weights):,}\")\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "model, base_model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea994246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš–ï¸ Step 8: Calculate Class Weights (Handle Imbalance)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"âš–ï¸ Class weights for imbalanced data:\")\n",
    "for cls_name, weight in zip(ALL_CLASSES, class_weights):\n",
    "    print(f\"   {cls_name:15s}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Step 9: Training Callbacks with tqdm Progress Bar\n",
    "import datetime\n",
    "\n",
    "# Create output directories\n",
    "CHECKPOINT_DIR = OUTPUT_DIR / \"checkpoints\"\n",
    "LOGS_DIR = OUTPUT_DIR / \"logs\"\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Custom tqdm callback for training progress\n",
    "class TqdmCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs, phase_name=\"Training\"):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.phase_name = phase_name\n",
    "        self.epoch_bar = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch_bar = tqdm(total=self.epochs, desc=f\"ğŸš€ {self.phase_name}\", \n",
    "                              unit=\"epoch\", position=0, leave=True,\n",
    "                              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]')\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        # Update progress bar with metrics\n",
    "        self.epoch_bar.set_postfix({\n",
    "            'loss': f\"{logs.get('loss', 0):.4f}\",\n",
    "            'acc': f\"{logs.get('accuracy', 0):.2%}\",\n",
    "            'val_acc': f\"{logs.get('val_accuracy', 0):.2%}\"\n",
    "        })\n",
    "        self.epoch_bar.update(1)\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.epoch_bar.close()\n",
    "\n",
    "# Training callbacks\n",
    "callbacks_base = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=EARLY_STOPPING_PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        str(CHECKPOINT_DIR / \"best_model.keras\"),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=0  # Reduced verbosity for cleaner output\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=str(LOGS_DIR / datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"ğŸ¯ Training callbacks configured:\")\n",
    "print(\"   âœ… TqdmCallback (progress bar)\")\n",
    "print(\"   âœ… EarlyStopping (patience={})\".format(EARLY_STOPPING_PATIENCE))\n",
    "print(\"   âœ… ReduceLROnPlateau\")\n",
    "print(\"   âœ… ModelCheckpoint\")\n",
    "print(\"   âœ… TensorBoard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f42ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Step 10: Phase 1 - Train Head Only (Frozen Backbone)\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ PHASE 1: Training Classification Head (Backbone Frozen)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compile model for Phase 1\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LR),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING),\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_accuracy')]\n",
    ")\n",
    "\n",
    "# Create Phase 1 callbacks with tqdm\n",
    "phase1_callbacks = callbacks_base + [TqdmCallback(EPOCHS_PHASE1, \"Phase 1: Head\")]\n",
    "\n",
    "# Train Phase 1\n",
    "history_phase1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE1,\n",
    "    callbacks=phase1_callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0  # Suppress default output, use tqdm instead\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Phase 1 Complete!\")\n",
    "print(f\"   Best val_accuracy: {max(history_phase1.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5bf382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¥ Step 11: Phase 2 - Unfreeze Top Layers (Progressive Unfreezing)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ”¥ PHASE 2: Training Top 30% of Backbone\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Unfreeze top 30% of base model layers\n",
    "base_model.trainable = True\n",
    "num_layers = len(base_model.layers)\n",
    "freeze_until = int(num_layers * 0.7)  # Freeze first 70%\n",
    "\n",
    "for layer in base_model.layers[:freeze_until]:\n",
    "    layer.trainable = False\n",
    "\n",
    "trainable_count = sum(1 for layer in base_model.layers if layer.trainable)\n",
    "print(f\"   ğŸ“Š Total layers: {num_layers}\")\n",
    "print(f\"   ğŸ”’ Frozen layers: {freeze_until}\")\n",
    "print(f\"   ğŸ”¥ Trainable layers: {trainable_count}\")\n",
    "\n",
    "# Recompile with lower LR\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING),\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_accuracy')]\n",
    ")\n",
    "\n",
    "# Create Phase 2 callbacks with tqdm\n",
    "phase2_callbacks = callbacks_base + [TqdmCallback(EPOCHS_PHASE2, \"Phase 2: Top 30%\")]\n",
    "\n",
    "# Train Phase 2\n",
    "history_phase2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE2,\n",
    "    callbacks=phase2_callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0  # Suppress default output, use tqdm instead\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Phase 2 Complete!\")\n",
    "print(f\"   Best val_accuracy: {max(history_phase2.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Step 12: Phase 3 - Full Fine-tuning (All Layers)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“ PHASE 3: Full Fine-tuning (All Layers Trainable)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Unfreeze entire backbone\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "print(f\"   ğŸ”¥ All {len(base_model.layers)} layers now trainable\")\n",
    "print(f\"   ğŸ“Š Total trainable params: {sum(tf.keras.backend.count_params(w) for w in model.trainable_weights):,}\")\n",
    "\n",
    "# Recompile with very low LR\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR / 5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING),\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_accuracy')]\n",
    ")\n",
    "\n",
    "# Create Phase 3 callbacks with tqdm\n",
    "phase3_callbacks = callbacks_base + [TqdmCallback(EPOCHS_PHASE3, \"Phase 3: Full\")]\n",
    "\n",
    "# Train Phase 3\n",
    "history_phase3 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS_PHASE3,\n",
    "    callbacks=phase3_callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=0  # Suppress default output, use tqdm instead\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Phase 3 Complete!\")\n",
    "print(f\"   Best val_accuracy: {max(history_phase3.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3867f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Step 13: Training Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(histories, phase_names):\n",
    "    \"\"\"Plot training curves for all phases.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    colors = ['#2ecc71', '#3498db', '#9b59b6']\n",
    "    \n",
    "    epoch_offset = 0\n",
    "    for hist, name, color in zip(histories, phase_names, colors):\n",
    "        epochs = range(epoch_offset, epoch_offset + len(hist.history['loss']))\n",
    "        \n",
    "        # Loss\n",
    "        axes[0, 0].plot(epochs, hist.history['loss'], color=color, linestyle='-', label=f'{name} Train')\n",
    "        axes[0, 0].plot(epochs, hist.history['val_loss'], color=color, linestyle='--', label=f'{name} Val')\n",
    "        \n",
    "        # Accuracy\n",
    "        axes[0, 1].plot(epochs, hist.history['accuracy'], color=color, linestyle='-', label=f'{name} Train')\n",
    "        axes[0, 1].plot(epochs, hist.history['val_accuracy'], color=color, linestyle='--', label=f'{name} Val')\n",
    "        \n",
    "        # Top-3 Accuracy\n",
    "        axes[1, 0].plot(epochs, hist.history['top3_accuracy'], color=color, linestyle='-', label=f'{name} Train')\n",
    "        axes[1, 0].plot(epochs, hist.history['val_top3_accuracy'], color=color, linestyle='--', label=f'{name} Val')\n",
    "        \n",
    "        epoch_offset += len(hist.history['loss'])\n",
    "    \n",
    "    axes[0, 0].set_title('Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].legend(fontsize=8)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].set_title('Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].legend(fontsize=8)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].set_title('Top-3 Accuracy', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].legend(fontsize=8)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate visualization\n",
    "    axes[1, 1].text(0.5, 0.5, f\"ğŸ† Training Summary\\n\\nPhase 1: Head Only\\nPhase 2: Top 30% Backbone\\nPhase 3: Full Fine-tuning\\n\\nBest Val Accuracy:\\n{max(history_phase3.history['val_accuracy']):.2%}\", \n",
    "                    ha='center', va='center', fontsize=12, transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(str(OUTPUT_DIR / 'training_history.png'), dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(\n",
    "    [history_phase1, history_phase2, history_phase3],\n",
    "    ['Phase 1', 'Phase 2', 'Phase 3']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23be36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª Step 14: Model Evaluation on Test Set\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ§ª FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluate on test set with progress bar\n",
    "print(\"\\nğŸ“Š Evaluating model...\")\n",
    "test_loss, test_acc, test_top3 = model.evaluate(test_ds, verbose=1)\n",
    "print(f\"\\nğŸ“Š Test Results:\")\n",
    "print(f\"   Loss:          {test_loss:.4f}\")\n",
    "print(f\"   Accuracy:      {test_acc:.2%}\")\n",
    "print(f\"   Top-3 Accuracy: {test_top3:.2%}\")\n",
    "\n",
    "# Get predictions with tqdm progress bar\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(\"\\nğŸ”® Generating predictions...\")\n",
    "for images, labels in tqdm(test_ds, desc=\"ğŸ”® Predicting\", unit=\"batch\"):\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nğŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=ALL_CLASSES, digits=3))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=ALL_CLASSES, yticklabels=ALL_CLASSES)\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUTPUT_DIR / 'confusion_matrix.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf59848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¾ Step 15: Save Final Model\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ’¾ SAVING FINAL MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save in multiple formats\n",
    "final_model_path = OUTPUT_DIR / \"fasalvaidya-npk-efficientnetv2s.h5\"\n",
    "model.save(str(final_model_path))\n",
    "print(f\"   âœ… Saved H5:     {final_model_path}\")\n",
    "\n",
    "# Save as SavedModel format (for TensorFlow Serving)\n",
    "saved_model_path = OUTPUT_DIR / \"saved_model\"\n",
    "model.save(str(saved_model_path))\n",
    "print(f\"   âœ… Saved TF:     {saved_model_path}\")\n",
    "\n",
    "# Save class names\n",
    "class_names_path = OUTPUT_DIR / \"class_names.txt\"\n",
    "with open(class_names_path, 'w') as f:\n",
    "    for cls in ALL_CLASSES:\n",
    "        f.write(cls + '\\n')\n",
    "print(f\"   âœ… Saved Classes: {class_names_path}\")\n",
    "\n",
    "# Save training config\n",
    "config = {\n",
    "    'model': 'EfficientNetV2-S',\n",
    "    'img_size': IMG_SIZE,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'classes': ALL_CLASSES,\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_top3_accuracy': float(test_top3),\n",
    "    'training_phases': ['head_only', 'top_30_unfrozen', 'full_finetune']\n",
    "}\n",
    "\n",
    "import json\n",
    "config_path = OUTPUT_DIR / \"model_config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(f\"   âœ… Saved Config: {config_path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ Model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02393f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¥ Step 16: Copy Model to Backend\n",
    "import shutil\n",
    "\n",
    "print(\"ğŸ“¥ Copying trained model to backend directory...\")\n",
    "\n",
    "# Set backend path based on environment\n",
    "if IS_COLAB:\n",
    "    # On Colab, save to Google Drive\n",
    "    backend_model_path = Path(\"/content/drive/MyDrive/FasalVaidya/ml/models/plantvillage-npk-v3.h5\")\n",
    "    print(\"   â„¹ï¸ On Colab: Model saved to Google Drive\")\n",
    "    print(\"   ğŸ“¥ Download it and copy to your local backend/ml/models/ folder\")\n",
    "else:\n",
    "    # Local Windows path\n",
    "    backend_model_path = Path(r\"E:\\FasalVaidya\\backend\\ml\\models\\plantvillage-npk-v3.h5\")\n",
    "\n",
    "shutil.copy2(final_model_path, backend_model_path)\n",
    "print(f\"   âœ… Copied to: {backend_model_path}\")\n",
    "\n",
    "# Also save a backup\n",
    "backup_path = OUTPUT_DIR / \"plantvillage-npk-v3.h5\"\n",
    "if backup_path != final_model_path:\n",
    "    shutil.copy2(final_model_path, backup_path)\n",
    "    print(f\"   âœ… Backup at: {backup_path}\")\n",
    "\n",
    "print(\"\\nâœ… Model is ready! To use it:\")\n",
    "print(f\"   1. Update MODEL_PATH in tasks.json to: {backend_model_path}\")\n",
    "print(f\"   2. Restart the backend server\")\n",
    "print(f\"   3. Test with new scans!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92345004",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“‹ Training Instructions\n",
    "\n",
    "### ğŸŒ Google Colab Setup\n",
    "1. **Upload datasets to Google Drive:**\n",
    "   ```\n",
    "   /MyDrive/FasalVaidya/ml/models/\n",
    "   â”œâ”€â”€ Bigger CoLeaf DATASET/\n",
    "   â”œâ”€â”€ Propossed_Data/\n",
    "   â”œâ”€â”€ Nitrogen deficiency/\n",
    "   â”œâ”€â”€ ThorCam_semiFiltered/\n",
    "   â””â”€â”€ POTASSIUM DEFICIENCY/\n",
    "   ```\n",
    "2. **Run Step 1** - Installs dependencies and detects GPU\n",
    "3. **Run Step 2** - Mounts Google Drive automatically\n",
    "4. **Run remaining cells** in order\n",
    "\n",
    "### ğŸ’» Local Training Setup\n",
    "Your datasets should be at:\n",
    "```\n",
    "E:\\FasalVaidya\\backend\\ml\\models\\\n",
    "â”œâ”€â”€ Bigger CoLeaf DATASET/          # Main dataset (9 classes)\n",
    "â”œâ”€â”€ Propossed_Data/                  # 3 augmentation variants\n",
    "â”‚   â”œâ”€â”€ Contrast_Stretching/\n",
    "â”‚   â”œâ”€â”€ Histogram_Equalization/\n",
    "â”‚   â””â”€â”€ Log_Transformation/\n",
    "â”œâ”€â”€ Nitrogen deficiency/             # Extra nitrogen data\n",
    "â”œâ”€â”€ ThorCam_semiFiltered/            # Phosphorus data\n",
    "â””â”€â”€ POTASSIUM DEFICIENCY/            # Extra potassium data\n",
    "```\n",
    "\n",
    "### 2ï¸âƒ£ Run All Cells in Order\n",
    "Run each cell sequentially (Shift+Enter):\n",
    "1. Step 1: Imports & Environment Detection\n",
    "2. Step 2: Paths (auto-detects Colab vs Local)\n",
    "3. Step 3: Configuration\n",
    "4. Step 4: Combine datasets (creates balanced cache)\n",
    "5. Step 5: Train/Val/Test splits\n",
    "6. Step 6: Create data pipeline\n",
    "7. Step 7: Build model\n",
    "8. Step 8: Class weights\n",
    "9. Step 9: Callbacks\n",
    "10. Steps 10-12: Training phases\n",
    "11. Steps 13-16: Evaluation and save\n",
    "\n",
    "### 3ï¸âƒ£ Training Time Estimates\n",
    "| Environment | Phase 1 | Phase 2 | Phase 3 | Total |\n",
    "|-------------|---------|---------|---------|-------|\n",
    "| Colab GPU (T4) | ~15 min | ~20 min | ~15 min | ~50 min |\n",
    "| Local CPU | ~45 min | ~60 min | ~75 min | ~3 hours |\n",
    "| Local GPU | ~20 min | ~30 min | ~25 min | ~1.25 hours |\n",
    "\n",
    "### 4ï¸âƒ£ After Training\n",
    "- Model saved as `plantvillage-npk-v3.h5`\n",
    "- If on Colab: Download from Google Drive\n",
    "- Update backend to use the new model\n",
    "- Test with the frontend app\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’¡ Tips:**\n",
    "\n",
    "- On Colab: Use GPU runtime (Runtime â†’ Change runtime type â†’ GPU)\n",
    "- Use smaller batch size (8-16) for CPU training\n",
    "- Monitor memory usage during training\n",
    "- Early stopping will kick in if validation loss plateaus\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
