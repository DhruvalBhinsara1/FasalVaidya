# ğŸŒ¾ FasalVaidya

**AI-Powered Crop Health Diagnosis Platform**

FasalVaidya is an intelligent mobile application that uses machine learning to diagnose crop nutrient deficiencies (NPK - Nitrogen, Phosphorus and Potassium) by analyzing leaf images. Built with React Native (Expo) and Flask, it provides farmers with instant, accurate crop health assessments and personalized fertilizer recommendations.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)[![React Native](https://img.shields.io/badge/React%20Native-0.81.5-61DAFB.svg)](https://reactnative.dev/)[![Expo](https://img.shields.io/badge/Expo-~54.0.0-000020.svg)](https://expo.dev/)[![Flask](https://img.shields.io/badge/Flask-3.0.0-green.svg)](https://flask.palletsprojects.com/)[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15+-FF6F00.svg)](https://www.tensorflow.org/)

---

## âœ¨ Features

-   **ğŸ“· Camera-Based Scanning**: Capture and analyze crop leaf images in real-time
-   **ğŸ¤– AI-Powered Diagnosis**: Deep learning models detect NPK+Mg deficiencies with confidence scores
-   ```plaintext
    ğŸŒ¾ Multi-Crop Support: Supports 9 crops (Rice, Wheat, Maize, Banana, Coffee, Ashgourd, EggPlant, Snakegourd, Bittergourd)
    ```
    
-   **ğŸ“Š Visual Analysis**: Heatmap overlays showing nutrient deficiency areas
-   **ğŸ’¡ Smart Recommendations**: Crop-specific fertilizer suggestions with dosage information
-   **ğŸ“œ Scan History**: Track all your diagnoses with detailed results

### ğŸŒ Accessibility & Localization

-   **ğŸ”Š Text-to-Speech**: Audio narration of diagnosis results
-   **ğŸŒ Multi-Language Support**: 10+ languages including English, Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam, and Punjabi
-   **ğŸ“± Mobile-First Design**: Optimized for smartphones with offline capabilities

### ğŸ¨ User Experience

-   **Modern UI/UX**: Clean, intuitive interface following Material Design principles
-   **Real-Time Processing**: Fast inference (<500ms) using optimized TensorFlow Lite models
-   **Confidence Indicators**: Visual feedback on prediction reliability
-   **Product Suggestions**: Integrated fertilizer product recommendations

---

## ğŸ—ï¸ Architecture

```
FasalVaidya/â”œâ”€â”€ backend/                 # Flask API serverâ”‚   â”œâ”€â”€ app.py              # Main Flask applicationâ”‚   â”œâ”€â”€ ml/                 # Machine Learning models & inferenceâ”‚   â”‚   â”œâ”€â”€ unified_inference.pyâ”‚   â”‚   â”œâ”€â”€ models/         # Trained model files (.keras, .tflite)â”‚   â”‚   â””â”€â”€ train_*.py      # Training scriptsâ”‚   â”œâ”€â”€ uploads/           # User-uploaded imagesâ”‚   â”œâ”€â”€ logs/               # Application logsâ”‚   â””â”€â”€ requirements.txt    # Python dependenciesâ”‚â”œâ”€â”€ frontend/               # React Native Expo appâ”‚   â”œâ”€â”€ src/â”‚   â”‚   â”œâ”€â”€ screens/        # App screens (Home, Camera, Results, History)â”‚   â”‚   â”œâ”€â”€ components/     # Reusable UI componentsâ”‚   â”‚   â”œâ”€â”€ api/            # API client & endpointsâ”‚   â”‚   â”œâ”€â”€ i18n/           # Internationalizationâ”‚   â”‚   â””â”€â”€ theme/          # Design systemâ”‚   â”œâ”€â”€ App.tsx             # Main entry pointâ”‚   â””â”€â”€ package.json        # Node dependenciesâ”‚â””â”€â”€ guidelines/             # Documentation & training guides    â”œâ”€â”€ QUICK_START_V2.md    â”œâ”€â”€ UNIFIED_V2_TRAINING_PLAN.md    â””â”€â”€ V2_DEPLOYMENT_SUMMARY.md
```

---

## ğŸ› ï¸ Tech Stack

### Frontend (Mobile App)

-   **React Native** (0.81.5) - Cross-platform mobile framework
-   **Expo** (~54.0.0) - Development platform and tooling
-   **TypeScript** - Type-safe JavaScript
-   **React Navigation** - Navigation library
-   **Expo Camera** - Camera integration
-   **Axios** - HTTP client for API calls
-   **i18n-js** - Internationalization

### Backend (API Server)

-   **Flask** (3.0.0) - Python web framework
-   **Python** (3.11+) - Programming language
-   **SQLite** - Database
-   **Flask-CORS** - Cross-origin resource sharing

### Machine Learning

-   **TensorFlow** (2.15+) - Deep learning framework
-   **TensorFlow Lite** - Mobile-optimized inference
-   **MobileNetV2** - Base model architecture (transfer learning)
-   **NumPy** - Numerical computing
-   **Pillow** - Image processing
-   **scikit-learn** - Machine learning utilities

### Development Tools

-   **VS Code** - IDE with custom tasks and keybindings
-   **pytest** - Testing framework
-   **Git** - Version control

---

## ğŸš€ Quick Start

### Prerequisites

-   **Python 3.11+** (for backend)
-   **Node.js 18+** and **npm** (for frontend)
-   **Expo CLI** (`npm install -g expo-cli`)
-   **SQLite** (included with Python)

### Backend Setup

1.  **Navigate to backend directory**
    
    ```bash
    cd backend
    ```
    
2.  **Create virtual environment** (recommended)
    
    ```bash
    python -m venv .venv311# Windows.venv311Scriptsactivate# Linux/Macsource .venv311/bin/activate
    ```
    
3.  **Install dependencies**
    
    ```bash
    pip install -r requirements.txt
    ```
    
4.  **Initialize database** (auto-created on first run)
    
    ```bash
    python app.py
    ```
    
5.  **Start Flask server**
    
    ```bash
    python app.py
    ```
    
    Server runs on `http://localhost:5000` by default
    

### Frontend Setup

1.  **Navigate to frontend directory**
    
    ```bash
    cd frontend
    ```
    
2.  **Install dependencies**
    
    ```bash
    npm install
    ```
    
3.  **Start Expo development server**
    
    ```bash
    npm start# ornpx expo start --tunnel
    ```
    
4.  **Run on device**
    
    -   Scan QR code with Expo Go app (iOS/Android)
    -   Or press `a` for Android, `i` for iOS simulator

### Environment Variables

Create a `.env` file in the `backend/` directory (optional):

```env
FLASK_ENV=developmentFASALVAIDYA_LOG_LEVEL=INFOFASALVAIDYA_LOG_CONSOLE=1
```

---

## ğŸ“± Supported Crops

Crop

Classes

Status

Accuracy

ğŸŒ¾ Rice

4

âœ… Active

92-97%

ğŸŒ¾ Wheat

3

âœ… Active

81-90%

ğŸŒ½ Maize

4

âœ… Active

74-96%

ğŸŒ Banana

3

âœ… Active

95-97%

â˜• Coffee

4

âœ… Active

85-92%

ğŸ¥’ Ashgourd

7

âœ… Active

88-94%

ğŸ† EggPlant

4

âœ… Active

82-88%

ğŸ Snakegourd

5

âœ… Active

82-88%

ğŸ¥’ Bittergourd

9

âœ… Active

80-86%

**Total: 9 crops, 43 nutrient deficiency classes**

---

## ğŸ¤– Machine Learning Models

### Custom Dataset

Our machine learning models were trained on a **custom dataset** that we created by gathering and curating images from multiple sources. This comprehensive dataset includes:

-   **PlantVillage Dataset**: Crop disease and health images
-   **Kaggle Leaf Nutrient Dataset**: Nutrient deficiency samples
-   **Additional Sources**: Curated images from various agricultural research databases
-   **Total Training Images**: ~40,000+ images across 9 crops and 43 nutrient deficiency classes

The dataset was carefully organized, labeled, and preprocessed to ensure high-quality training data for accurate NPK deficiency detection. Each image was manually verified and categorized by crop type and nutrient deficiency status (healthy, nitrogen-deficient, phosphorus-deficient, potassium-deficient, etc.).

### Model Architecture

-   **Base Model**: Transfer learning from MobileNetV2
-   **Input Size**: 224x224x3 RGB images
-   **Output**: 43-class classification (crop + nutrient deficiency)
-   **Optimization**: Quantized TensorFlow Lite for mobile deployment

### Model Files

-   **Backend**: `unified_v2_nutrient_best.keras` (15.7 MB)
-   **Mobile**: `fasalvaidya_unified_v2.tflite` (3.0 MB)
-   **Labels**: `unified_v2_labels.txt` (43 classes)
-   **Metadata**: `unified_v2_model_metadata.json`

### Performance Metrics

-   **Overall Accuracy**: 72.5%
-   **Top-3 Accuracy**: 89.7%
-   **Inference Time**: <500ms (mobile)
-   **Model Size**: 3.0 MB (TFLite)

---

## ğŸ“š API Documentation

### Endpoints

#### `POST /api/scans`

Upload a leaf image for diagnosis.

**Request:**

```json
{  "crop_id": 1,  "image": "<base64_encoded_image>"}
```

**Response:**

```json
{  "scan_id": "uuid",  "crop_name": "Wheat",  "n_score": 75,  "p_score": 82,  "k_score": 68,  "mg_score": 70,  "n_severity": "attention",  "p_severity": "healthy",  "k_severity": "attention",  "overall_status": "attention",  "recommendations": {...},  "image_url": "/uploads/...",  "heatmap_url": "/uploads/heatmap_..."}
```

#### `GET /api/scans`

Retrieve scan history.

#### `GET /api/scans/{scan_id}`

Get specific scan details.

#### `GET /api/crops`

List all supported crops.

---

## ğŸ§ª Testing

### Backend Tests

```bash
cd backendpytest tests/
```

### API Tests

```bash
cd backendpython tests/test_api.py
```

---

## ğŸ“ Training New Models

See detailed guides in the `guidelines/` directory:

-   **Quick Start**: [`QUICK_START_V2.md`](guidelines/QUICK_START_V2.md)
-   **Training Plan**: [`UNIFIED_V2_TRAINING_PLAN.md`](guidelines/UNIFIED_V2_TRAINING_PLAN.md)
-   **Deployment**: [`V2_DEPLOYMENT_SUMMARY.md`](guidelines/V2_DEPLOYMENT_SUMMARY.md)

### Quick Training Steps

1.  **Prepare dataset**
    
    ```bash
    cd backend/mlpython prepare_unified_v2_dataset.py
    ```
    
2.  **Train model** (requires GPU)
    
    ```bash
    python train_unified_v2.py
    ```
    
3.  **Convert to TFLite**
    
    ```bash
    python convert_to_tflite.py
    ```
    

---

## ğŸ› ï¸ Development

### VS Code Setup

The project includes VS Code configuration:

-   **Tasks**: Pre-configured tasks for running backend/frontend
-   **Keybindings**: Custom shortcuts (Ctrl+Shift+B to start all)
-   **Settings**: Python path, formatters, and workspace settings

### Running Both Services

**Option 1: VS Code Tasks**

-   Press `Ctrl+Shift+B` to start both backend and frontend

**Option 2: Manual**

```bash
# Terminal 1 - Backendcd backendpython app.py# Terminal 2 - Frontendcd frontendnpm start
```

---

## ğŸ¤ Contributing

1.  Fork the repository
2.  Create a feature branch (`git checkout -b feature/amazing-feature`)
3.  Commit your changes (`git commit -m 'Add amazing feature'`)
4.  Push to the branch (`git push origin feature/amazing-feature`)
5.  Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

-   **Custom Dataset**: We created a comprehensive custom dataset by gathering and curating images from multiple sources including PlantVillage, Kaggle Leaf Nutrient Dataset, and other agricultural research databases
-   **PlantVillage Dataset** - Source for crop disease images
-   **Kaggle Leaf Nutrient Dataset** - Source for nutrient deficiency samples
-   **TensorFlow** - Machine learning framework
-   **Expo** - React Native development platform
-   **Flask** - Python web framework

---

## ğŸ“ Support

For issues, questions:

-   Open an issue on GitHub
-   Check the `guidelines/` directory for detailed documentation
-   Review API logs in `backend/logs/backend.log`
-   Contact : [dhruvalbhinsara460@gmail.com](mailto:dhruvalbhinsara460@gmail.com)

---

## ğŸ”® Roadmap

-    Implement real-time camera preview with ML overlay
-    Offline mode with local model inference
-    Add fertilizer product marketplace integration
-    Implement user accounts and cloud sync
-    Add expert consultation chat feature
-    Support for more nutrient deficiencies

---

**Made with â¤ï¸ for farmers worldwide**