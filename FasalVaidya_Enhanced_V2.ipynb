{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ FasalVaidya Enhanced Training V2\n",
        "\n",
        "**Key Features:**\n",
        "- Binary Leaf Validator (rejects non-leaf images)\n",
        "- PlantVillage Pre-training (smart download)\n",
        "- Two-Phase Fine-Tuning (freeze â†’ unfreeze)\n",
        "- Confidence-Based Predictions (high/medium/low)\n",
        "- RAM Optimized for Colab\n",
        "\n",
        "**Training Time:** ~2 hours on T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install and import packages\n",
        "!pip install -q tensorflow>=2.15.0 kaggle opendatasets scikit-learn matplotlib seaborn\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(f\"TensorFlow: {tf.__version__}\")\n",
        "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "SESSION_START = datetime.now()\n",
        "print(f\"Session: {SESSION_START.strftime('%H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# CONFIGURATION - RAM OPTIMIZED\n",
        "# =============================================================\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16  # Reduced for RAM\n",
        "\n",
        "# Epochs\n",
        "LEAF_VALIDATOR_EPOCHS = 5\n",
        "PLANTVILLAGE_EPOCHS = 6\n",
        "FROZEN_EPOCHS = 6\n",
        "FINETUNE_EPOCHS = 4\n",
        "\n",
        "# Learning rates\n",
        "LR_FROZEN = 1e-3\n",
        "LR_FINETUNE = 1e-5\n",
        "\n",
        "# Confidence thresholds\n",
        "CONF_HIGH = 0.85\n",
        "CONF_LOW = 0.50\n",
        "\n",
        "# Paths\n",
        "OUTPUT_DIR = '/content/fasalvaidya_enhanced'\n",
        "DRIVE_CHECKPOINT = '/content/drive/MyDrive/FasalVaidya_Enhanced_Checkpoints'\n",
        "PLANTVILLAGE_PATH = '/content/plantvillage'\n",
        "NUTRIENT_ROOT = '/content/local_nutrients'\n",
        "UNIFIED_PATH = '/content/unified_dataset'\n",
        "LEAF_DATA_PATH = '/content/leaf_validation_data'\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(DRIVE_CHECKPOINT, exist_ok=True)\n",
        "\n",
        "# GPU config - Memory optimized\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "tf.config.optimizer.set_jit(False)  # Disable JIT to save RAM\n",
        "tf.keras.mixed_precision.set_global_policy('float32')\n",
        "\n",
        "# Crops\n",
        "CROP_DATASETS = {\n",
        "    'rice': 'Rice Nutrients',\n",
        "    'wheat': 'Wheat Nitrogen',\n",
        "    'maize': 'Maize Nutrients',\n",
        "    'banana': 'Banana leaves Nutrient',\n",
        "    'coffee': 'Coffee Nutrients',\n",
        "    'ashgourd': 'Ashgourd Nutrients',\n",
        "    'eggplant': 'EggPlant Nutrients',\n",
        "    'snakegourd': 'Snakegourd Nutrients',\n",
        "    'bittergourd': 'Bittergourd Nutrients',\n",
        "}\n",
        "\n",
        "print(f\"âœ… Config: {len(CROP_DATASETS)} crops, batch={BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”‘ Kaggle & PlantVillage (Smart Download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Smart detection\n",
        "KAGGLE_CONFIG = os.path.expanduser('~/.kaggle/kaggle.json')\n",
        "USE_PLANTVILLAGE = True\n",
        "\n",
        "def check_kaggle():\n",
        "    if os.path.exists(KAGGLE_CONFIG):\n",
        "        try:\n",
        "            with open(KAGGLE_CONFIG) as f:\n",
        "                if 'username' in f.read():\n",
        "                    return True\n",
        "        except: pass\n",
        "    return False\n",
        "\n",
        "def find_plantvillage():\n",
        "    paths = ['/content/plantvillage/plantdisease/PlantVillage',\n",
        "             '/content/plantvillage/PlantVillage',\n",
        "             '/content/drive/MyDrive/PlantVillage']\n",
        "    for p in paths:\n",
        "        if os.path.exists(p) and len(os.listdir(p)) >= 15:\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "kaggle_ok = check_kaggle()\n",
        "pv_path = find_plantvillage()\n",
        "print(f'Kaggle: {\"âœ…\" if kaggle_ok else \"âŒ\"} | PlantVillage: {\"âœ… \" + pv_path if pv_path else \"âŒ\"}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle setup if needed\n",
        "if USE_PLANTVILLAGE and not pv_path and not kaggle_ok:\n",
        "    print('ðŸ“¤ Upload kaggle.json (https://kaggle.com/settings â†’ API â†’ Create Token)')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if 'kaggle.json' in uploaded:\n",
        "        !mkdir -p ~/.kaggle && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "        print('âœ… Kaggle configured')\n",
        "        kaggle_ok = True\n",
        "    else:\n",
        "        USE_PLANTVILLAGE = False\n",
        "elif pv_path:\n",
        "    print('âœ… PlantVillage exists, skipping setup')\n",
        "else:\n",
        "    print('âœ… Kaggle ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download PlantVillage if needed\n",
        "if USE_PLANTVILLAGE:\n",
        "    pv_path = find_plantvillage()\n",
        "    if pv_path:\n",
        "        PLANTVILLAGE_PATH = pv_path\n",
        "        print(f'âœ… Using existing: {PLANTVILLAGE_PATH}')\n",
        "    else:\n",
        "        print('ðŸ“¥ Downloading PlantVillage (~3-5 min)...')\n",
        "        import opendatasets as od\n",
        "        os.makedirs('/content/plantvillage', exist_ok=True)\n",
        "        od.download('https://www.kaggle.com/datasets/emmarex/plantdisease', data_dir='/content/plantvillage')\n",
        "        pv_path = find_plantvillage()\n",
        "        if pv_path:\n",
        "            PLANTVILLAGE_PATH = pv_path\n",
        "            print(f'âœ… Downloaded: {len(os.listdir(PLANTVILLAGE_PATH))} classes')\n",
        "        else:\n",
        "            print('âš ï¸ Download failed, skipping')\n",
        "            USE_PLANTVILLAGE = False\n",
        "else:\n",
        "    print('â„¹ï¸ PlantVillage skipped')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ Nutrient Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find nutrient dataset\n",
        "search = ['/content/drive/MyDrive/Leaf Nutrient Data Sets']\n",
        "shortcut_dir = '/content/drive/MyDrive/.shortcut-targets-by-id'\n",
        "if os.path.exists(shortcut_dir):\n",
        "    for fid in os.listdir(shortcut_dir):\n",
        "        t = os.path.join(shortcut_dir, fid, 'Leaf Nutrient Data Sets')\n",
        "        if os.path.exists(t): search.append(t)\n",
        "\n",
        "DRIVE_NUTRIENT = None\n",
        "for p in search:\n",
        "    if os.path.exists(p) and len(os.listdir(p)) >= 5:\n",
        "        DRIVE_NUTRIENT = p\n",
        "        break\n",
        "\n",
        "if not DRIVE_NUTRIENT:\n",
        "    raise FileNotFoundError('Dataset not found! Add shortcut to My Drive.')\n",
        "print(f'âœ… Found: {DRIVE_NUTRIENT}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy to local SSD\n",
        "os.makedirs(NUTRIENT_ROOT, exist_ok=True)\n",
        "print('Copying to SSD...')\n",
        "for crop, folder in CROP_DATASETS.items():\n",
        "    src = os.path.join(DRIVE_NUTRIENT, folder)\n",
        "    dst = os.path.join(NUTRIENT_ROOT, folder)\n",
        "    if os.path.exists(dst) and sum(1 for _ in Path(dst).rglob('*.jpg')) > 50:\n",
        "        print(f'  {crop}: exists')\n",
        "        continue\n",
        "    if os.path.exists(src):\n",
        "        print(f'  {crop}: copying...', end=' ')\n",
        "        if os.path.exists(dst): shutil.rmtree(dst)\n",
        "        shutil.copytree(src, dst)\n",
        "        print('âœ…')\n",
        "print(f'âœ… Data on SSD')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŒ¿ Part 1: Leaf Validator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create leaf validation data\n",
        "os.makedirs(f'{LEAF_DATA_PATH}/leaf', exist_ok=True)\n",
        "os.makedirs(f'{LEAF_DATA_PATH}/non_leaf', exist_ok=True)\n",
        "\n",
        "# Collect leaf samples\n",
        "print('Collecting leaves...')\n",
        "leaf_count = 0\n",
        "for crop, folder in CROP_DATASETS.items():\n",
        "    crop_path = os.path.join(NUTRIENT_ROOT, folder)\n",
        "    if not os.path.exists(crop_path): continue\n",
        "    for root, dirs, files in os.walk(crop_path):\n",
        "        imgs = [f for f in files if f.lower().endswith(('.jpg', '.png'))][:20]\n",
        "        for img in imgs:\n",
        "            shutil.copy2(os.path.join(root, img), f'{LEAF_DATA_PATH}/leaf/{crop}_{leaf_count}_{img}')\n",
        "            leaf_count += 1\n",
        "        if leaf_count > 150: break\n",
        "print(f'âœ… {leaf_count} leaf images')\n",
        "\n",
        "# Generate non-leaf\n",
        "from PIL import Image\n",
        "for i in range(leaf_count):\n",
        "    if i % 4 == 0:\n",
        "        img = Image.new('RGB', (224,224), (random.randint(0,255), random.randint(0,255), random.randint(0,255)))\n",
        "    elif i % 4 == 1:\n",
        "        img = Image.fromarray(np.random.randint(0, 256, (224,224,3), dtype=np.uint8))\n",
        "    elif i % 4 == 2:\n",
        "        arr = np.zeros((224,224,3), dtype=np.uint8)\n",
        "        for y in range(224): arr[y,:,:] = [y, 128, 255-y]\n",
        "        img = Image.fromarray(arr)\n",
        "    else:\n",
        "        arr = np.clip(np.random.randint(-20, 20, (224,224,3)) + [139,90,43], 0, 255).astype(np.uint8)\n",
        "        img = Image.fromarray(arr)\n",
        "    img.save(f'{LEAF_DATA_PATH}/non_leaf/syn_{i:04d}.jpg')\n",
        "print(f'âœ… {leaf_count} non-leaf images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets - save class_names BEFORE transforming\n",
        "train_leaf_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    LEAF_DATA_PATH, validation_split=0.2, subset='training', seed=42,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='binary')\n",
        "val_leaf_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    LEAF_DATA_PATH, validation_split=0.2, subset='validation', seed=42,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='binary')\n",
        "\n",
        "leaf_class_names = train_leaf_raw.class_names  # Save before transform!\n",
        "\n",
        "def norm(img, lbl):\n",
        "    return tf.keras.applications.mobilenet_v2.preprocess_input(tf.cast(img, tf.float32)), lbl\n",
        "\n",
        "train_leaf = train_leaf_raw.map(norm).prefetch(tf.data.AUTOTUNE)\n",
        "val_leaf = val_leaf_raw.map(norm).prefetch(tf.data.AUTOTUNE)\n",
        "print(f'Leaf classes: {leaf_class_names}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build and train leaf validator\n",
        "base_v = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False, weights='imagenet')\n",
        "base_v.trainable = False\n",
        "\n",
        "leaf_validator = tf.keras.Sequential([\n",
        "    base_v,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', dtype='float32')\n",
        "], name='leaf_validator')\n",
        "\n",
        "leaf_validator.compile(optimizer=tf.keras.optimizers.Adam(LR_FROZEN), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(f'ðŸŒ¿ Training Leaf Validator ({LEAF_VALIDATOR_EPOCHS} epochs)')\n",
        "h_leaf = leaf_validator.fit(train_leaf, validation_data=val_leaf, epochs=LEAF_VALIDATOR_EPOCHS,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
        "               tf.keras.callbacks.ModelCheckpoint(f'{OUTPUT_DIR}/leaf_validator.keras', save_best_only=True)])\n",
        "leaf_acc = max(h_leaf.history['val_accuracy'])\n",
        "print(f'âœ… Leaf Validator: {leaf_acc:.1%}')\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŒ± Part 2a: PlantVillage Pre-training (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PRETRAINED_BASE = None\n",
        "if USE_PLANTVILLAGE and os.path.exists(PLANTVILLAGE_PATH):\n",
        "    print(f'ðŸŒ± PlantVillage ({PLANTVILLAGE_EPOCHS} epochs)')\n",
        "    train_pv_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "        PLANTVILLAGE_PATH, validation_split=0.2, subset='training', seed=42,\n",
        "        image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
        "    val_pv_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "        PLANTVILLAGE_PATH, validation_split=0.2, subset='validation', seed=42,\n",
        "        image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
        "    \n",
        "    pv_classes = train_pv_raw.class_names\n",
        "    train_pv = train_pv_raw.map(norm).prefetch(tf.data.AUTOTUNE)\n",
        "    val_pv = val_pv_raw.map(norm).prefetch(tf.data.AUTOTUNE)\n",
        "    \n",
        "    base_pv = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False, weights='imagenet')\n",
        "    base_pv.trainable = False\n",
        "    model_pv = tf.keras.Sequential([base_pv, tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dropout(0.3), tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(len(pv_classes), activation='softmax', dtype='float32')])\n",
        "    model_pv.compile(optimizer=tf.keras.optimizers.Adam(LR_FROZEN), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    h_pv = model_pv.fit(train_pv, validation_data=val_pv, epochs=PLANTVILLAGE_EPOCHS,\n",
        "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)])\n",
        "    print(f'âœ… PlantVillage: {max(h_pv.history[\"val_accuracy\"]):.1%}')\n",
        "    PRETRAINED_BASE = base_pv\n",
        "    del train_pv, val_pv, train_pv_raw, val_pv_raw, model_pv\n",
        "    gc.collect()\n",
        "else:\n",
        "    print('â„¹ï¸ Skipping PlantVillage')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŒ¾ Part 2b: Disease Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build unified dataset - handles all folder structures\n",
        "if os.path.exists(UNIFIED_PATH): shutil.rmtree(UNIFIED_PATH)\n",
        "os.makedirs(UNIFIED_PATH)\n",
        "\n",
        "CLASS_RENAME = {\n",
        "    'rice': {'Nitrogen(N)': 'rice_nitrogen', 'Phosphorus(P)': 'rice_phosphorus', 'Potassium(K)': 'rice_potassium'},\n",
        "    'wheat': {'control': 'wheat_control', 'deficiency': 'wheat_deficiency'},\n",
        "    'maize': {'ALL Present': 'maize_all_present', 'ALLAB': 'maize_allab', 'KAB': 'maize_kab', 'NAB': 'maize_nab', 'PAB': 'maize_pab', 'ZNAB': 'maize_znab'},\n",
        "    'banana': {'healthy': 'banana_healthy', 'magnesium': 'banana_magnesium', 'potassium': 'banana_potassium'},\n",
        "    'coffee': {'healthy': 'coffee_healthy', 'nitrogen-N': 'coffee_nitrogen', 'phosphorus-P': 'coffee_phosphorus', 'potasium-K': 'coffee_potassium'},\n",
        "}\n",
        "\n",
        "def get_cls(crop, orig):\n",
        "    if crop in CLASS_RENAME and orig in CLASS_RENAME[crop]: return CLASS_RENAME[crop][orig]\n",
        "    return f\"{crop}_{orig.lower().replace(' ', '_').replace('-', '_')}\"\n",
        "\n",
        "def copy_imgs(src, dst, prefix):\n",
        "    cnt = 0\n",
        "    if not os.path.exists(src): return 0\n",
        "    for f in os.listdir(src):\n",
        "        if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            shutil.copy2(os.path.join(src, f), os.path.join(dst, f'{prefix}_{f}'))\n",
        "            cnt += 1\n",
        "    return cnt\n",
        "\n",
        "print('Building unified dataset...')\n",
        "class_counts = {}\n",
        "for crop, folder in CROP_DATASETS.items():\n",
        "    crop_path = os.path.join(NUTRIENT_ROOT, folder)\n",
        "    if not os.path.exists(crop_path): continue\n",
        "    crop_imgs = 0\n",
        "    for item in os.listdir(crop_path):\n",
        "        item_path = os.path.join(crop_path, item)\n",
        "        if not os.path.isdir(item_path): continue\n",
        "        \n",
        "        if item.lower() in ['train', 'test', 'val', 'validation']:\n",
        "            for cls in os.listdir(item_path):\n",
        "                cls_path = os.path.join(item_path, cls)\n",
        "                if os.path.isdir(cls_path):\n",
        "                    uc = get_cls(crop, cls)\n",
        "                    dst = os.path.join(UNIFIED_PATH, uc)\n",
        "                    os.makedirs(dst, exist_ok=True)\n",
        "                    n = copy_imgs(cls_path, dst, f'{crop}_{item}')\n",
        "                    class_counts[uc] = class_counts.get(uc, 0) + n\n",
        "                    crop_imgs += n\n",
        "        else:\n",
        "            uc = get_cls(crop, item)\n",
        "            dst = os.path.join(UNIFIED_PATH, uc)\n",
        "            os.makedirs(dst, exist_ok=True)\n",
        "            subs = os.listdir(item_path)\n",
        "            if any(s.lower() in ['train', 'test', 'val', 'validation'] for s in subs):\n",
        "                for sp in subs:\n",
        "                    sp_path = os.path.join(item_path, sp)\n",
        "                    if os.path.isdir(sp_path):\n",
        "                        n = copy_imgs(sp_path, dst, f'{crop}_{item}_{sp}')\n",
        "                        class_counts[uc] = class_counts.get(uc, 0) + n\n",
        "                        crop_imgs += n\n",
        "            else:\n",
        "                n = copy_imgs(item_path, dst, crop)\n",
        "                class_counts[uc] = class_counts.get(uc, 0) + n\n",
        "                crop_imgs += n\n",
        "    print(f'  {crop}: {crop_imgs}')\n",
        "\n",
        "class_names = sorted(class_counts.keys())\n",
        "num_classes = len(class_names)\n",
        "total_images = sum(class_counts.values())\n",
        "print(f'\\nâœ… {num_classes} classes, {total_images:,} images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "class_weight = {i: total_images / (num_classes * class_counts.get(c, 1)) for i, c in enumerate(class_names)}\n",
        "\n",
        "train_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    UNIFIED_PATH, validation_split=0.2, subset='training', seed=42,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
        "val_raw = tf.keras.utils.image_dataset_from_directory(\n",
        "    UNIFIED_PATH, validation_split=0.2, subset='validation', seed=42,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
        "\n",
        "class_names = train_raw.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "aug = tf.keras.Sequential([tf.keras.layers.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.RandomRotation(0.05), tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomBrightness(0.1), tf.keras.layers.RandomContrast(0.1)])\n",
        "\n",
        "@tf.function\n",
        "def aug_norm(img, lbl): return tf.keras.applications.mobilenet_v2.preprocess_input(aug(img, training=True)), lbl\n",
        "@tf.function\n",
        "def norm_only(img, lbl): return tf.keras.applications.mobilenet_v2.preprocess_input(tf.cast(img, tf.float32)), lbl\n",
        "\n",
        "train_ds = train_raw.map(aug_norm, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(norm_only, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
        "print(f'âœ… {num_classes} classes ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build disease model\n",
        "if PRETRAINED_BASE is not None:\n",
        "    print('Using PlantVillage base')\n",
        "    base_model = PRETRAINED_BASE\n",
        "else:\n",
        "    print('Using ImageNet base')\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False, weights='imagenet')\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "disease_model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')\n",
        "], name='disease_classifier')\n",
        "\n",
        "disease_model.compile(optimizer=tf.keras.optimizers.Adam(LR_FROZEN), loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3')])\n",
        "print(f'âœ… Model ready: {num_classes} classes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 1: Frozen\n",
        "print(f'\\nðŸ”’ Phase 1: Frozen ({FROZEN_EPOCHS} epochs)')\n",
        "h1 = disease_model.fit(train_ds, validation_data=val_ds, epochs=FROZEN_EPOCHS, class_weight=class_weight,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "               tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)])\n",
        "p1_acc = max(h1.history['val_accuracy'])\n",
        "print(f'âœ… Phase 1: {p1_acc:.1%}')\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 2: Fine-tune\n",
        "print(f'\\nðŸ”“ Phase 2: Fine-tune ({FINETUNE_EPOCHS} epochs)')\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-30]: layer.trainable = False\n",
        "\n",
        "disease_model.compile(optimizer=tf.keras.optimizers.Adam(LR_FINETUNE), loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3')])\n",
        "\n",
        "h2 = disease_model.fit(train_ds, validation_data=val_ds, epochs=FINETUNE_EPOCHS, class_weight=class_weight,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
        "               tf.keras.callbacks.ModelCheckpoint(f'{OUTPUT_DIR}/disease_final.keras', save_best_only=True),\n",
        "               tf.keras.callbacks.ModelCheckpoint(f'{DRIVE_CHECKPOINT}/disease_final.keras', save_best_only=True)])\n",
        "p2_acc = max(h2.history['val_accuracy'])\n",
        "print(f'âœ… Phase 2: {p2_acc:.1%}')\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate\n",
        "print('Evaluating...')\n",
        "y_true, y_pred, y_probs = [], [], []\n",
        "for imgs, lbls in val_ds:\n",
        "    preds = disease_model.predict(imgs, verbose=0)\n",
        "    y_true.extend(np.argmax(lbls.numpy(), axis=1))\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "    y_probs.extend(np.max(preds, axis=1))\n",
        "\n",
        "y_true, y_pred, y_probs = np.array(y_true), np.array(y_pred), np.array(y_probs)\n",
        "acc = (y_true == y_pred).mean()\n",
        "print(f'\\nðŸ“Š Accuracy: {acc:.1%}')\n",
        "\n",
        "high = (y_probs >= CONF_HIGH).sum()\n",
        "med = ((y_probs >= CONF_LOW) & (y_probs < CONF_HIGH)).sum()\n",
        "low = (y_probs < CONF_LOW).sum()\n",
        "print(f'Confidence: High {high/len(y_probs):.0%} | Med {med/len(y_probs):.0%} | Low {low/len(y_probs):.0%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ’¾ Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export leaf validator\n",
        "print('Exporting leaf validator...')\n",
        "conv = tf.lite.TFLiteConverter.from_keras_model(leaf_validator)\n",
        "conv.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tfl = conv.convert()\n",
        "with open(f'{OUTPUT_DIR}/leaf_validator.tflite', 'wb') as f: f.write(tfl)\n",
        "with open(f'{DRIVE_CHECKPOINT}/leaf_validator.tflite', 'wb') as f: f.write(tfl)\n",
        "print(f'âœ… {len(tfl)/1024/1024:.1f} MB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export disease model\n",
        "print('Exporting disease model...')\n",
        "tf.keras.backend.clear_session()\n",
        "best = tf.keras.models.load_model(f'{OUTPUT_DIR}/disease_final.keras')\n",
        "_ = best(tf.zeros((1,224,224,3), dtype=tf.float32), training=False)\n",
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec([1,224,224,3], tf.float32)])\n",
        "def serve(x): return best(x, training=False)\n",
        "\n",
        "conv = tf.lite.TFLiteConverter.from_concrete_functions([serve.get_concrete_function()])\n",
        "conv.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "try: tfl = conv.convert()\n",
        "except:\n",
        "    conv.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "    tfl = conv.convert()\n",
        "\n",
        "with open(f'{OUTPUT_DIR}/fasalvaidya_enhanced.tflite', 'wb') as f: f.write(tfl)\n",
        "with open(f'{DRIVE_CHECKPOINT}/fasalvaidya_enhanced.tflite', 'wb') as f: f.write(tfl)\n",
        "print(f'âœ… {len(tfl)/1024/1024:.1f} MB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save metadata\n",
        "meta = {'version': '2.0', 'date': datetime.now().isoformat(), 'classes': num_classes,\n",
        "        'class_names': class_names, 'thresholds': {'high': CONF_HIGH, 'low': CONF_LOW},\n",
        "        'accuracy': {'overall': float(acc), 'p1': float(p1_acc), 'p2': float(p2_acc)},\n",
        "        'crops': list(CROP_DATASETS.keys())}\n",
        "for d in [OUTPUT_DIR, DRIVE_CHECKPOINT]:\n",
        "    with open(f'{d}/metadata.json', 'w') as f: json.dump(meta, f, indent=2)\n",
        "    with open(f'{d}/labels.txt', 'w') as f: f.write('\\n'.join(class_names))\n",
        "\n",
        "print(f'\\nâœ… DONE! Time: {datetime.now() - SESSION_START}')\n",
        "print(f'Files: {OUTPUT_DIR}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {"display_name": "Python 3", "name": "python3"},
    "language_info": {"name": "python", "version": "3.10.0"}
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
