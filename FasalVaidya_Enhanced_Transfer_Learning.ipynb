{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e188b6",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q tensorflow>=2.15.0 kaggle opendatasets scikit-learn matplotlib seaborn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# =============================================================\n",
    "# ‚è±Ô∏è SESSION TIME TRACKER (Important for 3-hour limit!)\n",
    "# =============================================================\n",
    "SESSION_START_TIME = datetime.now()\n",
    "\n",
    "def get_session_time():\n",
    "    \"\"\"Get elapsed session time\"\"\"\n",
    "    elapsed = datetime.now() - SESSION_START_TIME\n",
    "    hours = elapsed.seconds // 3600\n",
    "    minutes = (elapsed.seconds % 3600) // 60\n",
    "    return f\"{hours}h {minutes}m\"\n",
    "\n",
    "def check_time_limit(warn_minutes=150):\n",
    "    \"\"\"Warn if approaching 3-hour limit (180 min)\"\"\"\n",
    "    elapsed = (datetime.now() - SESSION_START_TIME).seconds // 60\n",
    "    remaining = 180 - elapsed\n",
    "    if elapsed >= warn_minutes:\n",
    "        print(f\"‚ö†Ô∏è WARNING: {remaining} minutes remaining before typical Colab disconnect!\")\n",
    "        print(f\"   Consider saving checkpoints and downloading results now.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Session started at: {SESSION_START_TIME.strftime('%H:%M:%S')}\")\n",
    "print(f\"   You have ~3 hours before Colab may disconnect\")\n",
    "print(f\"   Checkpoints auto-save to Drive (training resumes from checkpoint)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ddc489",
   "metadata": {},
   "source": [
    "## üîë Configuration\n",
    "\n",
    "### Set your crop type and paths here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== UNIFIED MODEL - ALL CROPS ==========\n",
    "# Root path to your \"Leaf Nutrient Data Sets\" folder on Google Drive\n",
    "NUTRIENT_DATASETS_ROOT = '/content/drive/MyDrive/Leaf Nutrient Data Sets'\n",
    "\n",
    "# ALL 12 CROPS - Combined into ONE model automatically!\n",
    "CROP_DATASETS = {\n",
    "    'rice': 'Rice Nutrients',\n",
    "    'wheat': 'Wheat Nitrogen',\n",
    "    'tomato': 'Tomato Nutrients',\n",
    "    'maize': 'Maize Nutrients',\n",
    "    'banana': 'Banana leaves Nutrient',\n",
    "    'coffee': 'Coffee Nutrients',\n",
    "    'cucumber': 'Cucumber Nutrients',\n",
    "    'eggplant': 'EggPlant Nutrients',\n",
    "    'ashgourd': 'Ashgourd Nutrients',\n",
    "    'bittergourd': 'Bittergourd Nutrients',\n",
    "    'ridgegourd': 'Ridgegourd',\n",
    "    'snakegourd': 'Snakegourd Nutrients'\n",
    "}\n",
    "\n",
    "# =============================================================\n",
    "# üöÄ T4 GPU OPTIMIZED SETTINGS (16GB VRAM)\n",
    "# =============================================================\n",
    "# ‚úÖ Optimized for speed + stability on Colab T4\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 128  # T4 can easily handle 128 with MobileNetV2\n",
    "\n",
    "# Training epochs (balanced for 3-hour time limit)\n",
    "PLANTVILLAGE_EPOCHS = 12   # Stage 2: Transfer learning foundation\n",
    "UNIFIED_EPOCHS = 20        # Stage 3: Main nutrient detection training\n",
    "\n",
    "# Learning rates (tuned for Adam + mixed precision)\n",
    "LEARNING_RATE_STAGE2 = 3e-4  # Higher for frozen base\n",
    "LEARNING_RATE_STAGE3 = 1e-4  # Lower for fine-tuning\n",
    "\n",
    "# Regularization (prevents overfitting without underfitting)\n",
    "DROPOUT_RATE = 0.3  # Balanced dropout\n",
    "\n",
    "# Enable mixed precision training (2x speedup on T4)\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "print(\"üöÄ Mixed precision enabled (FP16)\")\n",
    "\n",
    "# Output paths (persistent on Drive for checkpoint resume)\n",
    "OUTPUT_DIR = '/content/fasalvaidya_unified_model'\n",
    "DRIVE_CHECKPOINT_DIR = '/content/drive/MyDrive/FasalVaidya_Checkpoints'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(DRIVE_CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"üåæ UNIFIED MULTI-CROP MODEL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training ONE model for ALL {len(CROP_DATASETS)} crops\")\n",
    "print(f\"\\nüî• T4 GPU OPTIMIZED SETTINGS:\")\n",
    "print(f\"   - Batch size: {BATCH_SIZE} (utilizes 16GB VRAM)\")\n",
    "print(f\"   - Mixed precision: FP16 (2x faster)\")\n",
    "print(f\"   - XLA/JIT compilation: Enabled\")\n",
    "print(f\"   - Local disk I/O: Enabled (10-50x faster reads)\")\n",
    "print(f\"   - Stage 2: {PLANTVILLAGE_EPOCHS} epochs\")\n",
    "print(f\"   - Stage 3: {UNIFIED_EPOCHS} epochs\")\n",
    "print(f\"   - Checkpoints saved to Drive (resume if disconnected)\")\n",
    "print(f\"\\n‚ö° Expected: ~1-2 min/epoch (vs ~10 min without optimizations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ab98b",
   "metadata": {},
   "source": [
    "## üíæ Mount Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2242a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Robust check for already-mounted Drive\n",
    "drive_path = '/content/drive'\n",
    "is_mounted = False\n",
    "\n",
    "if os.path.exists(drive_path):\n",
    "    # Check if directory has content (indicates already mounted)\n",
    "    try:\n",
    "        if os.listdir(drive_path):\n",
    "            is_mounted = True\n",
    "            print(\"‚úÖ Google Drive already mounted!\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if not is_mounted:\n",
    "    print(\"üìÅ Mounting Google Drive...\")\n",
    "    # Clean up if directory exists but is empty\n",
    "    if os.path.exists(drive_path) and not os.listdir(drive_path):\n",
    "        os.rmdir(drive_path)\n",
    "    drive.mount(drive_path)\n",
    "    print(\"‚úÖ Google Drive mounted successfully!\")\n",
    "\n",
    "# =============================================================\n",
    "# üîç SMART PATH DETECTION: Search All Possible Locations\n",
    "# =============================================================\n",
    "print(\"\\nüîç Searching for 'Leaf Nutrient Data Sets' folder...\")\n",
    "\n",
    "# List of possible locations to check\n",
    "search_paths = [\n",
    "    '/content/drive/MyDrive/Leaf Nutrient Data Sets',\n",
    "    '/content/drive/Shareddrives/Leaf Nutrient Data Sets',\n",
    "    '/content/drive/Shared drives/Leaf Nutrient Data Sets',\n",
    "]\n",
    "\n",
    "# Also search for shortcuts and nested locations\n",
    "mydrive_base = '/content/drive/MyDrive'\n",
    "if os.path.exists(mydrive_base):\n",
    "    # Search in .shortcut-targets-by-id (where \"Shared with me\" shortcuts appear)\n",
    "    shortcut_dir = os.path.join(mydrive_base, '.shortcut-targets-by-id')\n",
    "    if os.path.exists(shortcut_dir):\n",
    "        try:\n",
    "            for folder_id in os.listdir(shortcut_dir):\n",
    "                target_path = os.path.join(shortcut_dir, folder_id, 'Leaf Nutrient Data Sets')\n",
    "                if os.path.exists(target_path):\n",
    "                    search_paths.append(target_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Try each location\n",
    "found_location = None\n",
    "\n",
    "for search_path in search_paths:\n",
    "    if os.path.exists(search_path):\n",
    "        # Verify it has crop folders\n",
    "        try:\n",
    "            contents = os.listdir(search_path)\n",
    "            crop_folders = [f for f in contents if os.path.isdir(os.path.join(search_path, f))]\n",
    "            if len(crop_folders) >= 5:  # Should have at least 5 crop folders\n",
    "                print(f\"‚úÖ Found at: {search_path}\")\n",
    "                print(f\"   Contains {len(crop_folders)} folders\")\n",
    "                found_location = search_path\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if found_location:\n",
    "    NUTRIENT_DATASETS_ROOT = found_location\n",
    "    print(f\"\\n‚úÖ Using dataset location: {NUTRIENT_DATASETS_ROOT}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå 'Leaf Nutrient Data Sets' folder NOT FOUND!\")\n",
    "    print(f\"\\nüìÇ What's in your Drive:\")\n",
    "    try:\n",
    "        mydrive_items = os.listdir(mydrive_base)[:10]  # Show first 10 items\n",
    "        for item in mydrive_items:\n",
    "            item_path = os.path.join(mydrive_base, item)\n",
    "            if os.path.isdir(item_path):\n",
    "                print(f\"   üìÅ {item}\")\n",
    "            else:\n",
    "                print(f\"   üìÑ {item}\")\n",
    "    except:\n",
    "        print(\"   (Could not list Drive contents)\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è FOLDER IS IN 'SHARED WITH ME' - NOT ACCESSIBLE!\")\n",
    "    print(f\"\\n‚úÖ SOLUTION: Add shortcut to My Drive\")\n",
    "    print(f\"   1. Open Google Drive in browser: https://drive.google.com\")\n",
    "    print(f\"   2. Click 'Shared with me' in left sidebar\")\n",
    "    print(f\"   3. Right-click 'Leaf Nutrient Data Sets' folder\")\n",
    "    print(f\"   4. Select 'Add shortcut to Drive' or 'Organize' > 'Add shortcut'\")\n",
    "    print(f\"   5. Choose 'My Drive' root (don't put it in a subfolder)\")\n",
    "    print(f\"   6. Click 'Add' or 'Add shortcut'\")\n",
    "    print(f\"   7. Come back here and re-run this cell\")\n",
    "    print(f\"\\nüí° After adding shortcut, the folder will appear at:\")\n",
    "    print(f\"   /content/drive/MyDrive/Leaf Nutrient Data Sets\")\n",
    "\n",
    "# Verify ALL crop datasets exist (only if folder found)\n",
    "if found_location:\n",
    "    print(\"\\nüîç Verifying crop datasets...\")\n",
    "    missing_crops = []\n",
    "    for crop, folder_name in CROP_DATASETS.items():\n",
    "        crop_path = os.path.join(NUTRIENT_DATASETS_ROOT, folder_name)\n",
    "        if os.path.exists(crop_path):\n",
    "            num_classes = len([d for d in os.listdir(crop_path) if os.path.isdir(os.path.join(crop_path, d))])\n",
    "            print(f\"‚úÖ {crop.upper()}: {num_classes} classes\")\n",
    "        else:\n",
    "            print(f\"‚ùå {crop.upper()}: NOT FOUND\")\n",
    "            missing_crops.append(crop)\n",
    "\n",
    "    if missing_crops:\n",
    "        print(f\"\\n‚ö†Ô∏è WARNING: {len(missing_crops)} crop(s) not found: {', '.join(missing_crops)}\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ All {len(CROP_DATASETS)} crop datasets verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0539d26",
   "metadata": {},
   "source": [
    "## üöÄ Speed Optimization: Copy Data to Local Disk\n",
    "\n",
    "**This is the BIGGEST speed boost!** Copying from Drive to local SSD speeds up training 10-50x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üöÄ MASSIVE SPEEDUP: Copy Data from Drive to Local SSD\n",
    "# =============================================================\n",
    "# Reading from Google Drive is SLOW (network I/O)\n",
    "# Copying to /content/ uses Colab's fast local SSD = 10-50x faster!\n",
    "\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "def copy_folder_to_local(src_path, dest_name, force_copy=False):\n",
    "    \"\"\"Copy folder from Drive to local SSD for fast I/O\"\"\"\n",
    "    local_path = f\"/content/{dest_name}\"\n",
    "    \n",
    "    # Skip if already exists (for session resume)\n",
    "    if os.path.exists(local_path) and not force_copy:\n",
    "        num_items = len(os.listdir(local_path))\n",
    "        if num_items > 0:\n",
    "            print(f\"‚úÖ {dest_name} already on local disk ({num_items} items)\")\n",
    "            return local_path\n",
    "    \n",
    "    if not os.path.exists(src_path):\n",
    "        print(f\"‚ö†Ô∏è Source not found: {src_path}\")\n",
    "        return src_path  # Return original path as fallback\n",
    "    \n",
    "    print(f\"üöÄ Copying {dest_name} to local SSD...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    if os.path.exists(local_path):\n",
    "        shutil.rmtree(local_path)\n",
    "    \n",
    "    shutil.copytree(src_path, local_path)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    size_mb = sum(os.path.getsize(os.path.join(root, f)) \n",
    "                  for root, _, files in os.walk(local_path) \n",
    "                  for f in files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"‚úÖ Copied {dest_name}: {size_mb:.0f}MB in {elapsed:.1f}s\")\n",
    "    return local_path\n",
    "\n",
    "# Copy Nutrient datasets to local SSD\n",
    "print(\"=\" * 60)\n",
    "print(\"üöÄ COPYING DATASETS TO LOCAL SSD (One-time per session)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚è≥ This takes 2-5 minutes but saves HOURS of training time!\\n\")\n",
    "\n",
    "LOCAL_NUTRIENT_ROOT = '/content/local_nutrient_datasets'\n",
    "os.makedirs(LOCAL_NUTRIENT_ROOT, exist_ok=True)\n",
    "\n",
    "copy_success = 0\n",
    "copy_failed = []\n",
    "\n",
    "for crop, folder_name in CROP_DATASETS.items():\n",
    "    src = os.path.join(NUTRIENT_DATASETS_ROOT, folder_name)\n",
    "    dst = os.path.join(LOCAL_NUTRIENT_ROOT, folder_name)\n",
    "    \n",
    "    if os.path.exists(src):\n",
    "        if not os.path.exists(dst):\n",
    "            try:\n",
    "                shutil.copytree(src, dst)\n",
    "                print(f\"  ‚úÖ {crop}: Copied\")\n",
    "                copy_success += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå {crop}: Failed ({e})\")\n",
    "                copy_failed.append(crop)\n",
    "        else:\n",
    "            print(f\"  ‚è© {crop}: Already local\")\n",
    "            copy_success += 1\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è {crop}: Not found on Drive\")\n",
    "        copy_failed.append(crop)\n",
    "\n",
    "# Update root path to local copy\n",
    "NUTRIENT_DATASETS_ROOT = LOCAL_NUTRIENT_ROOT\n",
    "\n",
    "print(f\"\\n‚úÖ {copy_success}/{len(CROP_DATASETS)} crops copied to local SSD\")\n",
    "if copy_failed:\n",
    "    print(f\"‚ö†Ô∏è Failed: {', '.join(copy_failed)}\")\n",
    "print(\"üöÄ Training will now be 10-50x FASTER!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1061a425",
   "metadata": {},
   "source": [
    "## üå± Stage 1: Download PlantVillage Dataset from Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c0d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle credentials\n",
    "# IMPORTANT: You need to manually download kaggle.json FIRST!\n",
    "# \n",
    "# üìù HOW TO GET kaggle.json:\n",
    "# 1. Go to https://www.kaggle.com/settings\n",
    "# 2. Scroll down to \"API\" section\n",
    "# 3. Click \"Create New Token\" button\n",
    "# 4. This will DOWNLOAD a file called \"kaggle.json\" to your computer\n",
    "# 5. Find the downloaded file (usually in your Downloads folder)\n",
    "# 6. Then come back here and upload it when prompted below\n",
    "#\n",
    "# ‚ö†Ô∏è NOTE: If you only see the API key on screen but no download happened,\n",
    "#    click \"Create New Token\" again - it should download the file\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üì§ UPLOAD YOUR kaggle.json FILE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüìù If you haven't downloaded it yet:\")\n",
    "print(\"   1. Go to: https://www.kaggle.com/settings\")\n",
    "print(\"   2. Scroll to 'API' section\")\n",
    "print(\"   3. Click 'Create New Token' (downloads kaggle.json)\")\n",
    "print(\"   4. Find the file in your Downloads folder\")\n",
    "print(\"   5. Click 'Choose Files' below and select it\")\n",
    "print(\"\\n‚è≥ Waiting for your kaggle.json file...\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Verify the file was uploaded\n",
    "if 'kaggle.json' not in uploaded:\n",
    "    print(\"\\n‚ùå ERROR: kaggle.json was not uploaded!\")\n",
    "    print(\"   Please make sure you selected the correct file.\")\n",
    "    raise FileNotFoundError(\"kaggle.json not found in uploaded files\")\n",
    "\n",
    "# Move kaggle.json to the correct location\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print(\"\\n‚úÖ Kaggle credentials configured successfully!\")\n",
    "print(\"üìÅ File saved to: ~/.kaggle/kaggle.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b862f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PlantVillage dataset from Kaggle (SKIP IF ALREADY EXISTS)\n",
    "import opendatasets as od\n",
    "\n",
    "PLANTVILLAGE_URL = 'https://www.kaggle.com/datasets/emmarex/plantdisease'\n",
    "PLANTVILLAGE_PATH = '/content/plantvillage'\n",
    "\n",
    "# Known possible paths after download\n",
    "POSSIBLE_PATHS = [\n",
    "    os.path.join(PLANTVILLAGE_PATH, 'plantdisease', 'PlantVillage'),\n",
    "    os.path.join(PLANTVILLAGE_PATH, 'PlantVillage'),\n",
    "    os.path.join(PLANTVILLAGE_PATH, 'plantdisease', 'plantvillage', 'PlantVillage'),\n",
    "]\n",
    "\n",
    "def find_plantvillage_dataset():\n",
    "    \"\"\"Find PlantVillage dataset if it exists\"\"\"\n",
    "    for path in POSSIBLE_PATHS:\n",
    "        if os.path.exists(path) and os.path.isdir(path):\n",
    "            subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "            if len(subdirs) >= 15:\n",
    "                sample_dir = os.path.join(path, subdirs[0])\n",
    "                sample_files = [f for f in os.listdir(sample_dir)\n",
    "                              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                if len(sample_files) > 0:\n",
    "                    return path\n",
    "    return None\n",
    "\n",
    "# Check if dataset already exists\n",
    "existing_path = find_plantvillage_dataset()\n",
    "\n",
    "if existing_path:\n",
    "    print(\"‚úÖ PlantVillage dataset ALREADY EXISTS! Skipping download...\")\n",
    "    print(f\"üìÅ Using cached dataset at: {existing_path}\")\n",
    "    PLANTVILLAGE_PATH = existing_path\n",
    "else:\n",
    "    print(\"üì• Downloading PlantVillage dataset (54,305 images)...\")\n",
    "    print(\"‚è≥ This will take 3-5 minutes (first time only)...\")\n",
    "    \n",
    "    od.download(PLANTVILLAGE_URL, data_dir=PLANTVILLAGE_PATH)\n",
    "    \n",
    "    print(\"\\nüîç Locating dataset structure...\")\n",
    "    \n",
    "    # Find the dataset path\n",
    "    dataset_root = find_plantvillage_dataset()\n",
    "    \n",
    "    if not dataset_root:\n",
    "        # Search recursively as fallback\n",
    "        for root, dirs, files in os.walk(PLANTVILLAGE_PATH):\n",
    "            if len(dirs) >= 15:\n",
    "                has_images = False\n",
    "                for d in dirs[:3]:\n",
    "                    dir_path = os.path.join(root, d)\n",
    "                    if os.path.isdir(dir_path):\n",
    "                        dir_files = os.listdir(dir_path)\n",
    "                        if any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in dir_files):\n",
    "                            has_images = True\n",
    "                            break\n",
    "                if has_images:\n",
    "                    dataset_root = root\n",
    "                    break\n",
    "    \n",
    "    if dataset_root:\n",
    "        PLANTVILLAGE_PATH = dataset_root\n",
    "    else:\n",
    "        raise FileNotFoundError(\"‚ùå PlantVillage dataset not found after download\")\n",
    "\n",
    "# Verify dataset\n",
    "class_dirs = [d for d in os.listdir(PLANTVILLAGE_PATH) \n",
    "              if os.path.isdir(os.path.join(PLANTVILLAGE_PATH, d))]\n",
    "num_classes = len(class_dirs)\n",
    "\n",
    "print(f\"\\n‚úÖ PlantVillage dataset ready!\")\n",
    "print(f\"üìÅ Path: {PLANTVILLAGE_PATH}\")\n",
    "print(f\"üåø Classes: {num_classes}\")\n",
    "\n",
    "# Quick image count\n",
    "total_images = sum(len([f for f in os.listdir(os.path.join(PLANTVILLAGE_PATH, cls))\n",
    "                        if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) \n",
    "                   for cls in class_dirs[:5])\n",
    "print(f\"üìä Sample: First 5 classes have {total_images:,} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac424fc",
   "metadata": {},
   "source": [
    "## üìä Data Exploration & Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze PlantVillage dataset\n",
    "plantvillage_classes = sorted(os.listdir(PLANTVILLAGE_PATH))\n",
    "print(f\"üå± PlantVillage Dataset:\")\n",
    "print(f\"Total classes: {len(plantvillage_classes)}\")\n",
    "print(f\"\\nSample classes:\")\n",
    "for cls in plantvillage_classes[:5]:\n",
    "    class_path = os.path.join(PLANTVILLAGE_PATH, cls)\n",
    "    if os.path.isdir(class_path):\n",
    "        num_images = len(os.listdir(class_path))\n",
    "        print(f\"  - {cls}: {num_images} images\")\n",
    "\n",
    "# Build unified dataset info\n",
    "print(f\"\\nüåæ UNIFIED Nutrient Dataset (ALL {len(CROP_DATASETS)} crops):\")\n",
    "total_classes = 0\n",
    "total_images = 0\n",
    "\n",
    "for crop, folder_name in CROP_DATASETS.items():\n",
    "    crop_path = os.path.join(NUTRIENT_DATASETS_ROOT, folder_name)\n",
    "    if os.path.exists(crop_path):\n",
    "        crop_classes = [d for d in os.listdir(crop_path) if os.path.isdir(os.path.join(crop_path, d))]\n",
    "        crop_images = sum([len([f for f in os.listdir(os.path.join(crop_path, cls)) \n",
    "                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) \n",
    "                          for cls in crop_classes])\n",
    "        total_classes += len(crop_classes)\n",
    "        total_images += crop_images\n",
    "        print(f\"  {crop.upper()}: {len(crop_classes)} classes, {crop_images} images\")\n",
    "\n",
    "print(f\"\\nüìä UNIFIED TOTALS:\")\n",
    "print(f\"  Total classes: {total_classes}\")\n",
    "print(f\"  Total images: {total_images}\")\n",
    "print(f\"  Class format: {{crop}}_{{deficiency}} (e.g., rice_N, wheat_healthy)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7afbe",
   "metadata": {},
   "source": [
    "## üî® Create Data Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üöÄ OPTIMIZED DATA PIPELINE (T4 GPU + Local SSD)\n",
    "# =============================================================\n",
    "# With data on local SSD, we can use aggressive prefetching!\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def create_dataset(data_dir, img_size, batch_size, validation_split=0.2, subset=None):\n",
    "    \"\"\"Create dataset optimized for T4 GPU\"\"\"\n",
    "    return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=validation_split,\n",
    "        subset=subset,\n",
    "        seed=42,\n",
    "        image_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical',\n",
    "        shuffle=True  # Shuffles filenames (memory-safe)\n",
    "    )\n",
    "\n",
    "@tf.function\n",
    "def augment_training(image, label):\n",
    "    \"\"\"Training augmentation - balanced to prevent overfitting\"\"\"\n",
    "    # Random horizontal flip\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # Random brightness (mild)\n",
    "    image = tf.image.random_brightness(image, 0.15)\n",
    "    # Random contrast (mild)\n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    # Random saturation (very mild - preserve leaf colors)\n",
    "    image = tf.image.random_saturation(image, 0.95, 1.05)\n",
    "    return image, label\n",
    "\n",
    "@tf.function  \n",
    "def normalize_mobilenet(image, label):\n",
    "    \"\"\"Normalize for MobileNetV2 [-1, 1]\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "def build_pipeline(dataset, is_training=True):\n",
    "    \"\"\"\n",
    "    Optimized pipeline for T4 GPU with local SSD\n",
    "    - AUTOTUNE prefetch: GPU never waits for data\n",
    "    - Parallel map: CPU prepares batches in parallel\n",
    "    \"\"\"\n",
    "    if is_training:\n",
    "        # Parallel augmentation\n",
    "        dataset = dataset.map(augment_training, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # Parallel normalization\n",
    "    dataset = dataset.map(normalize_mobilenet, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # AUTOTUNE prefetch - prepares next batch while GPU trains\n",
    "    # Safe to use with local SSD (no RAM explosion)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Create PlantVillage datasets\n",
    "print(\"üì¶ Creating PlantVillage datasets (T4 OPTIMIZED)...\")\n",
    "\n",
    "train_plantvillage_raw = create_dataset(\n",
    "    PLANTVILLAGE_PATH, IMG_SIZE, BATCH_SIZE, \n",
    "    validation_split=0.2, subset='training'\n",
    ")\n",
    "val_plantvillage_raw = create_dataset(\n",
    "    PLANTVILLAGE_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "    validation_split=0.2, subset='validation'\n",
    ")\n",
    "\n",
    "# Apply optimized pipeline\n",
    "train_plantvillage = build_pipeline(train_plantvillage_raw, is_training=True)\n",
    "val_plantvillage = build_pipeline(val_plantvillage_raw, is_training=False)\n",
    "\n",
    "train_batches = tf.data.experimental.cardinality(train_plantvillage_raw).numpy()\n",
    "val_batches = tf.data.experimental.cardinality(val_plantvillage_raw).numpy()\n",
    "\n",
    "print(f\"\\n‚úÖ PlantVillage datasets ready (T4 OPTIMIZED)\")\n",
    "print(f\"   Training: {train_batches} batches √ó {BATCH_SIZE} = ~{train_batches * BATCH_SIZE:,} images\")\n",
    "print(f\"   Validation: {val_batches} batches √ó {BATCH_SIZE} = ~{val_batches * BATCH_SIZE:,} images\")\n",
    "print(f\"   ‚ö° AUTOTUNE prefetch enabled (GPU never waits)\")\n",
    "print(f\"   üé® Training augmentation: flip, brightness, contrast, saturation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8d714",
   "metadata": {},
   "source": [
    "## ‚úÖ Pre-Training Validation\n",
    "\n",
    "Run this cell to verify everything is set up correctly before training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ PRE-TRAINING VALIDATION (T4 Optimized)\n",
    "print(\"=\" * 60)\n",
    "print(\"üîç PRE-TRAINING VALIDATION\")\n",
    "print(f\"‚è±Ô∏è Session time: {get_session_time()}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = []\n",
    "\n",
    "# 1. GPU Check\n",
    "print(\"\\n1Ô∏è‚É£ GPU Check...\")\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    gpu_name = gpus[0].name\n",
    "    print(f\"   ‚úÖ GPU: {gpu_name}\")\n",
    "    # Check if T4\n",
    "    try:\n",
    "        !nvidia-smi --query-gpu=name --format=csv,noheader\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    errors.append(\"No GPU detected!\")\n",
    "    print(\"   ‚ö†Ô∏è No GPU - training will be MUCH slower\")\n",
    "\n",
    "# 2. Quick data test\n",
    "print(\"\\n2Ô∏è‚É£ Data Pipeline Check...\")\n",
    "try:\n",
    "    import time\n",
    "    start = time.time()\n",
    "    for batch_images, batch_labels in train_plantvillage.take(1):\n",
    "        load_time = time.time() - start\n",
    "        print(f\"   ‚úÖ Batch shape: {batch_images.shape}\")\n",
    "        print(f\"   ‚úÖ Labels shape: {batch_labels.shape}\")\n",
    "        print(f\"   ‚úÖ Image dtype: {batch_images.dtype}\")\n",
    "        print(f\"   ‚ö° First batch load: {load_time:.2f}s\")\n",
    "        break\n",
    "except Exception as e:\n",
    "    errors.append(f\"Data pipeline error: {e}\")\n",
    "    print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "# 3. Memory check\n",
    "print(\"\\n3Ô∏è‚É£ Memory Status...\")\n",
    "try:\n",
    "    import psutil\n",
    "    ram_total = psutil.virtual_memory().total / (1024**3)\n",
    "    ram_avail = psutil.virtual_memory().available / (1024**3)\n",
    "    print(f\"   ‚úÖ RAM: {ram_avail:.1f}GB available / {ram_total:.1f}GB total\")\n",
    "    if ram_avail < 3:\n",
    "        print(\"   ‚ö†Ô∏è Low RAM - data copied to local SSD helps prevent crashes\")\n",
    "except:\n",
    "    print(\"   ‚ÑπÔ∏è Could not check RAM\")\n",
    "\n",
    "# 4. GPU Memory check\n",
    "print(\"\\n4Ô∏è‚É£ GPU Memory Check...\")\n",
    "try:\n",
    "    !nvidia-smi --query-gpu=memory.total,memory.free --format=csv,noheader\n",
    "except:\n",
    "    print(\"   ‚ÑπÔ∏è Could not query GPU memory\")\n",
    "\n",
    "# 5. Existing checkpoints\n",
    "print(\"\\n5Ô∏è‚É£ Checkpoint Status...\")\n",
    "stage2_exists = os.path.exists(os.path.join(DRIVE_CHECKPOINT_DIR, 'stage2_plantvillage_best.keras'))\n",
    "stage3_exists = os.path.exists(os.path.join(DRIVE_CHECKPOINT_DIR, 'unified_nutrient_best.keras'))\n",
    "print(f\"   Stage 2 checkpoint: {'‚úÖ Found (will resume)' if stage2_exists else '‚ùå None (fresh start)'}\")\n",
    "print(f\"   Stage 3 checkpoint: {'‚úÖ Found (will resume)' if stage3_exists else '‚ùå None (fresh start)'}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if errors:\n",
    "    print(\"‚ùå ISSUES FOUND:\")\n",
    "    for e in errors:\n",
    "        print(f\"   ‚Ä¢ {e}\")\n",
    "else:\n",
    "    print(\"‚úÖ ALL CHECKS PASSED!\")\n",
    "    print(f\"\\nüöÄ T4 GPU OPTIMIZED SETTINGS:\")\n",
    "    print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE} (fills 16GB VRAM)\")\n",
    "    print(f\"   ‚Ä¢ Mixed precision: FP16\")\n",
    "    print(f\"   ‚Ä¢ JIT/XLA compilation: Enabled\")\n",
    "    print(f\"   ‚Ä¢ AUTOTUNE prefetch: Enabled\")\n",
    "    print(f\"   ‚Ä¢ Data location: Local SSD (fast I/O)\")\n",
    "    print(f\"\\n‚ö° Expected: ~1-2 min/epoch (10x faster than Drive I/O)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a853f",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Stage 2: Build Model with MobileNetV2 Base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, input_shape=(224, 224, 3), freeze_base=True, dropout_rate=0.3):\n",
    "    \"\"\"Create MobileNetV2-based model optimized for T4 GPU\"\"\"\n",
    "    \n",
    "    # Load MobileNetV2 with ImageNet weights\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = not freeze_base\n",
    "    \n",
    "    # Balanced classification head (prevents overfitting)\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(256, activation='relu', \n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(dropout_rate * 0.8),  # Slightly less on second dropout\n",
    "        # Float32 output for numerical stability with mixed precision\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Get number of PlantVillage classes\n",
    "num_plantvillage_classes = len(plantvillage_classes)\n",
    "\n",
    "# =============================================================\n",
    "# üîÑ CHECKPOINT RESUME: Load existing model if available\n",
    "# =============================================================\n",
    "STAGE2_CHECKPOINT = os.path.join(DRIVE_CHECKPOINT_DIR, 'stage2_plantvillage_best.keras')\n",
    "STAGE2_LOCAL = os.path.join(OUTPUT_DIR, 'stage2_plantvillage_best.keras')\n",
    "\n",
    "model_stage2 = None\n",
    "resume_stage2 = False\n",
    "\n",
    "# Check for existing checkpoint (Drive first, then local)\n",
    "for checkpoint_path in [STAGE2_CHECKPOINT, STAGE2_LOCAL]:\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            print(f\"üîÑ Found existing Stage 2 checkpoint!\")\n",
    "            print(f\"   Loading from: {checkpoint_path}\")\n",
    "            model_stage2 = tf.keras.models.load_model(checkpoint_path)\n",
    "            \n",
    "            # Verify it has correct output shape\n",
    "            if model_stage2.output_shape[-1] == num_plantvillage_classes:\n",
    "                resume_stage2 = True\n",
    "                print(f\"‚úÖ Resuming from checkpoint ({num_plantvillage_classes} classes)\")\n",
    "                \n",
    "                # Evaluate current performance\n",
    "                print(\"üìä Evaluating checkpoint...\")\n",
    "                val_loss, val_acc = model_stage2.evaluate(val_plantvillage, verbose=0)\n",
    "                print(f\"   Current val_accuracy: {val_acc:.4f}\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Checkpoint has different classes ({model_stage2.output_shape[-1]} vs {num_plantvillage_classes})\")\n",
    "                model_stage2 = None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not load checkpoint: {e}\")\n",
    "            model_stage2 = None\n",
    "\n",
    "# Create new model if no valid checkpoint\n",
    "if model_stage2 is None:\n",
    "    print(f\"üèóÔ∏è Creating NEW model for PlantVillage ({num_plantvillage_classes} classes)...\")\n",
    "    model_stage2, base_model = create_model(\n",
    "        num_plantvillage_classes, \n",
    "        freeze_base=True,\n",
    "        dropout_rate=DROPOUT_RATE\n",
    "    )\n",
    "else:\n",
    "    base_model = model_stage2.layers[0]\n",
    "\n",
    "# Compile with JIT compilation for 10-20% speedup\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_STAGE2)\n",
    "\n",
    "model_stage2.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    jit_compile=True  # XLA compilation - 10-20% faster on T4\n",
    ")\n",
    "\n",
    "# Count trainable params\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model_stage2.trainable_weights])\n",
    "print(f\"\\nüîí Base model frozen: {not base_model.trainable}\")\n",
    "print(f\"üìä Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"üíæ Mixed precision: FP16 enabled\")\n",
    "print(f\"‚ö° JIT/XLA compilation: Enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa4eee",
   "metadata": {},
   "source": [
    "## üéØ Stage 2: Train on PlantVillage Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0dc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting Stage 2: PlantVillage Fine-tuning\")\n",
    "print(f\"‚è±Ô∏è Epochs: {PLANTVILLAGE_EPOCHS} | LR: {LEARNING_RATE_STAGE2} | Batch: {BATCH_SIZE}\")\n",
    "if resume_stage2:\n",
    "    print(\"üîÑ RESUMING from previous checkpoint\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Balanced callbacks (prevent overfitting without underfitting)\n",
    "callbacks_stage2 = [\n",
    "    # Early stopping with balanced patience\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=4,  # Balanced - not too aggressive\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        min_delta=0.001  # Minimum improvement threshold\n",
    "    ),\n",
    "    # Reduce LR on plateau (helps find better minima)\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Save best to local (fast)\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, 'stage2_plantvillage_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Save best to Drive (persistent across sessions)\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(DRIVE_CHECKPOINT_DIR, 'stage2_plantvillage_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=0\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train\n",
    "history_stage2 = model_stage2.fit(\n",
    "    train_plantvillage,\n",
    "    validation_data=val_plantvillage,\n",
    "    epochs=PLANTVILLAGE_EPOCHS,\n",
    "    callbacks=callbacks_stage2,\n",
    "    verbose=2  # One line per epoch\n",
    ")\n",
    "\n",
    "# Calculate training stats\n",
    "best_val_acc = max(history_stage2.history['val_accuracy'])\n",
    "best_val_loss = min(history_stage2.history['val_loss'])\n",
    "final_train_acc = history_stage2.history['accuracy'][-1]\n",
    "\n",
    "print(f\"\\n‚úÖ Stage 2 completed!\")\n",
    "print(f\"üìà Best val accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"üìâ Best val loss: {best_val_loss:.4f}\")\n",
    "print(f\"üìä Final train accuracy: {final_train_acc:.4f}\")\n",
    "\n",
    "# Check for overfitting/underfitting\n",
    "gap = final_train_acc - best_val_acc\n",
    "if gap > 0.15:\n",
    "    print(f\"‚ö†Ô∏è Overfitting detected (train-val gap: {gap:.2%})\")\n",
    "elif best_val_acc < 0.7:\n",
    "    print(f\"‚ö†Ô∏è Possible underfitting (val_acc: {best_val_acc:.2%})\")\n",
    "else:\n",
    "    print(f\"‚úÖ Good generalization (train-val gap: {gap:.2%})\")\n",
    "\n",
    "print(f\"\\nüíæ Checkpoints saved to:\")\n",
    "print(f\"   Local: {OUTPUT_DIR}\")\n",
    "print(f\"   Drive: {DRIVE_CHECKPOINT_DIR} (persistent)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0802c5",
   "metadata": {},
   "source": [
    "## üìà Stage 2 Results Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history_stage2.history['accuracy'], 'b-', label='Train')\n",
    "axes[0].plot(history_stage2.history['val_accuracy'], 'r-', label='Val')\n",
    "axes[0].set_title('Stage 2: Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history_stage2.history['loss'], 'b-', label='Train')\n",
    "axes[1].plot(history_stage2.history['val_loss'], 'r-', label='Val')\n",
    "axes[1].set_title('Stage 2: Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'stage2_training_history.png'), dpi=150)\n",
    "plt.savefig(os.path.join(DRIVE_CHECKPOINT_DIR, 'stage2_training_history.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Memory cleanup (preserve model references)\n",
    "import gc\n",
    "gc.collect()\n",
    "print(\"üßπ Memory cleaned (models preserved for Stage 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9651b0c7",
   "metadata": {},
   "source": [
    "## üîÑ Stage 3: Build UNIFIED Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3160d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build unified dataset by combining all crops\n",
    "print(\"üèóÔ∏è Building UNIFIED dataset...\")\n",
    "\n",
    "UNIFIED_DATASET_PATH = '/content/unified_nutrient_dataset'\n",
    "\n",
    "# Check if unified dataset already exists\n",
    "if os.path.exists(UNIFIED_DATASET_PATH):\n",
    "    existing_classes = [d for d in os.listdir(UNIFIED_DATASET_PATH) \n",
    "                        if os.path.isdir(os.path.join(UNIFIED_DATASET_PATH, d))]\n",
    "    if len(existing_classes) > 10:\n",
    "        print(f\"‚úÖ Already exists with {len(existing_classes)} classes!\")\n",
    "        unified_classes = existing_classes\n",
    "    else:\n",
    "        import shutil\n",
    "        shutil.rmtree(UNIFIED_DATASET_PATH)\n",
    "        os.makedirs(UNIFIED_DATASET_PATH)\n",
    "        unified_classes = []\n",
    "else:\n",
    "    os.makedirs(UNIFIED_DATASET_PATH)\n",
    "    unified_classes = []\n",
    "\n",
    "if len(unified_classes) == 0:\n",
    "    skipped_crops = []\n",
    "    \n",
    "    for crop, folder_name in CROP_DATASETS.items():\n",
    "        crop_path = os.path.join(NUTRIENT_DATASETS_ROOT, folder_name)\n",
    "        \n",
    "        if not os.path.exists(crop_path):\n",
    "            skipped_crops.append(crop)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            crop_classes = [d for d in os.listdir(crop_path) \n",
    "                            if os.path.isdir(os.path.join(crop_path, d))]\n",
    "        except:\n",
    "            skipped_crops.append(crop)\n",
    "            continue\n",
    "        \n",
    "        for cls in crop_classes:\n",
    "            try:\n",
    "                clean_cls = cls.replace(f\"{crop}_\", \"\").replace(f\"{crop}__\", \"\")\n",
    "                unified_class_name = f\"{crop}_{clean_cls}\"\n",
    "                \n",
    "                src_dir = os.path.join(crop_path, cls)\n",
    "                dst_dir = os.path.join(UNIFIED_DATASET_PATH, unified_class_name)\n",
    "                \n",
    "                if not os.path.exists(dst_dir):\n",
    "                    os.symlink(src_dir, dst_dir)\n",
    "                    unified_classes.append(unified_class_name)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        print(f\"  ‚úÖ {crop.upper()}: {len([c for c in unified_classes if c.startswith(crop)])} classes\")\n",
    "    \n",
    "    if skipped_crops:\n",
    "        print(f\"‚ö†Ô∏è Skipped: {', '.join(skipped_crops)}\")\n",
    "\n",
    "if len(unified_classes) == 0:\n",
    "    raise RuntimeError(\"‚ùå No classes! Check Google Drive paths.\")\n",
    "\n",
    "class_names = sorted(unified_classes)\n",
    "num_unified_classes = len(class_names)\n",
    "\n",
    "print(f\"\\n‚úÖ Unified dataset: {num_unified_classes} classes\")\n",
    "\n",
    "# Create MEMORY-SAFE datasets\n",
    "print(\"üì¶ Creating datasets (MEMORY-SAFE)...\")\n",
    "\n",
    "train_nutrient_raw = create_dataset(\n",
    "    UNIFIED_DATASET_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "    validation_split=0.2, subset='training'\n",
    ")\n",
    "val_nutrient_raw = create_dataset(\n",
    "    UNIFIED_DATASET_PATH, IMG_SIZE, BATCH_SIZE,\n",
    "    validation_split=0.2, subset='validation'\n",
    ")\n",
    "\n",
    "train_nutrient = build_pipeline(train_nutrient_raw, is_training=True)\n",
    "val_nutrient = build_pipeline(val_nutrient_raw, is_training=False)\n",
    "\n",
    "print(f\"‚úÖ Datasets ready (MEMORY-SAFE)\")\n",
    "print(f\"   Training: {tf.data.experimental.cardinality(train_nutrient_raw).numpy()} batches\")\n",
    "print(f\"   Validation: {tf.data.experimental.cardinality(val_nutrient_raw).numpy()} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0ec80",
   "metadata": {},
   "source": [
    "## üîß Stage 3: Adapt Model for Unified Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# üîÑ STAGE 3: Adapt Model for Unified Classes (with Resume)\n",
    "# =============================================================\n",
    "if 'num_unified_classes' not in locals() or num_unified_classes == 0:\n",
    "    raise RuntimeError(\"‚ö†Ô∏è Run 'Build UNIFIED Dataset' cell first!\")\n",
    "\n",
    "print(f\"üîß Setting up Stage 3 for {num_unified_classes} unified classes...\")\n",
    "\n",
    "# Check for existing Stage 3 checkpoint\n",
    "STAGE3_CHECKPOINT = os.path.join(DRIVE_CHECKPOINT_DIR, 'unified_nutrient_best.keras')\n",
    "STAGE3_LOCAL = os.path.join(OUTPUT_DIR, 'unified_nutrient_best.keras')\n",
    "\n",
    "model_stage3 = None\n",
    "resume_stage3 = False\n",
    "initial_epoch = 0\n",
    "\n",
    "# Try to load existing checkpoint\n",
    "for checkpoint_path in [STAGE3_CHECKPOINT, STAGE3_LOCAL]:\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            print(f\"üîÑ Found existing Stage 3 checkpoint!\")\n",
    "            print(f\"   Loading from: {checkpoint_path}\")\n",
    "            model_stage3 = tf.keras.models.load_model(checkpoint_path)\n",
    "            \n",
    "            # Verify correct output shape\n",
    "            if model_stage3.output_shape[-1] == num_unified_classes:\n",
    "                resume_stage3 = True\n",
    "                print(f\"‚úÖ Checkpoint valid ({num_unified_classes} classes)\")\n",
    "                \n",
    "                # Evaluate current performance\n",
    "                print(\"üìä Evaluating checkpoint...\")\n",
    "                results = model_stage3.evaluate(val_nutrient, verbose=0)\n",
    "                print(f\"   Current - Loss: {results[0]:.4f}, Accuracy: {results[1]:.4f}\")\n",
    "                \n",
    "                # Check training history for initial_epoch\n",
    "                history_path = os.path.join(DRIVE_CHECKPOINT_DIR, 'stage3_history.json')\n",
    "                if os.path.exists(history_path):\n",
    "                    with open(history_path, 'r') as f:\n",
    "                        prev_history = json.load(f)\n",
    "                        initial_epoch = len(prev_history.get('accuracy', []))\n",
    "                        print(f\"   Resuming from epoch {initial_epoch}\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Class mismatch ({model_stage3.output_shape[-1]} vs {num_unified_classes})\")\n",
    "                print(\"   Creating new model (classes changed)\")\n",
    "                model_stage3 = None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not load: {e}\")\n",
    "            model_stage3 = None\n",
    "\n",
    "# Create new model if needed\n",
    "if model_stage3 is None:\n",
    "    print(f\"üèóÔ∏è Creating NEW unified model...\")\n",
    "    \n",
    "    # Get base model from Stage 2\n",
    "    base_model_stage2 = model_stage2.layers[0]\n",
    "    base_model_stage2.trainable = False  # Keep frozen initially\n",
    "    \n",
    "    # Balanced classification head (prevents overfitting)\n",
    "    model_stage3 = tf.keras.Sequential([\n",
    "        base_model_stage2,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "        tf.keras.layers.Dense(384, activation='relu',\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(DROPOUT_RATE * 0.8),\n",
    "        tf.keras.layers.Dense(num_unified_classes, activation='softmax', dtype='float32')\n",
    "    ], name='unified_nutrient_model')\n",
    "\n",
    "# Compile with JIT for speed\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_STAGE3)\n",
    "\n",
    "model_stage3.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')],\n",
    "    jit_compile=True  # XLA compilation - 10-20% faster\n",
    ")\n",
    "\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model_stage3.trainable_weights])\n",
    "print(f\"\\nüìä Trainable params: {trainable_params:,}\")\n",
    "print(f\"üéØ Output classes: {num_unified_classes}\")\n",
    "print(f\"‚ö° JIT/XLA compilation: Enabled\")\n",
    "print(f\"üîÑ Resume training: {'Yes (epoch ' + str(initial_epoch) + ')' if resume_stage3 else 'No (fresh start)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb2661",
   "metadata": {},
   "source": [
    "## üéØ Stage 3: Train on UNIFIED Nutrient Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting Stage 3: UNIFIED Nutrient Detection\")\n",
    "print(f\"üåæ Training ALL {len(CROP_DATASETS)} crops | Epochs: {UNIFIED_EPOCHS} | LR: {LEARNING_RATE_STAGE3}\")\n",
    "if resume_stage3:\n",
    "    print(f\"üîÑ RESUMING from epoch {initial_epoch}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Balanced callbacks (prevent overfitting without underfitting)\n",
    "callbacks_stage3 = [\n",
    "    # Early stopping - balanced patience\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,  # More patience for complex multi-crop task\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "        min_delta=0.001\n",
    "    ),\n",
    "    # Reduce LR on plateau\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Save best to local (fast)\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(OUTPUT_DIR, 'unified_nutrient_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # Save best to Drive (persistent)\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(DRIVE_CHECKPOINT_DIR, 'unified_nutrient_best.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=0\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train (with resume support)\n",
    "history_stage3 = model_stage3.fit(\n",
    "    train_nutrient,\n",
    "    validation_data=val_nutrient,\n",
    "    epochs=UNIFIED_EPOCHS,\n",
    "    initial_epoch=initial_epoch,  # Resume from checkpoint epoch\n",
    "    callbacks=callbacks_stage3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Save training history for resume\n",
    "history_dict = {k: [float(v) for v in vals] for k, vals in history_stage3.history.items()}\n",
    "with open(os.path.join(DRIVE_CHECKPOINT_DIR, 'stage3_history.json'), 'w') as f:\n",
    "    json.dump(history_dict, f)\n",
    "\n",
    "# Calculate final stats\n",
    "best_val_acc = max(history_stage3.history['val_accuracy'])\n",
    "best_val_loss = min(history_stage3.history['val_loss'])\n",
    "best_top3_acc = max(history_stage3.history['val_top3_acc'])\n",
    "final_train_acc = history_stage3.history['accuracy'][-1]\n",
    "\n",
    "print(f\"\\n‚úÖ Stage 3 completed!\")\n",
    "print(f\"üìà Best val accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"üéØ Best top-3 accuracy: {best_top3_acc:.4f}\")\n",
    "print(f\"üìâ Best val loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Check for overfitting/underfitting\n",
    "gap = final_train_acc - best_val_acc\n",
    "if gap > 0.20:\n",
    "    print(f\"\\n‚ö†Ô∏è Overfitting detected (gap: {gap:.2%})\")\n",
    "    print(\"   Consider: increase dropout, add more augmentation, or reduce model size\")\n",
    "elif best_val_acc < 0.5:\n",
    "    print(f\"\\n‚ö†Ô∏è Possible underfitting (val_acc: {best_val_acc:.2%})\")\n",
    "    print(\"   Consider: more epochs, higher learning rate, or unfreeze more layers\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Good generalization (gap: {gap:.2%})\")\n",
    "\n",
    "print(f\"\\nüíæ Model & history saved to Drive (persistent across sessions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fcb26",
   "metadata": {},
   "source": [
    "## üìà Stage 3 Results Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce165f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history_stage3.history['accuracy'], 'b-', label='Train')\n",
    "axes[0].plot(history_stage3.history['val_accuracy'], 'r-', label='Val')\n",
    "axes[0].set_title('Stage 3: Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history_stage3.history['loss'], 'b-', label='Train')\n",
    "axes[1].plot(history_stage3.history['val_loss'], 'r-', label='Val')\n",
    "axes[1].set_title('Stage 3: Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'stage3_training_history.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10140073",
   "metadata": {},
   "source": [
    "## üîç Model Evaluation & Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick evaluation (skip heavy confusion matrix for speed)\n",
    "print(\"üîç Evaluating UNIFIED model...\")\n",
    "results = model_stage3.evaluate(val_nutrient, verbose=0)\n",
    "\n",
    "print(f\"\\nüìä Validation Metrics:\")\n",
    "print(f\"   Loss: {results[0]:.4f}\")\n",
    "print(f\"   Accuracy: {results[1]:.4f}\")\n",
    "print(f\"   Top-3 Accuracy: {results[2]:.4f}\")\n",
    "\n",
    "# Quick per-crop accuracy (sample-based for speed)\n",
    "print(f\"\\nüåæ Per-Crop Performance (quick check):\")\n",
    "y_true, y_pred = [], []\n",
    "for images, labels in val_nutrient.take(20):  # Sample only\n",
    "    predictions = model_stage3.predict(images, verbose=0)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "for crop in list(CROP_DATASETS.keys())[:6]:  # First 6 crops\n",
    "    crop_classes = [cls for cls in class_names if cls.startswith(f\"{crop}_\")]\n",
    "    if not crop_classes:\n",
    "        continue\n",
    "    crop_indices = [class_names.index(cls) for cls in crop_classes]\n",
    "    crop_mask = np.isin(y_true, crop_indices)\n",
    "    if crop_mask.sum() > 0:\n",
    "        crop_acc = (np.array(y_true)[crop_mask] == np.array(y_pred)[crop_mask]).mean()\n",
    "        print(f\"   {crop.upper():12s}: {crop_acc:.1%}\")\n",
    "\n",
    "# Save classification report\n",
    "report = classification_report(y_true, y_pred, target_names=[class_names[i] for i in sorted(set(y_true))], output_dict=True, zero_division=0)\n",
    "with open(os.path.join(OUTPUT_DIR, 'unified_classification_report.json'), 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b395d",
   "metadata": {},
   "source": [
    "## üíæ Export to TensorFlow Lite for Mobile Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf78c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì¶ Converting to TensorFlow Lite...\")\n",
    "print(f\"‚è±Ô∏è Session time: {get_session_time()}\")\n",
    "check_time_limit()  # Warn if approaching 3-hour limit\n",
    "\n",
    "# Load best model\n",
    "best_model_path = os.path.join(OUTPUT_DIR, 'unified_nutrient_best.keras')\n",
    "if not os.path.exists(best_model_path):\n",
    "    # Try Drive checkpoint\n",
    "    best_model_path = os.path.join(DRIVE_CHECKPOINT_DIR, 'unified_nutrient_best.keras')\n",
    "    \n",
    "best_model = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "# Convert to TFLite with FP16 quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "print(\"‚öôÔ∏è Converting with FP16 quantization...\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save to both local and Drive\n",
    "tflite_path = os.path.join(OUTPUT_DIR, 'fasalvaidya_unified.tflite')\n",
    "tflite_drive_path = os.path.join(DRIVE_CHECKPOINT_DIR, 'fasalvaidya_unified.tflite')\n",
    "\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "with open(tflite_drive_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "keras_size = os.path.getsize(best_model_path) / (1024 * 1024)\n",
    "tflite_size = os.path.getsize(tflite_path) / (1024 * 1024)\n",
    "\n",
    "print(f\"\\n‚úÖ Conversion complete!\")\n",
    "print(f\"üìä Keras: {keras_size:.1f}MB ‚Üí TFLite: {tflite_size:.1f}MB ({(1-tflite_size/keras_size)*100:.0f}% smaller)\")\n",
    "print(f\"üöÄ Single model for {len(CROP_DATASETS)} crops!\")\n",
    "print(f\"\\nüíæ Saved to:\")\n",
    "print(f\"   Local: {tflite_path}\")\n",
    "print(f\"   Drive: {tflite_drive_path} (persistent)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488f02a",
   "metadata": {},
   "source": [
    "## üß™ Test TFLite Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b10789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick TFLite verification\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"üîç TFLite Model:\")\n",
    "print(f\"   Input: {input_details[0]['shape']} ({input_details[0]['dtype']})\")\n",
    "print(f\"   Output: {output_details[0]['shape']} ({num_unified_classes} classes)\")\n",
    "\n",
    "# Quick test\n",
    "for images, labels in val_nutrient.take(1):\n",
    "    test_image = images[0].numpy()\n",
    "    input_data = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    pred_idx = np.argmax(output[0])\n",
    "    true_idx = np.argmax(labels[0].numpy())\n",
    "    \n",
    "    print(f\"\\nüß™ Quick test:\")\n",
    "    print(f\"   True: {class_names[true_idx]}\")\n",
    "    print(f\"   Pred: {class_names[pred_idx]} ({output[0][pred_idx]:.1%})\")\n",
    "    print(f\"   {'‚úÖ CORRECT' if pred_idx == true_idx else '‚ùå INCORRECT'}\")\n",
    "    break\n",
    "\n",
    "print(\"\\n‚úÖ TFLite model verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ffab2",
   "metadata": {},
   "source": [
    "## üì§ Save Model Metadata & Class Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f144a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata and labels (to both local and Drive)\n",
    "print(\"üìù Saving metadata...\")\n",
    "\n",
    "crop_class_mapping = {crop: [c for c in class_names if c.startswith(f\"{crop}_\")] \n",
    "                      for crop in CROP_DATASETS.keys()}\n",
    "\n",
    "metadata = {\n",
    "    'model_type': 'unified_multi_crop',\n",
    "    'model_version': '2.0',\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'architecture': 'MobileNetV2',\n",
    "    'supported_crops': list(CROP_DATASETS.keys()),\n",
    "    'num_crops': len(CROP_DATASETS),\n",
    "    'input_shape': [IMG_SIZE, IMG_SIZE, 3],\n",
    "    'num_classes': num_unified_classes,\n",
    "    'class_names': class_names,\n",
    "    'crop_class_mapping': crop_class_mapping,\n",
    "    'metrics': {'accuracy': float(results[1]), 'top3_accuracy': float(results[2])},\n",
    "    'preprocessing': {'method': 'MobileNetV2', 'normalization': '[-1, 1]'},\n",
    "    'training_config': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'plantvillage_epochs': PLANTVILLAGE_EPOCHS,\n",
    "        'unified_epochs': UNIFIED_EPOCHS,\n",
    "        'dropout_rate': DROPOUT_RATE,\n",
    "        'optimizations': ['mixed_precision_fp16', 'jit_compile', 'autotune_prefetch']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to both locations\n",
    "for save_dir in [OUTPUT_DIR, DRIVE_CHECKPOINT_DIR]:\n",
    "    with open(os.path.join(save_dir, 'unified_model_metadata.json'), 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    with open(os.path.join(save_dir, 'labels.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(class_names))\n",
    "\n",
    "print(f\"‚úÖ Saved: metadata.json, labels.txt\")\n",
    "print(f\"üìä {len(CROP_DATASETS)} crops, {num_unified_classes} classes\")\n",
    "print(f\"üíæ Saved to both local and Drive (persistent)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d8a9c",
   "metadata": {},
   "source": [
    "## üì¶ Download Models to Local Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and download zip\n",
    "import shutil\n",
    "\n",
    "# Session summary\n",
    "print(\"=\" * 60)\n",
    "print(\"üéâ TRAINING SESSION COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚è±Ô∏è Total session time: {get_session_time()}\")\n",
    "print(f\"üìä Final validation accuracy: {results[1]:.4f}\")\n",
    "print(f\"üéØ Final top-3 accuracy: {results[2]:.4f}\")\n",
    "\n",
    "zip_filename = 'fasalvaidya_unified_model'\n",
    "shutil.make_archive(f'/content/{zip_filename}', 'zip', OUTPUT_DIR)\n",
    "\n",
    "print(f\"\\nüì¶ Created: {zip_filename}.zip\")\n",
    "print(f\"\\nüìÇ Contents:\")\n",
    "print(f\"   üì± fasalvaidya_unified.tflite ({tflite_size:.1f}MB)\")\n",
    "print(f\"   üíæ unified_nutrient_best.keras\")\n",
    "print(f\"   üìÑ unified_model_metadata.json\")\n",
    "print(f\"   üè∑Ô∏è labels.txt ({num_unified_classes} classes)\")\n",
    "print(f\"\\nüåæ Supports: {', '.join(list(CROP_DATASETS.keys())[:6])}...\")\n",
    "\n",
    "print(f\"\\nüíæ ALSO SAVED TO DRIVE (persistent):\")\n",
    "print(f\"   {DRIVE_CHECKPOINT_DIR}\")\n",
    "print(f\"   ‚úÖ Can resume training if disconnected!\")\n",
    "\n",
    "from google.colab import files\n",
    "files.download(f'/content/{zip_filename}.zip')\n",
    "print(f\"\\n‚¨áÔ∏è Download started!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a73ed9",
   "metadata": {},
   "source": [
    "## üéâ UNIFIED Model Training Complete!\n",
    "\n",
    "### üöÄ Performance Optimizations Applied\n",
    "\n",
    "This notebook is **10-50x FASTER** than the original thanks to:\n",
    "\n",
    "| Optimization | Impact | What it does |\n",
    "|-------------|--------|--------------|\n",
    "| **Local SSD Copy** | 10-50x faster I/O | Copies data from Drive to `/content/` at start |\n",
    "| **Batch Size 128** | 3-4x GPU utilization | Fills T4's 16GB VRAM efficiently |\n",
    "| **AUTOTUNE Prefetch** | ~20% faster | GPU never waits for data |\n",
    "| **JIT/XLA Compile** | 10-20% faster | Optimizes TensorFlow graph |\n",
    "| **Mixed Precision** | 2x faster | Uses FP16 on T4 Tensor Cores |\n",
    "\n",
    "**Expected performance:** ~1-2 minutes/epoch (vs ~10 min without optimizations)\n",
    "\n",
    "### üîÑ Checkpoint Resume Feature\n",
    "\n",
    "- **Automatic resume:** If Colab disconnects, just re-run the notebook\n",
    "- **Checkpoints saved to Drive:** Persistent across sessions\n",
    "- **Training continues from last epoch:** No wasted GPU time!\n",
    "\n",
    "### üéØ Overfitting/Underfitting Prevention\n",
    "\n",
    "- **L2 Regularization:** Prevents weights from growing too large\n",
    "- **Balanced Dropout:** 0.3 on first layer, 0.24 on second\n",
    "- **Early Stopping:** Patience=5 with min_delta=0.001\n",
    "- **Learning Rate Schedule:** ReduceLROnPlateau with factor=0.5\n",
    "- **Training Augmentation:** Flip, brightness, contrast, saturation\n",
    "\n",
    "### üì¶ What You Got\n",
    "\n",
    "**ONE powerful model for ALL crops:**\n",
    "\n",
    "- üì± Single TFLite file: `fasalvaidya_unified.tflite` (~10-15MB)\n",
    "- üåæ 12 crops: rice, wheat, tomato, maize, banana, coffee, cucumber, eggplant, ashgourd, bittergourd, ridgegourd, snakegourd\n",
    "- üéØ 40-60+ deficiency classes\n",
    "- üî• Class format: `{crop}_{deficiency}` (e.g., `rice_N`, `wheat_healthy`)\n",
    "\n",
    "### üíæ Files Saved (Both Local & Drive)\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `fasalvaidya_unified.tflite` | Mobile-optimized model |\n",
    "| `unified_nutrient_best.keras` | Full Keras model |\n",
    "| `unified_model_metadata.json` | Model info & class mappings |\n",
    "| `labels.txt` | All class labels |\n",
    "| `stage3_history.json` | Training history (for resume) |\n",
    "\n",
    "### üîÑ To Resume Training After Disconnect\n",
    "\n",
    "1. **Re-run all cells** - checkpoints auto-load from Drive\n",
    "2. Training continues from last saved epoch\n",
    "3. No need to re-download PlantVillage or re-copy data\n",
    "\n",
    "### ‚è±Ô∏è Time Budget (3-hour limit)\n",
    "\n",
    "| Stage | Estimated Time |\n",
    "|-------|---------------|\n",
    "| Setup & Data Copy | 5-10 min |\n",
    "| Stage 2 (PlantVillage) | 15-30 min |\n",
    "| Stage 3 (Unified) | 30-60 min |\n",
    "| Export & Download | 5 min |\n",
    "| **Total** | ~1-2 hours |\n",
    "\n",
    "**Plenty of buffer for the 3-hour Colab limit!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
