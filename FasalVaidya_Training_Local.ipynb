{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b5aebd",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup & Check GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a10a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "GPU Devices: []\n",
      "âš ï¸ No GPU detected - will use CPU (slow)\n",
      "\n",
      "ğŸ’¡ For AMD GPU on Windows, install: pip install tensorflow-directml\n",
      "ğŸ’¡ For NVIDIA GPU, install: pip install tensorflow[and-cuda]\n"
     ]
    }
   ],
   "source": [
    "# Check TensorFlow and GPU availability\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "\n",
    "# Check for GPU devices (works for both CUDA and DirectML)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPU Devices: {gpus}\")\n",
    "\n",
    "if gpus:\n",
    "    print(f\"âœ… {len(gpus)} GPU(s) detected!\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"   - {gpu}\")\n",
    "    \n",
    "    # Enable memory growth to prevent OOM errors\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"âœ… GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU config: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected - will use CPU (slow)\")\n",
    "    print(\"\\nğŸ’¡ For AMD GPU on Windows, install: pip install tensorflow-directml\")\n",
    "    print(\"ğŸ’¡ For NVIDIA GPU, install: pip install tensorflow[and-cuda]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ab0528",
   "metadata": {},
   "source": [
    "### ğŸ® AMD GPU Setup Instructions\n",
    "\n",
    "Since you have an AMD GPU, you need **TensorFlow-DirectML**:\n",
    "\n",
    "**1. Uninstall regular TensorFlow (if installed):**\n",
    "\n",
    "```bash\n",
    "pip uninstall tensorflow tensorflow-gpu\n",
    "```\n",
    "\n",
    "**2. Install TensorFlow-DirectML:**\n",
    "\n",
    "```bash\n",
    "pip install tensorflow-directml\n",
    "```\n",
    "\n",
    "**3. Run the GPU check cell below** to verify your AMD GPU is detected.\n",
    "\n",
    "âš ï¸ **Note:** DirectML has some limitations:\n",
    "\n",
    "- Slightly slower than NVIDIA CUDA\n",
    "- Some advanced features may not work\n",
    "- But it will still be **much faster than CPU**!\n",
    "\n",
    "If you have issues, you can still train on CPU (just slower).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9349de",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Configuration\n",
    "\n",
    "**IMPORTANT:** Update `DATASET_ROOT` to point to your local dataset folder.\n",
    "\n",
    "Expected structure:\n",
    "\n",
    "```\n",
    "Leaf Nutrient Data Sets/\n",
    "â”œâ”€â”€ Rice Nutrients/\n",
    "â”‚   â”œâ”€â”€ Nitrogen(N)/\n",
    "â”‚   â”œâ”€â”€ Phosphorus(P)/\n",
    "â”‚   â””â”€â”€ Potassium(K)/\n",
    "â”œâ”€â”€ Tomato Nutrients/\n",
    "â”‚   â””â”€â”€ train/\n",
    "â”‚       â”œâ”€â”€ Tomato - Healthy/\n",
    "â”‚       â”œâ”€â”€ Tomato - Nitrogen Deficiency/\n",
    "â”‚       â””â”€â”€ ...\n",
    "â””â”€â”€ ... other crops\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e530556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset found at: E:\\FasalVaidya\\Leaf Nutrient Data Sets\n",
      "ğŸ“‚ Contents: ['Ashgourd Nutrients', 'Banana leaves Nutrient', 'Bittergourd Nutrients', 'Coffee Nutrients', 'Cucumber Nutrients', 'EggPlant Nutrients', 'Maize Nutrients', 'Rice Nutrients', 'Ridgegourd', 'Snakegourd Nutrients', 'Tomato Nutrients', 'Wheat Nitrogen']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB2, MobileNetV3Large\n",
    "\n",
    "# ========================================\n",
    "# ğŸ“ DATASET PATHS (Relative to notebook location)\n",
    "# ========================================\n",
    "# Get notebook directory (current working directory)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "DATASET_ROOT = NOTEBOOK_DIR / 'Leaf Nutrient Data Sets'\n",
    "MODEL_OUTPUT = NOTEBOOK_DIR / 'backend' / 'ml' / 'models'\n",
    "\n",
    "# Create output directory\n",
    "MODEL_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Verify dataset exists\n",
    "if DATASET_ROOT.exists():\n",
    "    print(f\"âœ… Dataset found at: {DATASET_ROOT}\")\n",
    "    print(f\"ğŸ“‚ Contents: {[f.name for f in DATASET_ROOT.iterdir() if f.is_dir()]}\")\n",
    "else:\n",
    "    print(f\"âŒ Dataset NOT found at: {DATASET_ROOT}\")\n",
    "    print(\"Please update DATASET_ROOT to your local path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d7eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Checking dataset folder structure...\n",
      "\n",
      "âœ… Root exists: E:\\FasalVaidya\\Leaf Nutrient Data Sets\n",
      "\n",
      "ğŸ“ Ashgourd Nutrients/\n",
      "    â””â”€â”€ ash_gourd__healthy/ (83 images)\n",
      "    â””â”€â”€ ash_gourd__K/ (293 images)\n",
      "    â””â”€â”€ ash_gourd__K_Mg/ (53 images)\n",
      "    â””â”€â”€ ash_gourd__N/ (61 images)\n",
      "    â””â”€â”€ ash_gourd__N_K/ (386 images)\n",
      "    â””â”€â”€ ash_gourd__N_Mg/ (42 images)\n",
      "    â””â”€â”€ ash_gourd__PM/ (79 images)\n",
      "\n",
      "ğŸ“ Banana leaves Nutrient/\n",
      "    â””â”€â”€ healthy/ (950 images)\n",
      "    â””â”€â”€ magnesium/ (800 images)\n",
      "    â””â”€â”€ potassium/ (840 images)\n",
      "\n",
      "ğŸ“ Bittergourd Nutrients/\n",
      "    â””â”€â”€ bitter_gourd__DM/ (48 images)\n",
      "    â””â”€â”€ bitter_gourd__healthy/ (181 images)\n",
      "    â””â”€â”€ bitter_gourd__JAS/ (35 images)\n",
      "    â””â”€â”€ bitter_gourd__K/ (55 images)\n",
      "    â””â”€â”€ bitter_gourd__K_Mg/ (40 images)\n",
      "    â””â”€â”€ bitter_gourd__LS/ (35 images)\n",
      "    â””â”€â”€ bitter_gourd__N/ (147 images)\n",
      "    â””â”€â”€ bitter_gourd__N_K/ (128 images)\n",
      "    â””â”€â”€ bitter_gourd__N_Mg/ (116 images)\n",
      "\n",
      "ğŸ“ Coffee Nutrients/\n",
      "    â””â”€â”€ healthy/ (6 images)\n",
      "    â””â”€â”€ nitrogen-N/ (64 images)\n",
      "    â””â”€â”€ phosphorus-P/ (246 images)\n",
      "    â””â”€â”€ potasium-K/ (96 images)\n",
      "\n",
      "ğŸ“ Cucumber Nutrients/\n",
      "    â””â”€â”€ cucumber__healthy/ (34 images)\n",
      "    â””â”€â”€ cucumber__K/ (50 images)\n",
      "    â””â”€â”€ cucumber__N/ (89 images)\n",
      "    â””â”€â”€ cucumber__N_K/ (76 images)\n",
      "\n",
      "ğŸ“ EggPlant Nutrients/\n",
      "    â””â”€â”€ eggplant__healthy/ (92 images)\n",
      "    â””â”€â”€ eggplant__K/ (106 images)\n",
      "    â””â”€â”€ eggplant__N/ (67 images)\n",
      "    â””â”€â”€ eggplant__N_K/ (106 images)\n",
      "\n",
      "ğŸ“ Maize Nutrients/\n",
      "    â””â”€â”€ test/ (0 images)\n",
      "        â””â”€â”€ ALL Present/ (294 images)\n",
      "        â””â”€â”€ ALLAB/ (486 images)\n",
      "        â””â”€â”€ KAB/ (860 images)\n",
      "        â””â”€â”€ NAB/ (307 images)\n",
      "        â””â”€â”€ PAB/ (2376 images)\n",
      "        ... and 1 more folders\n",
      "    â””â”€â”€ train/ (0 images)\n",
      "        â””â”€â”€ ALL Present/ (1176 images)\n",
      "        â””â”€â”€ ALLAB/ (1944 images)\n",
      "        â””â”€â”€ KAB/ (3441 images)\n",
      "        â””â”€â”€ NAB/ (1228 images)\n",
      "        â””â”€â”€ PAB/ (2970 images)\n",
      "        ... and 1 more folders\n",
      "\n",
      "ğŸ“ Rice Nutrients/\n",
      "    â””â”€â”€ Nitrogen(N)/ (440 images)\n",
      "    â””â”€â”€ Phosphorus(P)/ (333 images)\n",
      "    â””â”€â”€ Potassium(K)/ (383 images)\n",
      "\n",
      "ğŸ“ Ridgegourd/\n",
      "    â””â”€â”€ ridge_gourd__healthy/ (70 images)\n",
      "    â””â”€â”€ ridge_gourd__N/ (152 images)\n",
      "    â””â”€â”€ ridge_gourd__N_Mg/ (34 images)\n",
      "    â””â”€â”€ ridge_gourd__PC/ (33 images)\n",
      "\n",
      "ğŸ“ Snakegourd Nutrients/\n",
      "    â””â”€â”€ snake_gourd__healthy/ (59 images)\n",
      "    â””â”€â”€ snake_gourd__K/ (56 images)\n",
      "    â””â”€â”€ snake_gourd__LS/ (33 images)\n",
      "    â””â”€â”€ snake_gourd__N/ (102 images)\n",
      "    â””â”€â”€ snake_gourd__N_K/ (206 images)\n",
      "\n",
      "ğŸ“ Tomato Nutrients/\n",
      "    â””â”€â”€ test/ (0 images)\n",
      "        â””â”€â”€ Tomato - Healthy/ (38 images)\n",
      "        â””â”€â”€ Tomato - Nitrogen and Potassium Deficiency/ (6 images)\n",
      "        â””â”€â”€ Tomato - Nitrogen Deficiency/ (8 images)\n",
      "        â””â”€â”€ Tomato - Potassium Deficiency/ (6 images)\n",
      "    â””â”€â”€ train/ (0 images)\n",
      "        â””â”€â”€ Tomato - Healthy/ (151 images)\n",
      "        â””â”€â”€ Tomato - Jassid and Mite/ (21 images)\n",
      "        â””â”€â”€ Tomato - Leaf Miner/ (132 images)\n",
      "        â””â”€â”€ Tomato - Mite/ (128 images)\n",
      "        â””â”€â”€ Tomato - Nitrogen and Potassium Deficiency/ (26 images)\n",
      "        ... and 2 more folders\n",
      "\n",
      "ğŸ“ Wheat Nitrogen/\n",
      "    â””â”€â”€ test/ (0 images)\n",
      "        â””â”€â”€ control/ (45 images)\n",
      "        â””â”€â”€ deficiency/ (45 images)\n",
      "    â””â”€â”€ train/ (0 images)\n",
      "        â””â”€â”€ control/ (210 images)\n",
      "        â””â”€â”€ deficiency/ (210 images)\n",
      "    â””â”€â”€ val/ (0 images)\n",
      "        â””â”€â”€ control/ (45 images)\n",
      "        â””â”€â”€ deficiency/ (45 images)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ğŸ” DEBUG: Check actual folder structure\n",
    "# ========================================\n",
    "print(\"ğŸ“‚ Checking dataset folder structure...\\n\")\n",
    "\n",
    "if DATASET_ROOT.exists():\n",
    "    print(f\"âœ… Root exists: {DATASET_ROOT}\\n\")\n",
    "    \n",
    "    for folder in sorted(DATASET_ROOT.iterdir()):\n",
    "        if folder.is_dir():\n",
    "            print(f\"ğŸ“ {folder.name}/\")\n",
    "            # List subfolders\n",
    "            subfolders = [f for f in folder.iterdir() if f.is_dir()]\n",
    "            for sf in sorted(subfolders)[:10]:  # Show first 10\n",
    "                # Count images directly in this folder\n",
    "                img_count = len(list(sf.glob('*.[jJpP][pPnN][gG]*')))\n",
    "                print(f\"    â””â”€â”€ {sf.name}/ ({img_count} images)\")\n",
    "                \n",
    "                # If no images directly but has subfolders, show those too\n",
    "                if img_count == 0:\n",
    "                    sub_subfolders = [f for f in sf.iterdir() if f.is_dir()]\n",
    "                    if sub_subfolders:\n",
    "                        for ssf in sorted(sub_subfolders)[:5]:  # Show first 5 sub-subfolders\n",
    "                            ssf_img_count = len(list(ssf.glob('*.[jJpP][pPnN][gG]*')))\n",
    "                            print(f\"        â””â”€â”€ {ssf.name}/ ({ssf_img_count} images)\")\n",
    "                        if len(sub_subfolders) > 5:\n",
    "                            print(f\"        ... and {len(sub_subfolders)-5} more folders\")\n",
    "            if len(subfolders) > 10:\n",
    "                print(f\"    ... and {len(subfolders)-10} more folders\")\n",
    "            print()\n",
    "else:\n",
    "    print(f\"âŒ Dataset root not found: {DATASET_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274bacc",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Crop Configurations\n",
    "\n",
    "Each crop has specific folder-to-label mappings for N, P, K, Mg deficiencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa357451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Available crops: ['rice', 'tomato', 'wheat', 'maize', 'banana', 'coffee', 'cucumber', 'eggplant', 'ashgourd', 'bittergourd', 'ridgegourd', 'snakegourd']\n"
     ]
    }
   ],
   "source": [
    "# Seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Image settings\n",
    "IMG_SIZE = 224\n",
    "MAX_SAMPLES_PER_CLASS = 2000\n",
    "\n",
    "# Crop configurations with folderâ†’label mappings\n",
    "CROP_CONFIGS = {\n",
    "    'rice': {\n",
    "        'name': 'Rice',\n",
    "        'dataset_path': DATASET_ROOT / 'Rice Nutrients',\n",
    "        'class_mapping': {\n",
    "            'Nitrogen(N)': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'Phosphorus(P)': {'N': 0, 'P': 1, 'K': 0, 'Mg': 0},\n",
    "            'Potassium(K)': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': False,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'tomato': {\n",
    "        'name': 'Tomato',\n",
    "        'dataset_path': DATASET_ROOT / 'Tomato Nutrients',\n",
    "        'use_train_folder': True,\n",
    "        'class_mapping': {\n",
    "            'Tomato - Healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'Tomato - Nitrogen Deficiency': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'Tomato - Potassium Deficiency': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'Tomato - Nitrogen and Potassium Deficiency': {'N': 1, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'Tomato - Jassid and Mite': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'Tomato - Leaf Miner': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'Tomato - Mite': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'wheat': {\n",
    "        'name': 'Wheat',\n",
    "        'dataset_path': DATASET_ROOT / 'Wheat Nitrogen',\n",
    "        'use_train_folder': True,\n",
    "        'include_val_folder': True,  # Include val folder for more training data\n",
    "        'class_mapping': {\n",
    "            'control': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'deficiency': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'maize': {\n",
    "        'name': 'Maize',\n",
    "        'dataset_path': DATASET_ROOT / 'Maize Nutrients',\n",
    "        'use_train_folder': True,\n",
    "        'class_mapping': {\n",
    "            'ALL Present': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'NAB': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'PAB': {'N': 0, 'P': 1, 'K': 0, 'Mg': 0},\n",
    "            'KAB': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'ALLAB': {'N': 1, 'P': 1, 'K': 1, 'Mg': 0},\n",
    "            'ZNAB': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'banana': {\n",
    "        'name': 'Banana',\n",
    "        'dataset_path': DATASET_ROOT / 'Banana leaves Nutrient',\n",
    "        'class_mapping': {\n",
    "            'healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'potassium': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'magnesium': {'N': 0, 'P': 0, 'K': 0, 'Mg': 1},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'coffee': {\n",
    "        'name': 'Coffee',\n",
    "        'dataset_path': DATASET_ROOT / 'Coffee Nutrients',\n",
    "        'class_mapping': {\n",
    "            'healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'nitrogen-N': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'phosphorus-P': {'N': 0, 'P': 1, 'K': 0, 'Mg': 0},\n",
    "            'potasium-K': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'cucumber': {\n",
    "        'name': 'Cucumber',\n",
    "        'dataset_path': DATASET_ROOT / 'Cucumber Nutrients',\n",
    "        'class_mapping': {\n",
    "            'cucumber__healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'cucumber__N': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'cucumber__K': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'cucumber__N_K': {'N': 1, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'eggplant': {\n",
    "        'name': 'Eggplant',\n",
    "        'dataset_path': DATASET_ROOT / 'EggPlant Nutrients',\n",
    "        'class_mapping': {\n",
    "            'eggplant__healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'eggplant__N': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'eggplant__K': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'eggplant__N_K': {'N': 1, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'ashgourd': {\n",
    "        'name': 'Ash Gourd',\n",
    "        'dataset_path': DATASET_ROOT / 'Ashgourd Nutrients',\n",
    "        'class_mapping': {\n",
    "            'ash_gourd__healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'ash_gourd__N': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'ash_gourd__K': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'ash_gourd__N_K': {'N': 1, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'ash_gourd__K_Mg': {'N': 0, 'P': 0, 'K': 1, 'Mg': 1},\n",
    "            'ash_gourd__N_Mg': {'N': 1, 'P': 0, 'K': 0, 'Mg': 1},\n",
    "            'ash_gourd__PM': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'bittergourd': {\n",
    "        'name': 'Bitter Gourd',\n",
    "        'dataset_path': DATASET_ROOT / 'Bittergourd Nutrients',\n",
    "        'class_mapping': {\n",
    "            'bitter_gourd__healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'bitter_gourd__N': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'bitter_gourd__K': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'bitter_gourd__N_K': {'N': 1, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'bitter_gourd__K_Mg': {'N': 0, 'P': 0, 'K': 1, 'Mg': 1},\n",
    "            'bitter_gourd__N_Mg': {'N': 1, 'P': 0, 'K': 0, 'Mg': 1},\n",
    "            'bitter_gourd__DM': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'bitter_gourd__JAS': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'bitter_gourd__LS': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'ridgegourd': {\n",
    "        'name': 'Ridge Gourd',\n",
    "        'dataset_path': DATASET_ROOT / 'Ridgegourd',\n",
    "        'class_mapping': {\n",
    "            'ridge_gourd__healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'ridge_gourd__N': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'ridge_gourd__N_Mg': {'N': 1, 'P': 0, 'K': 0, 'Mg': 1},\n",
    "            'ridge_gourd__PC': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "    'snakegourd': {\n",
    "        'name': 'Snake Gourd',\n",
    "        'dataset_path': DATASET_ROOT / 'Snakegourd Nutrients',\n",
    "        'class_mapping': {\n",
    "            'snake_gourd__healthy': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'snake_gourd__N': {'N': 1, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "            'snake_gourd__K': {'N': 0, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'snake_gourd__N_K': {'N': 1, 'P': 0, 'K': 1, 'Mg': 0},\n",
    "            'snake_gourd__LS': {'N': 0, 'P': 0, 'K': 0, 'Mg': 0},\n",
    "        },\n",
    "        'has_healthy': True,\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"ğŸ“‹ Available crops: {list(CROP_CONFIGS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d602cc",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Data Loading & Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b5d805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory-efficient data loading ready\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def load_and_preprocess_image(img_path, target_size=(IMG_SIZE, IMG_SIZE)):\n",
    "    \"\"\"Load and preprocess a single image.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize(target_size, Image.LANCZOS)\n",
    "        return np.array(img, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_image_paths_and_labels(crop_id):\n",
    "    \"\"\"Get list of image paths and their labels (doesn't load images into memory).\"\"\"\n",
    "    config = CROP_CONFIGS[crop_id]\n",
    "    dataset_path = config['dataset_path']\n",
    "    class_mapping = config['class_mapping']\n",
    "    use_train_folder = config.get('use_train_folder', False)\n",
    "    include_val_folder = config.get('include_val_folder', False)\n",
    "    \n",
    "    # List of folder paths to scan\n",
    "    scan_paths = []\n",
    "    \n",
    "    if use_train_folder:\n",
    "        train_path = dataset_path / 'train'\n",
    "        if train_path.exists():\n",
    "            scan_paths.append(train_path)\n",
    "        \n",
    "        # Also include val folder if requested (useful for Wheat)\n",
    "        if include_val_folder:\n",
    "            val_path = dataset_path / 'val'\n",
    "            if val_path.exists():\n",
    "                scan_paths.append(val_path)\n",
    "    else:\n",
    "        scan_paths.append(dataset_path)\n",
    "    \n",
    "    if not scan_paths:\n",
    "        raise FileNotFoundError(f\"Dataset not found: {dataset_path}\")\n",
    "    \n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_counts = {}\n",
    "    \n",
    "    print(f\"\\nğŸ“‚ Scanning {config['name']} from: {', '.join(str(p) for p in scan_paths)}\")\n",
    "    \n",
    "    # Scan all specified paths\n",
    "    for scan_path in scan_paths:\n",
    "        for folder_name, label_dict in class_mapping.items():\n",
    "            folder_path = scan_path / folder_name\n",
    "            if not folder_path.exists():\n",
    "                continue\n",
    "            \n",
    "            # Get image files\n",
    "            img_files = list(folder_path.glob('*.jpg')) + list(folder_path.glob('*.jpeg')) + \\\n",
    "                        list(folder_path.glob('*.png')) + list(folder_path.glob('*.JPG')) + \\\n",
    "                        list(folder_path.glob('*.JPEG')) + list(folder_path.glob('*.PNG'))\n",
    "            \n",
    "            # Update class counts\n",
    "            if folder_name not in class_counts:\n",
    "                class_counts[folder_name] = 0\n",
    "            class_counts[folder_name] += len(img_files)\n",
    "            \n",
    "            for img_path in img_files:\n",
    "                image_paths.append(str(img_path))\n",
    "                label = [label_dict.get('N', 0), label_dict.get('P', 0), \n",
    "                         label_dict.get('K', 0), label_dict.get('Mg', 0)]\n",
    "                labels.append(label)\n",
    "    \n",
    "    # Limit samples per class to prevent memory issues\n",
    "    if len(image_paths) > MAX_SAMPLES_PER_CLASS * len(class_mapping):\n",
    "        print(f\"  âš ï¸ Dataset too large, sampling {MAX_SAMPLES_PER_CLASS} per class\")\n",
    "        # Sample proportionally from each class\n",
    "        sampled_paths = []\n",
    "        sampled_labels = []\n",
    "        for folder_name in class_mapping.keys():\n",
    "            class_indices = [i for i, path in enumerate(image_paths) \n",
    "                           if folder_name in path]\n",
    "            if len(class_indices) > MAX_SAMPLES_PER_CLASS:\n",
    "                class_indices = random.sample(class_indices, MAX_SAMPLES_PER_CLASS)\n",
    "            for idx in class_indices:\n",
    "                sampled_paths.append(image_paths[idx])\n",
    "                sampled_labels.append(labels[idx])\n",
    "        image_paths = sampled_paths\n",
    "        labels = sampled_labels\n",
    "    \n",
    "    print(f\"  ğŸ“Š Class distribution: {class_counts}\")\n",
    "    print(f\"  âœ… Found {len(image_paths)} images\")\n",
    "    \n",
    "    return image_paths, np.array(labels, dtype=np.float32)\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Memory-efficient data generator that loads images on-the-fly.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, batch_size=32, img_size=IMG_SIZE, shuffle=True, augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.indices = np.arange(len(self.image_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for i in batch_indices:\n",
    "            img = load_and_preprocess_image(self.image_paths[i], (self.img_size, self.img_size))\n",
    "            if img is not None:\n",
    "                batch_images.append(img)\n",
    "                batch_labels.append(self.labels[i])\n",
    "        \n",
    "        return np.array(batch_images), np.array(batch_labels)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU and RAM memory.\"\"\"\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    print(\"ğŸ§¹ Memory cleared\")\n",
    "\n",
    "\n",
    "# Data augmentation layer (applied in model, not generator)\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.15),\n",
    "    layers.RandomContrast(0.15),\n",
    "], name='data_augmentation')\n",
    "\n",
    "print(\"âœ… Memory-efficient data loading ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8435abf",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31780238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model created: 4,417,063 parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"fasalvaidya_efficientnetb0\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"fasalvaidya_efficientnetb0\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ rescaling_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ normalization_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ npkmg_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ rescaling_2 (\u001b[38;5;33mRescaling\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ normalization_1 (\u001b[38;5;33mNormalization\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m4,049,571\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚         \u001b[38;5;34m5,120\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m327,936\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m32,896\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ npkmg_output (\u001b[38;5;33mDense\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              â”‚           \u001b[38;5;34m516\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,417,063</span> (16.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,417,063\u001b[0m (16.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">364,420</span> (1.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m364,420\u001b[0m (1.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,643</span> (15.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,052,643\u001b[0m (15.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model(backbone='efficientnetb0', num_outputs=4):\n",
    "    \"\"\"Create the nutrient deficiency detection model.\"\"\"\n",
    "    \n",
    "    # Select backbone\n",
    "    if backbone == 'efficientnetb0':\n",
    "        base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    elif backbone == 'efficientnetb2':\n",
    "        base = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    elif backbone == 'mobilenetv3large':\n",
    "        base = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n",
    "    \n",
    "    # Freeze base initially\n",
    "    base.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    # Preprocessing (scale to [0,1] then ImageNet normalization)\n",
    "    x = layers.Rescaling(1./255)(inputs)\n",
    "    x = layers.Normalization(mean=[0.485, 0.456, 0.406], variance=[0.229**2, 0.224**2, 0.225**2])(x)\n",
    "    \n",
    "    # Augmentation (only during training)\n",
    "    x = data_augmentation(x)\n",
    "    \n",
    "    # Backbone\n",
    "    x = base(x, training=False)\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Output: 4 sigmoid outputs for N, P, K, Mg\n",
    "    outputs = layers.Dense(num_outputs, activation='sigmoid', name='npkmg_output')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name=f'fasalvaidya_{backbone}')\n",
    "    return model, base\n",
    "\n",
    "\n",
    "# Test model creation\n",
    "test_model, _ = create_model()\n",
    "print(f\"âœ… Model created: {test_model.count_params():,} parameters\")\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe6ac3",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Training Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080cfdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training function ready (memory-efficient with continue-training support)\n"
     ]
    }
   ],
   "source": [
    "def train_crop_model(crop_id, epochs=50, batch_size=16, backbone='efficientnetb0', fine_tune=True):\n",
    "    \"\"\"\n",
    "    Train or improve a model for a specific crop (MEMORY-EFFICIENT VERSION).\n",
    "    \n",
    "    - Uses data generators to load images on-the-fly (prevents OOM crashes)\n",
    "    - If a model already exists: loads it and continues training (fine-tuning)\n",
    "    - If no model exists: trains from scratch\n",
    "    \n",
    "    Args:\n",
    "        crop_id: Crop identifier (e.g., 'rice', 'tomato')\n",
    "        epochs: Number of training epochs\n",
    "        batch_size: Batch size (default 16 to prevent OOM)\n",
    "        backbone: Model backbone (only used for new models)\n",
    "        fine_tune: Whether to fine-tune backbone layers\n",
    "    \"\"\"\n",
    "    # Clear memory before starting\n",
    "    clear_memory()\n",
    "    \n",
    "    config = CROP_CONFIGS[crop_id]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸŒ± Training model for: {config['name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Check for existing model\n",
    "    output_dir = MODEL_OUTPUT / crop_id\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    existing_model_path = output_dir / f'{crop_id}_best.keras'\n",
    "    \n",
    "    is_continuing = existing_model_path.exists()\n",
    "    \n",
    "    # Get image paths and labels (doesn't load images into memory!)\n",
    "    image_paths, labels = get_image_paths_and_labels(crop_id)\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        print(f\"âŒ No images found for {crop_id}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Split into train/val\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.2, random_state=SEED\n",
    "    )\n",
    "    print(f\"\\nğŸ“Š Train: {len(train_paths)}, Validation: {len(val_paths)}\")\n",
    "    \n",
    "    # Create data generators (memory-efficient!)\n",
    "    train_gen = DataGenerator(train_paths, train_labels, batch_size=batch_size, shuffle=True, augment=True)\n",
    "    val_gen = DataGenerator(val_paths, val_labels, batch_size=batch_size, shuffle=False, augment=False)\n",
    "    \n",
    "    # Either load existing model or create new one\n",
    "    if is_continuing:\n",
    "        print(f\"\\nğŸ”„ Found existing model - CONTINUING training to improve accuracy\")\n",
    "        print(f\"   Loading: {existing_model_path}\")\n",
    "        model = keras.models.load_model(str(existing_model_path))\n",
    "        base_model = None\n",
    "        \n",
    "        # Check previous accuracy on a small sample\n",
    "        sample_x, sample_y = val_gen[0]\n",
    "        old_results = model.evaluate(sample_x, sample_y, verbose=0)\n",
    "        print(f\"   Previous (sample) - Accuracy: {old_results[1]:.4f}, AUC: {old_results[2]:.4f}\")\n",
    "        \n",
    "        initial_lr = 1e-5\n",
    "    else:\n",
    "        print(f\"\\nğŸ†• No existing model - training from SCRATCH\")\n",
    "        model, base_model = create_model(backbone=backbone)\n",
    "        initial_lr = 1e-3\n",
    "        old_results = None\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=initial_lr),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            str(output_dir / f'{crop_id}_best.keras'),\n",
    "            monitor='val_auc',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_auc',\n",
    "            mode='max',\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=4,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    if is_continuing:\n",
    "        # For existing models: single phase of continued training\n",
    "        print(f\"\\nğŸŸ¢ Continuing training for {epochs} epochs...\")\n",
    "        history = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        # For new models: two-phase training\n",
    "        phase1_epochs = max(epochs // 2, 5)\n",
    "        phase2_epochs = epochs - phase1_epochs\n",
    "        \n",
    "        # Phase 1: Train classifier head\n",
    "        print(f\"\\nğŸ”µ Phase 1: Training classifier head ({phase1_epochs} epochs)...\")\n",
    "        history1 = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=phase1_epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Phase 2: Fine-tune backbone\n",
    "        if fine_tune and base_model is not None:\n",
    "            print(f\"\\nğŸŸ¢ Phase 2: Fine-tuning backbone ({phase2_epochs} epochs)...\")\n",
    "            base_model.trainable = True\n",
    "            \n",
    "            # Freeze early layers, train later ones\n",
    "            for layer in base_model.layers[:-20]:\n",
    "                layer.trainable = False\n",
    "            \n",
    "            model.compile(\n",
    "                optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "            )\n",
    "            \n",
    "            history2 = model.fit(\n",
    "                train_gen,\n",
    "                validation_data=val_gen,\n",
    "                epochs=phase2_epochs,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "    \n",
    "    # Evaluate on full validation set\n",
    "    print(f\"\\nğŸ“ˆ Final Evaluation:\")\n",
    "    results = model.evaluate(val_gen, verbose=0)\n",
    "    print(f\"  Loss: {results[0]:.4f}\")\n",
    "    print(f\"  Accuracy: {results[1]:.4f}\")\n",
    "    print(f\"  AUC: {results[2]:.4f}\")\n",
    "    \n",
    "    if is_continuing and old_results:\n",
    "        acc_change = results[1] - old_results[1]\n",
    "        auc_change = results[2] - old_results[2]\n",
    "        print(f\"\\nğŸ“Š Improvement (vs sample):\")\n",
    "        print(f\"  Accuracy: {'+' if acc_change >= 0 else ''}{acc_change:.4f}\")\n",
    "        print(f\"  AUC: {'+' if auc_change >= 0 else ''}{auc_change:.4f}\")\n",
    "    \n",
    "    # Save final model\n",
    "    model.save(str(output_dir / f'{crop_id}_final.keras'))\n",
    "    print(f\"\\nğŸ’¾ Model saved to: {output_dir}\")\n",
    "    \n",
    "    # Save/update metadata\n",
    "    metadata = {\n",
    "        'crop_id': crop_id,\n",
    "        'crop_name': config['name'],\n",
    "        'backbone': backbone if not is_continuing else 'continued',\n",
    "        'outputs': ['N', 'P', 'K', 'Mg'],\n",
    "        'val_accuracy': float(results[1]),\n",
    "        'val_auc': float(results[2]),\n",
    "        'trained_at': datetime.now().isoformat(),\n",
    "        'train_samples': len(train_paths),\n",
    "        'val_samples': len(val_paths),\n",
    "        'training_mode': 'continued' if is_continuing else 'from_scratch',\n",
    "    }\n",
    "    with open(output_dir / 'metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    # Clear memory after training\n",
    "    clear_memory()\n",
    "    \n",
    "    return model, results\n",
    "\n",
    "print(\"âœ… Training function ready (memory-efficient with continue-training support)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4183fba",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Train a Single Crop (Demo)\n",
    "\n",
    "Run this cell to train a model for a single crop. Change `CROP_TO_TRAIN` to train different crops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸ¯ SELECT CROP TO TRAIN\n",
    "# ========================================\n",
    "CROP_TO_TRAIN = 'rice'  # Change this: rice, tomato, wheat, maize, banana, coffee, etc.\n",
    "EPOCHS = 30             # Increase for better results (50-100 recommended)\n",
    "BATCH_SIZE = 16         # Adjust based on your GPU memory (16-32)\n",
    "BACKBONE = 'efficientnetb0'  # or 'efficientnetb2', 'mobilenetv3large'\n",
    "\n",
    "# Verify crop exists\n",
    "if CROP_TO_TRAIN in CROP_CONFIGS:\n",
    "    print(f\"ğŸš€ Starting training for: {CROP_TO_TRAIN}\")\n",
    "    print(f\"ğŸ’¡ Tip: If you run this again, it will IMPROVE the existing model!\")\n",
    "    model, results = train_crop_model(\n",
    "        CROP_TO_TRAIN, \n",
    "        epochs=EPOCHS, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        backbone=BACKBONE\n",
    "    )\n",
    "else:\n",
    "    print(f\"âŒ Unknown crop: {CROP_TO_TRAIN}\")\n",
    "    print(f\"Available: {list(CROP_CONFIGS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b53c0d",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Train All Crops (Full Run)\n",
    "\n",
    "âš ï¸ This will take a while! Only run if you want to train models for all crops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9129f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ğŸš€ TRAIN ALL CROPS\n",
    "# ========================================\n",
    "# This will train/improve models for ALL crops sequentially\n",
    "# Memory is cleared between each crop to prevent crashes\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 16  # Adjust based on your GPU memory\n",
    "\n",
    "results_summary = {}\n",
    "\n",
    "for crop_id in CROP_CONFIGS.keys():\n",
    "    try:\n",
    "        print(f\"\\n\\n{'#'*70}\")\n",
    "        print(f\"# Training crop {list(CROP_CONFIGS.keys()).index(crop_id)+1}/{len(CROP_CONFIGS)}: {crop_id}\")\n",
    "        print(f\"{'#'*70}\")\n",
    "        \n",
    "        model, results = train_crop_model(crop_id, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "        \n",
    "        if results:\n",
    "            results_summary[crop_id] = {\n",
    "                'accuracy': float(results[1]),\n",
    "                'auc': float(results[2]),\n",
    "                'status': 'success'\n",
    "            }\n",
    "        else:\n",
    "            results_summary[crop_id] = {'status': 'skipped', 'error': 'No images found'}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to train {crop_id}: {e}\")\n",
    "        results_summary[crop_id] = {'status': 'failed', 'error': str(e)}\n",
    "        clear_memory()  # Clear memory on failure to recover\n",
    "\n",
    "# Save summary\n",
    "with open(MODEL_OUTPUT / 'training_summary.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“Š TRAINING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "for crop, res in results_summary.items():\n",
    "    if res['status'] == 'success':\n",
    "        print(f\"  âœ… {crop}: Accuracy={res['accuracy']:.4f}, AUC={res['auc']:.4f}\")\n",
    "    elif res['status'] == 'skipped':\n",
    "        print(f\"  â­ï¸ {crop}: SKIPPED - {res.get('error', 'Unknown')}\")\n",
    "    else:\n",
    "        print(f\"  âŒ {crop}: FAILED - {res.get('error', 'Unknown error')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c21da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\FasalVaidya\\backend\\.venv311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "ğŸ§¹ Memory cleared\n",
      "\n",
      "============================================================\n",
      "ğŸŒ± Training model for: Bitter Gourd\n",
      "============================================================\n",
      "\n",
      "ğŸ“‚ Scanning Bitter Gourd from: E:\\FasalVaidya\\Leaf Nutrient Data Sets\\Bittergourd Nutrients\n",
      "  ğŸ“Š Class distribution: {'bitter_gourd__healthy': 362, 'bitter_gourd__N': 294, 'bitter_gourd__K': 110, 'bitter_gourd__N_K': 256, 'bitter_gourd__K_Mg': 80, 'bitter_gourd__N_Mg': 232, 'bitter_gourd__DM': 96, 'bitter_gourd__JAS': 70, 'bitter_gourd__LS': 70}\n",
      "  âœ… Found 1570 images\n",
      "\n",
      "ğŸ“Š Train: 1256, Validation: 314\n",
      "\n",
      "ğŸ†• No existing model - training from SCRATCH\n",
      "\n",
      "ğŸ”µ Phase 1: Training classifier head (20 epochs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\FasalVaidya\\backend\\.venv311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31s/step - accuracy: 0.2985 - auc: 0.5087 - loss: 0.7766 \n",
      "Epoch 1: val_auc improved from None to 0.67168, saving model to E:\\FasalVaidya\\backend\\ml\\models\\bittergourd\\bittergourd_best.keras\n",
      "\n",
      "Epoch 1: finished saving model to E:\\FasalVaidya\\backend\\ml\\models\\bittergourd\\bittergourd_best.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 50s/step - accuracy: 0.3790 - auc: 0.5649 - loss: 0.7050 - val_accuracy: 0.1115 - val_auc: 0.6717 - val_loss: 0.6409 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1/5\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m2:11\u001b[0m 33s/step - accuracy: 0.5781 - auc: 0.6524 - loss: 0.6074"
     ]
    }
   ],
   "source": [
    "# Train only the previously skipped crops\n",
    "SKIPPED_CROPS = ['bittergourd', 'ridgegourd', 'snakegourd', 'ashgourd']\n",
    "for crop_id in SKIPPED_CROPS:\n",
    "    model, results = train_crop_model(crop_id, epochs=40, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c53066",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ View Trained Models\n",
    "\n",
    "After training, your models are saved in:\n",
    "`E:/FasalVaidya/backend/ml/models/<crop_id>/`\n",
    "\n",
    "Each folder contains:\n",
    "\n",
    "- `<crop>_best.keras` - Best model by validation AUC\n",
    "- `<crop>_final.keras` - Final model after all epochs\n",
    "- `metadata.json` - Training info and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e65f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List trained models\n",
    "print(\"ğŸ“¦ Trained models:\")\n",
    "if MODEL_OUTPUT.exists():\n",
    "    for crop_dir in MODEL_OUTPUT.iterdir():\n",
    "        if crop_dir.is_dir():\n",
    "            files = list(crop_dir.glob('*.keras'))\n",
    "            if files:\n",
    "                print(f\"  {crop_dir.name}/\")\n",
    "                for f in files:\n",
    "                    size_mb = f.stat().st_size / (1024*1024)\n",
    "                    print(f\"    - {f.name} ({size_mb:.1f} MB)\")\n",
    "                # Show metadata if exists\n",
    "                metadata_file = crop_dir / 'metadata.json'\n",
    "                if metadata_file.exists():\n",
    "                    with open(metadata_file) as f:\n",
    "                        meta = json.load(f)\n",
    "                    print(f\"      Accuracy: {meta.get('val_accuracy', 'N/A'):.4f}\")\n",
    "                    print(f\"      AUC: {meta.get('val_auc', 'N/A'):.4f}\")\n",
    "else:\n",
    "    print(\"  No models found yet. Run training first!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FasalVaidya (.venv311)",
   "language": "python",
   "name": "fasalvaidya-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
